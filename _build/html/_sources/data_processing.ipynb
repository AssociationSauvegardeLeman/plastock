{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13449d70-f334-4082-a3ff-2d6ca7bd1a6a",
   "metadata": {},
   "source": [
    "(data_processing)=\n",
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0416dd59-f9b4-436d-ad6d-2b374c649c19",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "' '"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "blank_caption"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import multinomial\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from myst_nb import glue\n",
    "from slugify import slugify\n",
    "\n",
    "from typing import List \n",
    "\n",
    "import plastockconf as psc\n",
    "import plastock as pstk\n",
    "\n",
    "from plastockconf import name_zones, name_frequentation, name_situation\n",
    "from plastockconf import name_substrate, name_distance, table_css_styles, table_css_styles_top\n",
    "\n",
    "from plastock import add_table_to_page, capitalize_x_tick_labels, capitalize_x_and_y_axis_labels, capitalize_legend_components, attribute_summary\n",
    "\n",
    "import reportclass as rc\n",
    "\n",
    "section = \"DP\"\n",
    "page = \"\"\n",
    "\n",
    "def make_exportable(data, file_name, cmap='YlOrBr'):\n",
    "    data.fillna(0, inplace=True)\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    sns.heatmap(data=data, vmin=0, vmax=1, cmap=cmap, annot=True, fmt='.2', annot_kws={'size':10}, ax=ax, cbar=False)\n",
    "    plt.tight_layout()\n",
    "    ax.tick_params(which='both', axis='both', bottom=False, left=False)\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "glue('blank_caption', \" \", display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdbc60-f1ba-4a3e-98af-87384a1b594e",
   "metadata": {},
   "source": [
    "## Déchets sauvages\n",
    "\n",
    "### Position\n",
    "\n",
    "Les enquêtes sur les déchets de plage menées précédemment sur le lac considéraient la plage comme une unité à part entière. Dans Plastock, chaque plage a été divisée en deux sections, la ligne d'eau et la plage sèche. Pour comparer les données de Plastock aux résultats précédents et à d'autres études de ce type, les résultats de Plastock doivent être transformés en une section pour une plage. En d'autres termes, nous devons combiner la surface des deux sections pour chaque échantillon. Le nombre d'objets par échantillon est ensuite divisé par la surface commune des deux sections.\n",
    "\n",
    "### Substrat\n",
    "\n",
    "Certains échantillons ont des substrats différents pour chaque section de chaque plage. Les sections doivent avoir le même substrat pour chaque section si nous voulons compter la plage comme une unité entière. Pour les douze échantillons qui répondent à ce critère, le substrat a été modifié de 4 à 2 (du gravier au sable grossier).\n",
    "\n",
    "### Objets\n",
    "\n",
    "La variété des objets trouvés lors de chaque enquête est autant le reflet des déchets sur le terrain que du temps alloué aux participants pour compter, trier et identifier chaque objet collecté. Par conséquent, les seuls codes ou objets pris en considération sont ceux qui ont été identifiés pendant Plastock. Les données précédentes sont filtrées pour les mêmes codes.\n",
    "\n",
    "#### Combinaison d'objets similaires\n",
    "\n",
    "Certaines catégories d'objets sont combinées. Cela signifie que nous modifions le code de certains éléments pour refléter les tendances de l'échantillonnage et tenir compte des différentes interprétations du protocole. Le tableau suivant résume la façon dont les codes sont combinés :\n",
    "\n",
    "1. Gfrags: g80, g79, g78, g77, g76, g75\n",
    "2. Gfoams: G81, G82, G76\n",
    "3. Gcaps: G21, G22, G23, G24\n",
    "\n",
    "Gfrags comprend toutes les formes de plastiques fragmentés de plus de 5 mm, Gfoams toutes les tailles de polystyrène expansé et Gcaps tous les bouchons en plastique et les anneaux en plastique qui accompagnent chaque bouchon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80c6173-3821-493a-aa58-3112f5192619",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! read in data !\n",
    "# survey data\n",
    "new_data = pd.read_csv(\"data/end_pipe/macro_current.csv\")\n",
    "\n",
    "# the position, substrate, time, area, length for each sample in the data\n",
    "# ! there are samples that have different substrates on the same sample_id.!\n",
    "# that is position 1 has a different substrate than position 2. for litter \n",
    "# data and comparing to previous results this is unimportant. The value to\n",
    "# compare is the total survey divided by the length or the area. This needs\n",
    "# to be accounted for and changes made to certain samples.\n",
    "beach_data = pd.read_csv(\"data/end_pipe/pstock_beaches_current.csv\")\n",
    "\n",
    "\n",
    "# the feature columns of the survey data that are not dependent on the\n",
    "# position or substrat variables. they are indexed on the Plage column\n",
    "# one row for each sample location\n",
    "beach_datax = pd.read_csv(\"data/end_pipe/asl_beaches.csv\").set_index('Plage')\n",
    "\n",
    "# The code definitions\n",
    "codes = pd.read_csv('data/end_pipe/codes.csv').set_index('code')\n",
    "\n",
    "# the regional labels for each survey location\n",
    "regions = pd.read_csv(\"data/end_pipe/lac_leman_regions.csv\")\n",
    "regions.set_index('slug', drop=True, inplace=True)\n",
    "\n",
    "# the city name of the survey locations\n",
    "city_map = pd.read_csv('data/end_pipe/city_map.csv')\n",
    "city_map.set_index('slug', inplace=True)\n",
    "\n",
    "# translation of common terms into french, german and english\n",
    "language_maps = rc.language_maps()\n",
    "\n",
    "new_column_names = {\n",
    "    \"Position\":\"position\",\n",
    "    \"Substrat\":\"substrat\",\n",
    "    \"Date\":\"date\",\n",
    "    \"Code\":\"code\",\n",
    "    \"Quantité\":\"quantité\",\n",
    "    \"Aire\":\"area\"\n",
    "}\n",
    "\n",
    "# import data and assign new column names and sample_id\n",
    "# the sample_id is the tuple (location, date). Each row\n",
    "# is a unique combinantion of sample_id and code\n",
    "work_data = new_data[[\"Plage\", *new_column_names.keys()]].copy()\n",
    "work_data.rename(columns=new_column_names, inplace=True)\n",
    "work_data[\"slug\"] = work_data.Plage.apply(lambda x: slugify(x))\n",
    "work_data[\"échantillon\"] = list(zip(work_data.slug, work_data['date']))\n",
    "work_data['date'] = pd.to_datetime(work_data[\"date\"], format=\"mixed\", dayfirst=True)\n",
    "work_data.dropna(inplace=True)\n",
    "\n",
    "# type the columns\n",
    "work_data[[\"position\", \"substrat\"]] = work_data[[\"position\", \"substrat\"]].astype(\"int\")\n",
    "work_data['échantillon'] = work_data['échantillon'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf97495-c34a-42a0-be3a-70a8ab4e33d0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "voi = \"substrat\"\n",
    "vals = \"pcs/m²\"\n",
    "code = \"G27\"\n",
    "loc_dates_t = [\"('clarens', '16.01.2022')\", \"('amphion', '01.02.2022')\"]\n",
    "\n",
    "gfrags_c = codes.loc[codes.parent_code == 'Gfrags'].index\n",
    "\n",
    "start_amph_s = new_data[(new_data.Plage == \"Amphion\")&(new_data[\"Date\"] == \"01.02.2022\")&(new_data.Code == \"G27\")]\n",
    "start_amph_c = new_data[(new_data.Plage == \"Amphion\")&(new_data[\"Date\"] == \"01.02.2022\")&(new_data.Code.isin(gfrags_c))]\n",
    "start_clarens_s = new_data[(new_data.Plage == \"Clarens\")&(new_data[\"Date\"] == '16.01.2022')&(new_data.Code == \"G27\")]\n",
    "start_clarens_c = new_data[(new_data.Plage == \"Clarens\")&(new_data[\"Date\"] == '16.01.2022')&(new_data.Code.isin(gfrags_c))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96cae44-9c27-48fa-95c5-69361bd4b0f8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_8bca1 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_8bca1 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_8bca1 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_8bca1 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_8bca1 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_8bca1 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_8bca1\">\n  <caption>Les résultats de l'échantillon avant la combinaison des codes, des substrats et de la position</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_8bca1_level0_col0\" class=\"col_heading level0 col0\" >Plage</th>\n      <th id=\"T_8bca1_level0_col1\" class=\"col_heading level0 col1\" >Aire</th>\n      <th id=\"T_8bca1_level0_col2\" class=\"col_heading level0 col2\" >Position</th>\n      <th id=\"T_8bca1_level0_col3\" class=\"col_heading level0 col3\" >Substrat</th>\n      <th id=\"T_8bca1_level0_col4\" class=\"col_heading level0 col4\" >Date</th>\n      <th id=\"T_8bca1_level0_col5\" class=\"col_heading level0 col5\" >Code</th>\n      <th id=\"T_8bca1_level0_col6\" class=\"col_heading level0 col6\" >Quantité</th>\n      <th id=\"T_8bca1_level0_col7\" class=\"col_heading level0 col7\" >density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_8bca1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_8bca1_row0_col0\" class=\"data row0 col0\" >Amphion</td>\n      <td id=\"T_8bca1_row0_col1\" class=\"data row0 col1\" >342</td>\n      <td id=\"T_8bca1_row0_col2\" class=\"data row0 col2\" >2</td>\n      <td id=\"T_8bca1_row0_col3\" class=\"data row0 col3\" >4,00</td>\n      <td id=\"T_8bca1_row0_col4\" class=\"data row0 col4\" >01.02.2022</td>\n      <td id=\"T_8bca1_row0_col5\" class=\"data row0 col5\" >G27</td>\n      <td id=\"T_8bca1_row0_col6\" class=\"data row0 col6\" >4</td>\n      <td id=\"T_8bca1_row0_col7\" class=\"data row0 col7\" >0,01</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_8bca1_row1_col0\" class=\"data row1 col0\" >Amphion</td>\n      <td id=\"T_8bca1_row1_col1\" class=\"data row1 col1\" >98</td>\n      <td id=\"T_8bca1_row1_col2\" class=\"data row1 col2\" >1</td>\n      <td id=\"T_8bca1_row1_col3\" class=\"data row1 col3\" >4,00</td>\n      <td id=\"T_8bca1_row1_col4\" class=\"data row1 col4\" >01.02.2022</td>\n      <td id=\"T_8bca1_row1_col5\" class=\"data row1 col5\" >G78</td>\n      <td id=\"T_8bca1_row1_col6\" class=\"data row1 col6\" >8</td>\n      <td id=\"T_8bca1_row1_col7\" class=\"data row1 col7\" >0,08</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_8bca1_row2_col0\" class=\"data row2 col0\" >Amphion</td>\n      <td id=\"T_8bca1_row2_col1\" class=\"data row2 col1\" >342</td>\n      <td id=\"T_8bca1_row2_col2\" class=\"data row2 col2\" >2</td>\n      <td id=\"T_8bca1_row2_col3\" class=\"data row2 col3\" >4,00</td>\n      <td id=\"T_8bca1_row2_col4\" class=\"data row2 col4\" >01.02.2022</td>\n      <td id=\"T_8bca1_row2_col5\" class=\"data row2 col5\" >G78</td>\n      <td id=\"T_8bca1_row2_col6\" class=\"data row2 col6\" >86</td>\n      <td id=\"T_8bca1_row2_col7\" class=\"data row2 col7\" >0,25</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_8bca1_row3_col0\" class=\"data row3 col0\" >Amphion</td>\n      <td id=\"T_8bca1_row3_col1\" class=\"data row3 col1\" >98</td>\n      <td id=\"T_8bca1_row3_col2\" class=\"data row3 col2\" >1</td>\n      <td id=\"T_8bca1_row3_col3\" class=\"data row3 col3\" >4,00</td>\n      <td id=\"T_8bca1_row3_col4\" class=\"data row3 col4\" >01.02.2022</td>\n      <td id=\"T_8bca1_row3_col5\" class=\"data row3 col5\" >G79</td>\n      <td id=\"T_8bca1_row3_col6\" class=\"data row3 col6\" >12</td>\n      <td id=\"T_8bca1_row3_col7\" class=\"data row3 col7\" >0,12</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_8bca1_row4_col0\" class=\"data row4 col0\" >Amphion</td>\n      <td id=\"T_8bca1_row4_col1\" class=\"data row4 col1\" >342</td>\n      <td id=\"T_8bca1_row4_col2\" class=\"data row4 col2\" >2</td>\n      <td id=\"T_8bca1_row4_col3\" class=\"data row4 col3\" >4,00</td>\n      <td id=\"T_8bca1_row4_col4\" class=\"data row4 col4\" >01.02.2022</td>\n      <td id=\"T_8bca1_row4_col5\" class=\"data row4 col5\" >G79</td>\n      <td id=\"T_8bca1_row4_col6\" class=\"data row4 col6\" >225</td>\n      <td id=\"T_8bca1_row4_col7\" class=\"data row4 col7\" >0,66</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_8bca1_row5_col0\" class=\"data row5 col0\" >Amphion</td>\n      <td id=\"T_8bca1_row5_col1\" class=\"data row5 col1\" >342</td>\n      <td id=\"T_8bca1_row5_col2\" class=\"data row5 col2\" >2</td>\n      <td id=\"T_8bca1_row5_col3\" class=\"data row5 col3\" >4,00</td>\n      <td id=\"T_8bca1_row5_col4\" class=\"data row5 col4\" >01.02.2022</td>\n      <td id=\"T_8bca1_row5_col5\" class=\"data row5 col5\" >G79</td>\n      <td id=\"T_8bca1_row5_col6\" class=\"data row5 col6\" >3</td>\n      <td id=\"T_8bca1_row5_col7\" class=\"data row5 col7\" >0,01</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_8bca1_row6_col0\" class=\"data row6 col0\" >Clarens</td>\n      <td id=\"T_8bca1_row6_col1\" class=\"data row6 col1\" >273</td>\n      <td id=\"T_8bca1_row6_col2\" class=\"data row6 col2\" >2</td>\n      <td id=\"T_8bca1_row6_col3\" class=\"data row6 col3\" >2,00</td>\n      <td id=\"T_8bca1_row6_col4\" class=\"data row6 col4\" >16.01.2022</td>\n      <td id=\"T_8bca1_row6_col5\" class=\"data row6 col5\" >G78</td>\n      <td id=\"T_8bca1_row6_col6\" class=\"data row6 col6\" >5</td>\n      <td id=\"T_8bca1_row6_col7\" class=\"data row6 col7\" >0,02</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_8bca1_row7_col0\" class=\"data row7 col0\" >Clarens</td>\n      <td id=\"T_8bca1_row7_col1\" class=\"data row7 col1\" >67</td>\n      <td id=\"T_8bca1_row7_col2\" class=\"data row7 col2\" >1</td>\n      <td id=\"T_8bca1_row7_col3\" class=\"data row7 col3\" >4,00</td>\n      <td id=\"T_8bca1_row7_col4\" class=\"data row7 col4\" >16.01.2022</td>\n      <td id=\"T_8bca1_row7_col5\" class=\"data row7 col5\" >G27</td>\n      <td id=\"T_8bca1_row7_col6\" class=\"data row7 col6\" >3</td>\n      <td id=\"T_8bca1_row7_col7\" class=\"data row7 col7\" >0,04</td>\n    </tr>\n    <tr>\n      <th id=\"T_8bca1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_8bca1_row8_col0\" class=\"data row8 col0\" >Clarens</td>\n      <td id=\"T_8bca1_row8_col1\" class=\"data row8 col1\" >273</td>\n      <td id=\"T_8bca1_row8_col2\" class=\"data row8 col2\" >2</td>\n      <td id=\"T_8bca1_row8_col3\" class=\"data row8 col3\" >2,00</td>\n      <td id=\"T_8bca1_row8_col4\" class=\"data row8 col4\" >16.01.2022</td>\n      <td id=\"T_8bca1_row8_col5\" class=\"data row8 col5\" >G27</td>\n      <td id=\"T_8bca1_row8_col6\" class=\"data row8 col6\" >8</td>\n      <td id=\"T_8bca1_row8_col7\" class=\"data row8 col7\" >0,03</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x7fbb1c6415e0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_data = pd.concat([start_amph_s, start_amph_c, start_clarens_c, start_clarens_s])\n",
    "start_data['density'] = start_data[\"Quantité\"]/start_data[\"Aire\"]\n",
    "# start_data.loc[start_data.Code.isin(gfrags_c), 'Code'] = 'Gfrags'\n",
    "sd = start_data[[\"Plage\", \"Aire\", \"Position\", \"Substrat\", \"Date\", \"Code\", \"Quantité\", \"density\"]]\n",
    "sd.reset_index(inplace=True, drop=True)\n",
    "\n",
    "caption = \"Les résultats de l'échantillon avant la combinaison des codes, des substrats et de la position\"\n",
    "sd = sd.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption)\n",
    "glue(\"start_data\", sd, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9da2c5-3282-4539-b229-c2b05dca2e3d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! locate all the duplicate values by sample id and area !\n",
    "# this gives a data frame that has the position and area for\n",
    "# each sample_id\n",
    "total_area_dup = work_data.drop_duplicates(['échantillon', 'area'])\n",
    "\n",
    "# ! combine the surface areas of the position vectors !\n",
    "# sum of the areas for each position at each sample\n",
    "# use the sample_id as index and sum the areas for each postition at each sample\n",
    "total_area = total_area_dup.groupby(['échantillon', 'Plage'], as_index=False).area.sum()\n",
    "\n",
    "# sum of the areas for each position at each sample\n",
    "# use the sample_id as index and sum the areas for each postition at each sample\n",
    "total_area = total_area[['échantillon', 'area']].set_index('échantillon', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98818780-7c53-4e28-82a9-31cb72314d22",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# apply the total area to the work_data, index on sample_id\n",
    "work_data['area_c'] = work_data['échantillon'].apply(lambda x: total_area.loc[x])\n",
    "work_data['area'] = work_data.area_c\n",
    "work_data.drop('area_c', axis=1, inplace=True)\n",
    "# the code total per sample with the combined area\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'quantité', 'code'], as_index=False)['quantité'].sum()\n",
    "work_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f3194a-2397-4d31-b819-13a86eab9776",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_49d72 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_49d72 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_49d72 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_49d72 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_49d72 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_49d72 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_49d72\">\n  <caption>La variable position est supprimée et les surfaces sont combinées pour chaque position de chaque échantillon. Cependant, le substrat à Clarens n'est pas corrigé.</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_49d72_level0_col0\" class=\"col_heading level0 col0\" >échantillon</th>\n      <th id=\"T_49d72_level0_col1\" class=\"col_heading level0 col1\" >Plage</th>\n      <th id=\"T_49d72_level0_col2\" class=\"col_heading level0 col2\" >substrat</th>\n      <th id=\"T_49d72_level0_col3\" class=\"col_heading level0 col3\" >date</th>\n      <th id=\"T_49d72_level0_col4\" class=\"col_heading level0 col4\" >area</th>\n      <th id=\"T_49d72_level0_col5\" class=\"col_heading level0 col5\" >slug</th>\n      <th id=\"T_49d72_level0_col6\" class=\"col_heading level0 col6\" >code</th>\n      <th id=\"T_49d72_level0_col7\" class=\"col_heading level0 col7\" >quantité</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_49d72_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_49d72_row0_col0\" class=\"data row0 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_49d72_row0_col1\" class=\"data row0 col1\" >Amphion</td>\n      <td id=\"T_49d72_row0_col2\" class=\"data row0 col2\" >4</td>\n      <td id=\"T_49d72_row0_col3\" class=\"data row0 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_49d72_row0_col4\" class=\"data row0 col4\" >440</td>\n      <td id=\"T_49d72_row0_col5\" class=\"data row0 col5\" >amphion</td>\n      <td id=\"T_49d72_row0_col6\" class=\"data row0 col6\" >G79</td>\n      <td id=\"T_49d72_row0_col7\" class=\"data row0 col7\" >3</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_49d72_row1_col0\" class=\"data row1 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_49d72_row1_col1\" class=\"data row1 col1\" >Amphion</td>\n      <td id=\"T_49d72_row1_col2\" class=\"data row1 col2\" >4</td>\n      <td id=\"T_49d72_row1_col3\" class=\"data row1 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_49d72_row1_col4\" class=\"data row1 col4\" >440</td>\n      <td id=\"T_49d72_row1_col5\" class=\"data row1 col5\" >amphion</td>\n      <td id=\"T_49d72_row1_col6\" class=\"data row1 col6\" >G27</td>\n      <td id=\"T_49d72_row1_col7\" class=\"data row1 col7\" >4</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_49d72_row2_col0\" class=\"data row2 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_49d72_row2_col1\" class=\"data row2 col1\" >Amphion</td>\n      <td id=\"T_49d72_row2_col2\" class=\"data row2 col2\" >4</td>\n      <td id=\"T_49d72_row2_col3\" class=\"data row2 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_49d72_row2_col4\" class=\"data row2 col4\" >440</td>\n      <td id=\"T_49d72_row2_col5\" class=\"data row2 col5\" >amphion</td>\n      <td id=\"T_49d72_row2_col6\" class=\"data row2 col6\" >G78</td>\n      <td id=\"T_49d72_row2_col7\" class=\"data row2 col7\" >8</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_49d72_row3_col0\" class=\"data row3 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_49d72_row3_col1\" class=\"data row3 col1\" >Amphion</td>\n      <td id=\"T_49d72_row3_col2\" class=\"data row3 col2\" >4</td>\n      <td id=\"T_49d72_row3_col3\" class=\"data row3 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_49d72_row3_col4\" class=\"data row3 col4\" >440</td>\n      <td id=\"T_49d72_row3_col5\" class=\"data row3 col5\" >amphion</td>\n      <td id=\"T_49d72_row3_col6\" class=\"data row3 col6\" >G79</td>\n      <td id=\"T_49d72_row3_col7\" class=\"data row3 col7\" >12</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_49d72_row4_col0\" class=\"data row4 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_49d72_row4_col1\" class=\"data row4 col1\" >Amphion</td>\n      <td id=\"T_49d72_row4_col2\" class=\"data row4 col2\" >4</td>\n      <td id=\"T_49d72_row4_col3\" class=\"data row4 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_49d72_row4_col4\" class=\"data row4 col4\" >440</td>\n      <td id=\"T_49d72_row4_col5\" class=\"data row4 col5\" >amphion</td>\n      <td id=\"T_49d72_row4_col6\" class=\"data row4 col6\" >G78</td>\n      <td id=\"T_49d72_row4_col7\" class=\"data row4 col7\" >86</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_49d72_row5_col0\" class=\"data row5 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_49d72_row5_col1\" class=\"data row5 col1\" >Amphion</td>\n      <td id=\"T_49d72_row5_col2\" class=\"data row5 col2\" >4</td>\n      <td id=\"T_49d72_row5_col3\" class=\"data row5 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_49d72_row5_col4\" class=\"data row5 col4\" >440</td>\n      <td id=\"T_49d72_row5_col5\" class=\"data row5 col5\" >amphion</td>\n      <td id=\"T_49d72_row5_col6\" class=\"data row5 col6\" >G79</td>\n      <td id=\"T_49d72_row5_col7\" class=\"data row5 col7\" >225</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_49d72_row6_col0\" class=\"data row6 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_49d72_row6_col1\" class=\"data row6 col1\" >Clarens</td>\n      <td id=\"T_49d72_row6_col2\" class=\"data row6 col2\" >2</td>\n      <td id=\"T_49d72_row6_col3\" class=\"data row6 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_49d72_row6_col4\" class=\"data row6 col4\" >340</td>\n      <td id=\"T_49d72_row6_col5\" class=\"data row6 col5\" >clarens</td>\n      <td id=\"T_49d72_row6_col6\" class=\"data row6 col6\" >G78</td>\n      <td id=\"T_49d72_row6_col7\" class=\"data row6 col7\" >5</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_49d72_row7_col0\" class=\"data row7 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_49d72_row7_col1\" class=\"data row7 col1\" >Clarens</td>\n      <td id=\"T_49d72_row7_col2\" class=\"data row7 col2\" >2</td>\n      <td id=\"T_49d72_row7_col3\" class=\"data row7 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_49d72_row7_col4\" class=\"data row7 col4\" >340</td>\n      <td id=\"T_49d72_row7_col5\" class=\"data row7 col5\" >clarens</td>\n      <td id=\"T_49d72_row7_col6\" class=\"data row7 col6\" >G27</td>\n      <td id=\"T_49d72_row7_col7\" class=\"data row7 col7\" >8</td>\n    </tr>\n    <tr>\n      <th id=\"T_49d72_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_49d72_row8_col0\" class=\"data row8 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_49d72_row8_col1\" class=\"data row8 col1\" >Clarens</td>\n      <td id=\"T_49d72_row8_col2\" class=\"data row8 col2\" >4</td>\n      <td id=\"T_49d72_row8_col3\" class=\"data row8 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_49d72_row8_col4\" class=\"data row8 col4\" >340</td>\n      <td id=\"T_49d72_row8_col5\" class=\"data row8 col5\" >clarens</td>\n      <td id=\"T_49d72_row8_col6\" class=\"data row8 col6\" >G27</td>\n      <td id=\"T_49d72_row8_col7\" class=\"data row8 col7\" >3</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x7fba8cd0e400>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_2"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (work_data[\"échantillon\"].isin(loc_dates_t))&(work_data.code.isin([*gfrags_c, code]))\n",
    "\n",
    "test = work_data[mask].copy()\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "caption = \"La variable position est supprimée et les surfaces sont combinées pour chaque position de chaque échantillon. Cependant, le substrat à Clarens n'est pas corrigé.\"\n",
    "sd_2 = test.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption)\n",
    "glue(\"start_data_2\", sd_2, display=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee52963c-eb6d-451f-87b4-9069b305456b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the code total per sample with the combined area\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'code'], as_index=False)['quantité'].sum()\n",
    "\n",
    "# add the regional component\n",
    "work_data['region'] = work_data.slug.apply(lambda x: regions.loc[x, 'alabel'])\n",
    "\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'quantité', 'code'], as_index=False)['quantité'].sum()\n",
    "# get the pcs/m²  for each object at each sample\n",
    "work_data['pcs/m²'] = work_data['quantité']/work_data.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8c53a7-4cfc-4552-a00a-d196f71bd337",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! there are samples that have different substrates on the same sample_id.!\n",
    "# there should be one substrate per sample_id. Identify the locations that have duplicate values\n",
    "some_data = work_data.copy()\n",
    "groupby = ['échantillon', voi]\n",
    "data = some_data.groupby(groupby, as_index=False)[vals].sum()\n",
    "\n",
    "# the samples with more than one substrate\n",
    "dd = data[data['échantillon'].duplicated()].copy()\n",
    "# select all the duplicated sample_ids from the work_data\n",
    "duplicated = work_data[work_data['échantillon'].isin(dd['échantillon'].unique())].copy()\n",
    "# select all the duplicated sample_ids from the work_data\n",
    "# change the substrat to [2]\n",
    "duplicated['substrat'] = 2 \n",
    "\n",
    "# select all the values that are not duplicated\n",
    "not_duplicated = work_data[~(work_data['échantillon'].isin(dd['échantillon'].unique()))].copy()\n",
    "\n",
    "# put it back together again\n",
    "work_data = pd.concat([duplicated, not_duplicated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39363708-fbc0-4484-8c2b-e99f4ce4cce3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_127cd tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_127cd tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_127cd tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_127cd th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_127cd td {\n  padding: 4px;\n  text-align: center;\n}\n#T_127cd caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_127cd\">\n  <caption>Après avoir combiné les codes et supprimé la variable de la position, il reste des codes en double pour l'échantillon de Clarens.</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_127cd_level0_col0\" class=\"col_heading level0 col0\" >échantillon</th>\n      <th id=\"T_127cd_level0_col1\" class=\"col_heading level0 col1\" >Plage</th>\n      <th id=\"T_127cd_level0_col2\" class=\"col_heading level0 col2\" >substrat</th>\n      <th id=\"T_127cd_level0_col3\" class=\"col_heading level0 col3\" >date</th>\n      <th id=\"T_127cd_level0_col4\" class=\"col_heading level0 col4\" >area</th>\n      <th id=\"T_127cd_level0_col5\" class=\"col_heading level0 col5\" >slug</th>\n      <th id=\"T_127cd_level0_col6\" class=\"col_heading level0 col6\" >code</th>\n      <th id=\"T_127cd_level0_col7\" class=\"col_heading level0 col7\" >quantité</th>\n      <th id=\"T_127cd_level0_col8\" class=\"col_heading level0 col8\" >pcs/m²</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_127cd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_127cd_row0_col0\" class=\"data row0 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_127cd_row0_col1\" class=\"data row0 col1\" >Clarens</td>\n      <td id=\"T_127cd_row0_col2\" class=\"data row0 col2\" >2</td>\n      <td id=\"T_127cd_row0_col3\" class=\"data row0 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_127cd_row0_col4\" class=\"data row0 col4\" >340</td>\n      <td id=\"T_127cd_row0_col5\" class=\"data row0 col5\" >clarens</td>\n      <td id=\"T_127cd_row0_col6\" class=\"data row0 col6\" >G78</td>\n      <td id=\"T_127cd_row0_col7\" class=\"data row0 col7\" >5</td>\n      <td id=\"T_127cd_row0_col8\" class=\"data row0 col8\" >0,01</td>\n    </tr>\n    <tr>\n      <th id=\"T_127cd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_127cd_row1_col0\" class=\"data row1 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_127cd_row1_col1\" class=\"data row1 col1\" >Clarens</td>\n      <td id=\"T_127cd_row1_col2\" class=\"data row1 col2\" >2</td>\n      <td id=\"T_127cd_row1_col3\" class=\"data row1 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_127cd_row1_col4\" class=\"data row1 col4\" >340</td>\n      <td id=\"T_127cd_row1_col5\" class=\"data row1 col5\" >clarens</td>\n      <td id=\"T_127cd_row1_col6\" class=\"data row1 col6\" >G27</td>\n      <td id=\"T_127cd_row1_col7\" class=\"data row1 col7\" >8</td>\n      <td id=\"T_127cd_row1_col8\" class=\"data row1 col8\" >0,02</td>\n    </tr>\n    <tr>\n      <th id=\"T_127cd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_127cd_row2_col0\" class=\"data row2 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_127cd_row2_col1\" class=\"data row2 col1\" >Clarens</td>\n      <td id=\"T_127cd_row2_col2\" class=\"data row2 col2\" >2</td>\n      <td id=\"T_127cd_row2_col3\" class=\"data row2 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_127cd_row2_col4\" class=\"data row2 col4\" >340</td>\n      <td id=\"T_127cd_row2_col5\" class=\"data row2 col5\" >clarens</td>\n      <td id=\"T_127cd_row2_col6\" class=\"data row2 col6\" >G27</td>\n      <td id=\"T_127cd_row2_col7\" class=\"data row2 col7\" >3</td>\n      <td id=\"T_127cd_row2_col8\" class=\"data row2 col8\" >0,01</td>\n    </tr>\n    <tr>\n      <th id=\"T_127cd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_127cd_row3_col0\" class=\"data row3 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_127cd_row3_col1\" class=\"data row3 col1\" >Amphion</td>\n      <td id=\"T_127cd_row3_col2\" class=\"data row3 col2\" >4</td>\n      <td id=\"T_127cd_row3_col3\" class=\"data row3 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_127cd_row3_col4\" class=\"data row3 col4\" >440</td>\n      <td id=\"T_127cd_row3_col5\" class=\"data row3 col5\" >amphion</td>\n      <td id=\"T_127cd_row3_col6\" class=\"data row3 col6\" >G27</td>\n      <td id=\"T_127cd_row3_col7\" class=\"data row3 col7\" >4</td>\n      <td id=\"T_127cd_row3_col8\" class=\"data row3 col8\" >0,01</td>\n    </tr>\n    <tr>\n      <th id=\"T_127cd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_127cd_row4_col0\" class=\"data row4 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_127cd_row4_col1\" class=\"data row4 col1\" >Amphion</td>\n      <td id=\"T_127cd_row4_col2\" class=\"data row4 col2\" >4</td>\n      <td id=\"T_127cd_row4_col3\" class=\"data row4 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_127cd_row4_col4\" class=\"data row4 col4\" >440</td>\n      <td id=\"T_127cd_row4_col5\" class=\"data row4 col5\" >amphion</td>\n      <td id=\"T_127cd_row4_col6\" class=\"data row4 col6\" >G78</td>\n      <td id=\"T_127cd_row4_col7\" class=\"data row4 col7\" >94</td>\n      <td id=\"T_127cd_row4_col8\" class=\"data row4 col8\" >0,21</td>\n    </tr>\n    <tr>\n      <th id=\"T_127cd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_127cd_row5_col0\" class=\"data row5 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_127cd_row5_col1\" class=\"data row5 col1\" >Amphion</td>\n      <td id=\"T_127cd_row5_col2\" class=\"data row5 col2\" >4</td>\n      <td id=\"T_127cd_row5_col3\" class=\"data row5 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_127cd_row5_col4\" class=\"data row5 col4\" >440</td>\n      <td id=\"T_127cd_row5_col5\" class=\"data row5 col5\" >amphion</td>\n      <td id=\"T_127cd_row5_col6\" class=\"data row5 col6\" >G79</td>\n      <td id=\"T_127cd_row5_col7\" class=\"data row5 col7\" >240</td>\n      <td id=\"T_127cd_row5_col8\" class=\"data row5 col8\" >0,55</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x7fba8cd0e4f0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_3"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (work_data[\"échantillon\"].isin(loc_dates_t))&(work_data.code.isin([*gfrags_c, code]))\n",
    "\n",
    "test = work_data[mask].copy()\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "caption = \"Après avoir combiné les codes et supprimé la variable de la position, il reste des codes en double pour l'échantillon de Clarens.\"\n",
    "sd_3 = test.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption)\n",
    "glue(\"start_data_3\", sd_3, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0694d8-9f5f-4ad8-929a-49804d47fd8d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! valid codes and definitions !\n",
    "# plastock did not use the same inventory as iqaasl\n",
    "# here we select only the codes in the plastock inventory\n",
    "pcodes = work_data.code.unique()\n",
    "\n",
    "# identify and remove codes for which there is no defintion\n",
    "# if the code is not defined then it can not be used\n",
    "t = [x for x in pcodes if x not in codes.index]\n",
    "wd_ni = work_data[~work_data.code.isin(t)].copy()\n",
    "\n",
    "# ! aggregating to Gfrags, Gcaps and Gfoams !\n",
    "# these items are not well divided into the composite subgroups\n",
    "# for example people often know what a cap is, but whether it \n",
    "# comes from a drink bottle or other type is not well considered\n",
    "# we combine the subcategories into more comprehensive groups.\n",
    "ti = rc.use_gfrags_gfoams_gcaps(wd_ni, codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b312536-835e-49d2-9c4c-4ffbee2c6280",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! groupby the sample id and code otherwise there are duplicate codes\n",
    "# after aggregating to Gfrags etc..\n",
    "work_data = ti.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "work_data['pcs/m²'] = work_data['quantité']/work_data['area']\n",
    "\n",
    "# accounting for objects not found at a sample:\n",
    "# the codes that were indentified are the unique codes\n",
    "# in the set of data, they are the 'inventory'\n",
    "codes_ip = work_data.code.unique()\n",
    "# the unique samples by id\n",
    "loc_dates = work_data['échantillon'].unique()\n",
    "\n",
    "# a copy for itterating\n",
    "wd = work_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f20caec-1c55-46df-afa6-1c2b0f1b36f6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_ba696 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_ba696 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_ba696 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_ba696 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_ba696 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_ba696 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_ba696\">\n  <caption>La densité de l'échantillon si les zones et les substrats ne sont pas combinés pour chaque échantillon. Le résultat pour chaque échantillon est la moyenne des différents résultats pour les différentes positions et substrats pour chaque échantillon.</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_ba696_level0_col0\" class=\"col_heading level0 col0\" >Plage</th>\n      <th id=\"T_ba696_level0_col1\" class=\"col_heading level0 col1\" >Date</th>\n      <th id=\"T_ba696_level0_col2\" class=\"col_heading level0 col2\" >Code</th>\n      <th id=\"T_ba696_level0_col3\" class=\"col_heading level0 col3\" >density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_ba696_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_ba696_row0_col0\" class=\"data row0 col0\" >Amphion</td>\n      <td id=\"T_ba696_row0_col1\" class=\"data row0 col1\" >01.02.2022</td>\n      <td id=\"T_ba696_row0_col2\" class=\"data row0 col2\" >G27</td>\n      <td id=\"T_ba696_row0_col3\" class=\"data row0 col3\" >0,01</td>\n    </tr>\n    <tr>\n      <th id=\"T_ba696_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_ba696_row1_col0\" class=\"data row1 col0\" >Amphion</td>\n      <td id=\"T_ba696_row1_col1\" class=\"data row1 col1\" >01.02.2022</td>\n      <td id=\"T_ba696_row1_col2\" class=\"data row1 col2\" >Gfrags</td>\n      <td id=\"T_ba696_row1_col3\" class=\"data row1 col3\" >0,56</td>\n    </tr>\n    <tr>\n      <th id=\"T_ba696_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_ba696_row2_col0\" class=\"data row2 col0\" >Clarens</td>\n      <td id=\"T_ba696_row2_col1\" class=\"data row2 col1\" >16.01.2022</td>\n      <td id=\"T_ba696_row2_col2\" class=\"data row2 col2\" >G27</td>\n      <td id=\"T_ba696_row2_col3\" class=\"data row2 col3\" >0,04</td>\n    </tr>\n    <tr>\n      <th id=\"T_ba696_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_ba696_row3_col0\" class=\"data row3 col0\" >Clarens</td>\n      <td id=\"T_ba696_row3_col1\" class=\"data row3 col1\" >16.01.2022</td>\n      <td id=\"T_ba696_row3_col2\" class=\"data row3 col2\" >Gfrags</td>\n      <td id=\"T_ba696_row3_col3\" class=\"data row3 col3\" >0,02</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x7fba8ccf89d0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_4"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_data.loc[start_data.Code.isin(gfrags_c), 'Code'] = 'Gfrags'\n",
    "\n",
    "start_data = start_data.groupby([\"Plage\", \"Date\", \"Aire\", \"Code\"], as_index=False)[\"Quantité\"].sum()\n",
    "\n",
    "start_data['density'] = start_data[\"Quantité\"]/start_data.Aire\n",
    "sd_x = start_data.groupby([\"Plage\", \"Date\", \"Code\"], as_index=False).density.mean()\n",
    "\n",
    "caption = \"La densité de l'échantillon si les zones et les substrats ne sont pas combinés pour chaque échantillon. Le résultat pour chaque échantillon est la moyenne des différents résultats pour les différentes positions et substrats pour chaque échantillon.\"\n",
    "sd_x = sd_x.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption)\n",
    "glue(\"start_data_4\", sd_x, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dcec826-504d-4ddd-86dc-2b664bc8ef41",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# a copy for itterating\n",
    "wd = work_data.copy()\n",
    "\n",
    "rows = []\n",
    "for a_loc in loc_dates:\n",
    "    r = wd.loc[wd['échantillon'] == a_loc].copy()\n",
    "    r.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    t = r.loc[0][['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug']].values\n",
    "    asamp = [x for x in t]\n",
    "    used_codes = r.code.unique()\n",
    "    unused = [x for x in codes_ip if x not in used_codes]\n",
    "    for element in unused:\n",
    "        arow = [*asamp, element, 0, 0]\n",
    "        rows.append(arow)\n",
    "        \n",
    "\n",
    "# now all the data has the same number of records per sample\n",
    "# for each sample we can now say what was found and what was\n",
    "# not found with respect to all the results\n",
    "work_x = pd.DataFrame(rows, columns=['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug', 'code', 'quantité', 'pcs/m²'])\n",
    "work_data = pd.concat([work_x, work_data])\n",
    "\n",
    "\n",
    "# add the regional component\n",
    "work_data['region'] = work_data.slug.apply(lambda x: regions.loc[x, 'alabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca1a66c-911a-496e-ae2d-277bee82d5f6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_9e2f9 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_9e2f9 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_9e2f9 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_9e2f9 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_9e2f9 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_9e2f9 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_9e2f9\">\n  <caption>The density of sample if the areas are combined. The result for each sample is the sum of the different results for the different positions and substrates for each sample.</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_9e2f9_level0_col0\" class=\"col_heading level0 col0\" >échantillon</th>\n      <th id=\"T_9e2f9_level0_col1\" class=\"col_heading level0 col1\" >Plage</th>\n      <th id=\"T_9e2f9_level0_col2\" class=\"col_heading level0 col2\" >substrat</th>\n      <th id=\"T_9e2f9_level0_col3\" class=\"col_heading level0 col3\" >date</th>\n      <th id=\"T_9e2f9_level0_col4\" class=\"col_heading level0 col4\" >area</th>\n      <th id=\"T_9e2f9_level0_col5\" class=\"col_heading level0 col5\" >slug</th>\n      <th id=\"T_9e2f9_level0_col6\" class=\"col_heading level0 col6\" >code</th>\n      <th id=\"T_9e2f9_level0_col7\" class=\"col_heading level0 col7\" >quantité</th>\n      <th id=\"T_9e2f9_level0_col8\" class=\"col_heading level0 col8\" >pcs/m²</th>\n      <th id=\"T_9e2f9_level0_col9\" class=\"col_heading level0 col9\" >region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_9e2f9_level0_row0\" class=\"row_heading level0 row0\" >5</th>\n      <td id=\"T_9e2f9_row0_col0\" class=\"data row0 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_9e2f9_row0_col1\" class=\"data row0 col1\" >Amphion</td>\n      <td id=\"T_9e2f9_row0_col2\" class=\"data row0 col2\" >4</td>\n      <td id=\"T_9e2f9_row0_col3\" class=\"data row0 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_9e2f9_row0_col4\" class=\"data row0 col4\" >440</td>\n      <td id=\"T_9e2f9_row0_col5\" class=\"data row0 col5\" >amphion</td>\n      <td id=\"T_9e2f9_row0_col6\" class=\"data row0 col6\" >G27</td>\n      <td id=\"T_9e2f9_row0_col7\" class=\"data row0 col7\" >4</td>\n      <td id=\"T_9e2f9_row0_col8\" class=\"data row0 col8\" >0,01</td>\n      <td id=\"T_9e2f9_row0_col9\" class=\"data row0 col9\" >Grand lac</td>\n    </tr>\n    <tr>\n      <th id=\"T_9e2f9_level0_row1\" class=\"row_heading level0 row1\" >20</th>\n      <td id=\"T_9e2f9_row1_col0\" class=\"data row1 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_9e2f9_row1_col1\" class=\"data row1 col1\" >Amphion</td>\n      <td id=\"T_9e2f9_row1_col2\" class=\"data row1 col2\" >4</td>\n      <td id=\"T_9e2f9_row1_col3\" class=\"data row1 col3\" >2022-02-01 00:00:00</td>\n      <td id=\"T_9e2f9_row1_col4\" class=\"data row1 col4\" >440</td>\n      <td id=\"T_9e2f9_row1_col5\" class=\"data row1 col5\" >amphion</td>\n      <td id=\"T_9e2f9_row1_col6\" class=\"data row1 col6\" >Gfrags</td>\n      <td id=\"T_9e2f9_row1_col7\" class=\"data row1 col7\" >334</td>\n      <td id=\"T_9e2f9_row1_col8\" class=\"data row1 col8\" >0,76</td>\n      <td id=\"T_9e2f9_row1_col9\" class=\"data row1 col9\" >Grand lac</td>\n    </tr>\n    <tr>\n      <th id=\"T_9e2f9_level0_row2\" class=\"row_heading level0 row2\" >362</th>\n      <td id=\"T_9e2f9_row2_col0\" class=\"data row2 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_9e2f9_row2_col1\" class=\"data row2 col1\" >Clarens</td>\n      <td id=\"T_9e2f9_row2_col2\" class=\"data row2 col2\" >2</td>\n      <td id=\"T_9e2f9_row2_col3\" class=\"data row2 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_9e2f9_row2_col4\" class=\"data row2 col4\" >340</td>\n      <td id=\"T_9e2f9_row2_col5\" class=\"data row2 col5\" >clarens</td>\n      <td id=\"T_9e2f9_row2_col6\" class=\"data row2 col6\" >G27</td>\n      <td id=\"T_9e2f9_row2_col7\" class=\"data row2 col7\" >11</td>\n      <td id=\"T_9e2f9_row2_col8\" class=\"data row2 col8\" >0,03</td>\n      <td id=\"T_9e2f9_row2_col9\" class=\"data row2 col9\" >Haut lac</td>\n    </tr>\n    <tr>\n      <th id=\"T_9e2f9_level0_row3\" class=\"row_heading level0 row3\" >374</th>\n      <td id=\"T_9e2f9_row3_col0\" class=\"data row3 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_9e2f9_row3_col1\" class=\"data row3 col1\" >Clarens</td>\n      <td id=\"T_9e2f9_row3_col2\" class=\"data row3 col2\" >2</td>\n      <td id=\"T_9e2f9_row3_col3\" class=\"data row3 col3\" >2022-01-16 00:00:00</td>\n      <td id=\"T_9e2f9_row3_col4\" class=\"data row3 col4\" >340</td>\n      <td id=\"T_9e2f9_row3_col5\" class=\"data row3 col5\" >clarens</td>\n      <td id=\"T_9e2f9_row3_col6\" class=\"data row3 col6\" >Gfrags</td>\n      <td id=\"T_9e2f9_row3_col7\" class=\"data row3 col7\" >5</td>\n      <td id=\"T_9e2f9_row3_col8\" class=\"data row3 col8\" >0,01</td>\n      <td id=\"T_9e2f9_row3_col9\" class=\"data row3 col9\" >Haut lac</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x7fba8cd09e50>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_5"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (work_data[\"échantillon\"].isin(loc_dates_t))&(work_data.code.isin([\"Gfrags\", \"G27\"]))\n",
    "\n",
    "test = work_data[mask].copy()\n",
    "caption = \"The density of sample if the areas are combined. The result for each sample is the sum of the different results for the different positions and substrates for each sample.\"\n",
    "sd_5 = test.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption)\n",
    "glue(\"start_data_5\", sd_5, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e9ced6-3c60-4de3-a8ff-3bdf7375a5f4",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "work_data.to_csv('data/end_pipe/macro_data_msquared.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ac9be-e6b2-44ad-a2be-7c6edb04f112",
   "metadata": {},
   "source": [
    "## Exemple\n",
    "\n",
    "### Mètres carrés\n",
    "\n",
    "Pour illustrer les changements apportés aux données, considérons deux échantillons et deux codes. Le premier échantillon est Amphion le 2022-02-01 et le second est Clarens le 2022-01-16. À Amphion, il y a plusieurs valeurs pour les mêmes codes le même jour. Il en va de même pour Clarens, mais à Clarens, il y a également deux substrats pour la plage. Notez que les codes G78 et G79 font partie du code combiné Gfrags.\n",
    "\n",
    "```{glue} start_data\n",
    "```\n",
    "\n",
    "Pour combiner les données, nous devons additionner les surfaces pour chaque échantillon, appliquer la nouvelle surface à tous les comptages d'objets pour cet échantillon et ce jour, et supprimer la variable de position. Pour Amphion, la surface totale est de 342 + 98 = 440 m², pour Clarens 273 + 67 = 340 m².\n",
    "\n",
    "```{glue} start_data_2\n",
    "``` \n",
    "\n",
    "Après avoir combiné tous les totaux de codes pour chaque échantillon et remplacé le substrat 4 par le substrat 2 dans toutes les localités qui ont des valeurs de substrat distinctes pour la position, nous nous retrouvons encore avec des codes en double sur un échantillon.\n",
    "\n",
    "```{glue} start_data_3\n",
    "``` \n",
    "\n",
    "Dans la dernière étape, les codes qui doivent être combinés (G78 et G79) sont placés sous un seul code et les données sont agrégées à l'identifiant de l'échantillon (date et lieu de l'échantillon).  \n",
    "\n",
    "```{glue} start_data_5\n",
    "```\n",
    "\n",
    "#### La différence\n",
    "\n",
    "Si les surfaces des positions ne sont pas combinées, les valeurs attendues sont beaucoup plus faibles. En effet, nous sommes obligés de prendre la moyenne de la densité des deux positions pour chaque échantillon. Cela peut être difficile à communiquer, par exemple le total de l'échantillon moyen du projet pour Gfrags serait en fait la moyenne des moyennes de l'échantillon.\n",
    "\n",
    "```{glue} start_data_4\n",
    "``` \n",
    "\n",
    "### Mètres linéaires\n",
    "\n",
    "L'opération de transformation des données en mètres linéaires est différente. Pour convertir toutes les plages en une seule section, nous abandonnons la variable superficie et la remplaçons par les données de longueur fournies. La longueur est la même pour les deux sections de chaque plage (les surfaces sont différentes), nous avons donc divisé la somme de tous les objets par la longueur donnée pour l'échantillon. Ce processus est conforme à la norme décrite dans le guide de surveillance des déchets marins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee325418-ef53-42e0-b3a7-41a0e63f362f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# reading in data\n",
    "new_datai = pd.read_csv(\"data/end_pipe/macro_current.csv\")\n",
    "beach_data = pd.read_csv(\"data/end_pipe/pstock_beaches_current.csv\")\n",
    "\n",
    "\n",
    "# adding the lenght of each sample to the results\n",
    "length_key = beach_data[[\"Plage\",\"length\"]].drop_duplicates(\"Plage\").set_index(\"Plage\")\n",
    "work_datai = new_datai[[\"Plage\", *new_column_names.keys()]].copy()\n",
    "work_datai.rename(columns=new_column_names, inplace=True)\n",
    "work_datai[\"length\"] = work_datai.Plage.apply(lambda x: length_key.loc[x, \"length\"])\n",
    "\n",
    "# making a sample id from the location and date\n",
    "work_datai[\"slug\"] = work_datai.Plage.apply(lambda x: slugify(x))\n",
    "work_datai[\"echantillon\"] = list(zip(work_datai.slug, work_datai['date']))\n",
    "work_datai['date'] = pd.to_datetime(work_datai[\"date\"], format=\"mixed\", dayfirst=True)\n",
    "work_datai.dropna(inplace=True)\n",
    "\n",
    "# defining the data type of columns\n",
    "work_datai[[\"position\", \"substrat\"]] = work_datai[[\"position\", \"substrat\"]].astype(\"int\")\n",
    "\n",
    "# changing the column name to human readable\n",
    "work_datai['échantillon'] = work_datai['echantillon']\n",
    "work_datai.drop(['echantillon'], inplace=True, axis=1)\n",
    "\n",
    "# removing the position variable from data and\n",
    "# grouping by sample id and code to get the total per sample per code\n",
    "work_datai = work_datai.groupby(['échantillon', 'Plage', 'substrat', 'date', 'length', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "\n",
    "# divide that by length\n",
    "work_datai['pcs/m'] = work_datai['quantité']/work_datai['length']\n",
    "\n",
    "# add the region\n",
    "work_datai['region'] = work_datai.slug.apply(lambda x: regions.loc[x, 'alabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b630682-b5af-4834-aead-886e668ab981",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! combining the substrates for beaches where there are two substrates !\n",
    "voi = 'substrat'\n",
    "vals = \"pcs/m\"\n",
    "some_data = work_datai.copy()\n",
    "groupby = ['échantillon', voi]\n",
    "data = some_data.groupby(groupby, as_index=False)[vals].sum()\n",
    "\n",
    "# these are the duplicate values that need to be changed\n",
    "dd = data[data['échantillon'].duplicated()].copy()\n",
    "\n",
    "duplicated = work_datai[work_datai['échantillon'].isin(dd['échantillon'].unique())].copy()\n",
    "duplicated['substrat'] = 2 \n",
    "\n",
    "# notduplicated\n",
    "not_duplicated = work_datai[~(work_datai['échantillon'].isin(dd['échantillon'].unique()))].copy()\n",
    "\n",
    "# put it back to gether again\n",
    "work_datai = pd.concat([duplicated, not_duplicated])\n",
    "\n",
    "# groupby the new substrat values and calculate pcs/m\n",
    "work_datai = work_datai.groupby(['échantillon', 'Plage', 'region', 'substrat', 'date', 'length', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "work_datai['pcs/m'] = work_datai['quantité']/work_datai['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d02150b6-e677-4bed-9c12-22a4a1051a30",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! defining the total inventory of the current data !\n",
    "# accounting for objects not found at a sample:\n",
    "# the codes that were indentified at least once = inventory\n",
    "# defining the components of the inventory\n",
    "codes_ip = work_datai.code.unique()\n",
    "\n",
    "# the unique samples\n",
    "loc_dates = work_datai['échantillon'].unique()\n",
    "\n",
    "# a copy for itterating\n",
    "wd = work_datai.copy()\n",
    "\n",
    "# for each sample (échantillon) indentify the codes that were not\n",
    "# found by indentifying all the codes that were found in all surveys\n",
    "# and removing the codes that were not identified at that sample.\n",
    "# for each unidentified code per sample, add a row with the sample\n",
    "# id and the code. give the row a quantity of zero.\n",
    "rows = []\n",
    "for a_loc in loc_dates:\n",
    "    r = wd.loc[wd['échantillon'] == a_loc].copy()\n",
    "    r.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    t = r.loc[0][['échantillon', 'Plage', 'region', 'substrat', 'date', 'length', 'slug']].values\n",
    "    asamp = [x for x in t]\n",
    "    used_codes = r.code.unique()\n",
    "    unused = [x for x in codes_ip if x not in used_codes]\n",
    "    for element in unused:\n",
    "        arow = [*asamp, element, 0, 0]\n",
    "        rows.append(arow)\n",
    "        \n",
    "\n",
    "work_x = pd.DataFrame(rows, columns=['échantillon', 'Plage', 'region', 'substrat', 'date', 'length', 'slug', 'code', 'quantité', 'pcs/m'])\n",
    "work_datai = pd.concat([work_x, work_datai])\n",
    "\n",
    "work_datai.to_csv(\"data/end_pipe/macro_data_linearm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d068d-c2c7-4194-9985-688745195c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
