{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13449d70-f334-4082-a3ff-2d6ca7bd1a6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(data_processing)=\n",
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0416dd59-f9b4-436d-ad6d-2b374c649c19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "' '"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "blank_caption"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "# %load_ext rpy2.ipython\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "# import rpy2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import multinomial\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from myst_nb import glue\n",
    "from slugify import slugify\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "\n",
    "# from rpy2.robjects.packages import importr\n",
    "\n",
    "import plastockconf as psc\n",
    "import plastock as pstk\n",
    "\n",
    "from plastockconf import name_zones, name_frequentation, name_situation\n",
    "from plastockconf import name_substrate, name_distance, table_css_styles, table_css_styles_top\n",
    "\n",
    "from plastock import add_table_to_page, capitalize_x_tick_labels, capitalize_x_and_y_axis_labels, capitalize_legend_components, attribute_summary\n",
    "\n",
    "import reportclass as rc\n",
    "\n",
    "section = \"A\"\n",
    "page = \"5\"\n",
    "\n",
    "label = f'Table {section}{page}-'\n",
    "\n",
    "def make_exportable(data, file_name, cmap='YlOrBr'):\n",
    "    data.fillna(0, inplace=True)\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    sns.heatmap(data=data, vmin=0, vmax=1, cmap=cmap, annot=True, fmt='.2', annot_kws={'size':10}, ax=ax, cbar=False)\n",
    "    plt.tight_layout()\n",
    "    ax.tick_params(which='both', axis='both', bottom=False, left=False)\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "glue('blank_caption', \" \", display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdbc60-f1ba-4a3e-98af-87384a1b594e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Description des données macroplastiques\n",
    "\n",
    "__Cette méthode s'applique aux données sur les déchets visibles à l'oeil nu, mais pas aux microplastiques__\n",
    "\n",
    "### Position\n",
    "\n",
    "Les inventaires des déchets menés précédemment sur le lac considéraient la plage comme une unité à part entière. Dans Pla'stock, chaque plage a été divisée en deux sections, la ligne d'eau et la plage sèche. Pour comparer les données de Pla'stock aux résultats précédents et à d'autres études de ce type, les résultats de Pla'stock doivent être transformés en une section pour une plage. En d'autres termes, nous devons combiner la surface des deux sections pour chaque échantillon.\n",
    "\n",
    "### Objets\n",
    "\n",
    "La variété des objets identifiés lors de chaque action dépend des déchets sur le terrain et du temps passé à compter, trier et identifier chaque objet collecté. Par conséquent, les seuls codes ou objets pris en considération sont ceux qui ont été identifiés pendant Pla'stock. Les données historiques sont filtrées pour les mêmes codes.\n",
    "\n",
    "#### Combinaison d'objets similaires\n",
    "\n",
    "Certaines catégories d'objets sont combinées. Cela signifie que nous modifions le code de certains éléments pour refléter les tendances de l'échantillonnage et tenir compte des différentes interprétations du protocole. Le tableau suivant résume la façon dont les codes sont combinés :\n",
    "\n",
    "1. Gfrags: g80, g79, g78, g77, g76, g75\n",
    "2. Gfoams: G81, G82, G76\n",
    "3. Gcaps: G21, G22, G23, G24\n",
    "\n",
    "Gfrags comprend toutes les formes de plastiques fragmentés de plus de 5 mm, Gfoams toutes les tailles de polystyrène expansé et Gcaps tous les bouchons en plastique et les anneaux en plastique qui accompagnent chaque bouchon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80c6173-3821-493a-aa58-3112f5192619",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! read in data !\n",
    "# survey data\n",
    "new_data = pd.read_csv(\"data/end_pipe/macro_current.csv\")\n",
    "\n",
    "# the position, substrate, time, area, length for each sample in the data\n",
    "# ! there are samples that have different substrates on the same sample_id.!\n",
    "# that is position 1 has a different substrate than position 2. for litter \n",
    "# data and comparing to previous results this is unimportant. The value to\n",
    "# compare is the total survey divided by the length or the area. This needs\n",
    "# to be accounted for and changes made to certain samples.\n",
    "beach_data = pd.read_csv(\"data/end_pipe/pstock_beaches_current.csv\")\n",
    "\n",
    "\n",
    "# the feature columns of the survey data that are not dependent on the\n",
    "# position or substrat variables. they are indexed on the Plage column\n",
    "# one row for each sample location\n",
    "beach_datax = pd.read_csv(\"data/end_pipe/asl_beaches.csv\").set_index('Plage')\n",
    "\n",
    "# The code definitions\n",
    "codes = pd.read_csv('data/end_pipe/codes.csv').set_index('code')\n",
    "\n",
    "# the regional labels for each survey location\n",
    "regions = pd.read_csv(\"data/end_pipe/lac_leman_regions.csv\")\n",
    "regions.set_index('slug', drop=True, inplace=True)\n",
    "\n",
    "# the city name of the survey locations\n",
    "city_map = pd.read_csv('data/end_pipe/city_map.csv')\n",
    "city_map.set_index('slug', inplace=True)\n",
    "\n",
    "# translation of common terms into french, german and english\n",
    "language_maps = rc.language_maps()\n",
    "\n",
    "new_column_names = {\n",
    "    \"Position\":\"position\",\n",
    "    \"Substrat\":\"substrat\",\n",
    "    \"Date\":\"date\",\n",
    "    \"Code\":\"code\",\n",
    "    \"Quantité\":\"quantité\",\n",
    "    \"Aire\":\"area\"\n",
    "}\n",
    "new_data.loc[new_data.Substrat.isna(), \"Substrat\"] = 1\n",
    "\n",
    "# import data and assign new column names and sample_id\n",
    "# the sample_id is the tuple (location, date). Each row\n",
    "# is a unique combinantion of sample_id and code\n",
    "work_data = new_data[[\"Plage\", *new_column_names.keys()]].copy()\n",
    "work_data.rename(columns=new_column_names, inplace=True)\n",
    "work_data[\"slug\"] = work_data.Plage.apply(lambda x: slugify(x))\n",
    "work_data[\"échantillon\"] = list(zip(work_data.slug, work_data['date']))\n",
    "work_data['date'] = pd.to_datetime(work_data[\"date\"], format=\"mixed\", dayfirst=True)\n",
    "# work_data.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dd65a4-d065-4fb7-914d-e2fddb0c1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type the columns\n",
    "work_data[[\"position\", \"substrat\"]] = work_data[[\"position\", \"substrat\"]].astype(\"int\")\n",
    "work_data['échantillon'] = work_data['échantillon'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf97495-c34a-42a0-be3a-70a8ab4e33d0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "voi = \"substrat\"\n",
    "vals = \"pcs/m²\"\n",
    "code = \"G27\"\n",
    "loc_dates_t = [\"('clarens', '16.01.2022')\", \"('amphion', '01.02.2022')\"]\n",
    "\n",
    "gfrags_c = codes.loc[codes.parent_code == 'Gfrags'].index\n",
    "\n",
    "start_amph_s = new_data[(new_data.Plage == \"Amphion\")&(new_data[\"Date\"] == \"01.02.2022\")&(new_data.Code == \"G27\")]\n",
    "start_amph_c = new_data[(new_data.Plage == \"Amphion\")&(new_data[\"Date\"] == \"01.02.2022\")&(new_data.Code.isin(gfrags_c))]\n",
    "start_clarens_s = new_data[(new_data.Plage == \"Clarens\")&(new_data[\"Date\"] == '16.01.2022')&(new_data.Code == \"G27\")]\n",
    "start_clarens_c = new_data[(new_data.Plage == \"Clarens\")&(new_data[\"Date\"] == '16.01.2022')&(new_data.Code.isin(gfrags_c))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96cae44-9c27-48fa-95c5-69361bd4b0f8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_cd039 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_cd039 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_cd039 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_cd039 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_cd039 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_cd039 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_cd039\">\n  <caption><b>Table A5-1 :</b> Les résultats de l'échantillon avant la combinaison des codes, des substrats et de la position</caption>\n  <thead>\n    <tr>\n      <th id=\"T_cd039_level0_col0\" class=\"col_heading level0 col0\" >Plage</th>\n      <th id=\"T_cd039_level0_col1\" class=\"col_heading level0 col1\" >Date</th>\n      <th id=\"T_cd039_level0_col2\" class=\"col_heading level0 col2\" >Position</th>\n      <th id=\"T_cd039_level0_col3\" class=\"col_heading level0 col3\" >Substrat</th>\n      <th id=\"T_cd039_level0_col4\" class=\"col_heading level0 col4\" >Aire</th>\n      <th id=\"T_cd039_level0_col5\" class=\"col_heading level0 col5\" >Code</th>\n      <th id=\"T_cd039_level0_col6\" class=\"col_heading level0 col6\" >Quantité</th>\n      <th id=\"T_cd039_level0_col7\" class=\"col_heading level0 col7\" >pcs/m²</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_cd039_row0_col0\" class=\"data row0 col0\" >Amphion</td>\n      <td id=\"T_cd039_row0_col1\" class=\"data row0 col1\" >01.02.2022</td>\n      <td id=\"T_cd039_row0_col2\" class=\"data row0 col2\" >2</td>\n      <td id=\"T_cd039_row0_col3\" class=\"data row0 col3\" >4,00</td>\n      <td id=\"T_cd039_row0_col4\" class=\"data row0 col4\" >342</td>\n      <td id=\"T_cd039_row0_col5\" class=\"data row0 col5\" >G27</td>\n      <td id=\"T_cd039_row0_col6\" class=\"data row0 col6\" >4</td>\n      <td id=\"T_cd039_row0_col7\" class=\"data row0 col7\" >0,01</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row1_col0\" class=\"data row1 col0\" >Amphion</td>\n      <td id=\"T_cd039_row1_col1\" class=\"data row1 col1\" >01.02.2022</td>\n      <td id=\"T_cd039_row1_col2\" class=\"data row1 col2\" >1</td>\n      <td id=\"T_cd039_row1_col3\" class=\"data row1 col3\" >4,00</td>\n      <td id=\"T_cd039_row1_col4\" class=\"data row1 col4\" >98</td>\n      <td id=\"T_cd039_row1_col5\" class=\"data row1 col5\" >G78</td>\n      <td id=\"T_cd039_row1_col6\" class=\"data row1 col6\" >8</td>\n      <td id=\"T_cd039_row1_col7\" class=\"data row1 col7\" >0,08</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row2_col0\" class=\"data row2 col0\" >Amphion</td>\n      <td id=\"T_cd039_row2_col1\" class=\"data row2 col1\" >01.02.2022</td>\n      <td id=\"T_cd039_row2_col2\" class=\"data row2 col2\" >2</td>\n      <td id=\"T_cd039_row2_col3\" class=\"data row2 col3\" >4,00</td>\n      <td id=\"T_cd039_row2_col4\" class=\"data row2 col4\" >342</td>\n      <td id=\"T_cd039_row2_col5\" class=\"data row2 col5\" >G78</td>\n      <td id=\"T_cd039_row2_col6\" class=\"data row2 col6\" >86</td>\n      <td id=\"T_cd039_row2_col7\" class=\"data row2 col7\" >0,25</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row3_col0\" class=\"data row3 col0\" >Amphion</td>\n      <td id=\"T_cd039_row3_col1\" class=\"data row3 col1\" >01.02.2022</td>\n      <td id=\"T_cd039_row3_col2\" class=\"data row3 col2\" >1</td>\n      <td id=\"T_cd039_row3_col3\" class=\"data row3 col3\" >4,00</td>\n      <td id=\"T_cd039_row3_col4\" class=\"data row3 col4\" >98</td>\n      <td id=\"T_cd039_row3_col5\" class=\"data row3 col5\" >G79</td>\n      <td id=\"T_cd039_row3_col6\" class=\"data row3 col6\" >12</td>\n      <td id=\"T_cd039_row3_col7\" class=\"data row3 col7\" >0,12</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row4_col0\" class=\"data row4 col0\" >Amphion</td>\n      <td id=\"T_cd039_row4_col1\" class=\"data row4 col1\" >01.02.2022</td>\n      <td id=\"T_cd039_row4_col2\" class=\"data row4 col2\" >2</td>\n      <td id=\"T_cd039_row4_col3\" class=\"data row4 col3\" >4,00</td>\n      <td id=\"T_cd039_row4_col4\" class=\"data row4 col4\" >342</td>\n      <td id=\"T_cd039_row4_col5\" class=\"data row4 col5\" >G79</td>\n      <td id=\"T_cd039_row4_col6\" class=\"data row4 col6\" >225</td>\n      <td id=\"T_cd039_row4_col7\" class=\"data row4 col7\" >0,66</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row5_col0\" class=\"data row5 col0\" >Amphion</td>\n      <td id=\"T_cd039_row5_col1\" class=\"data row5 col1\" >01.02.2022</td>\n      <td id=\"T_cd039_row5_col2\" class=\"data row5 col2\" >2</td>\n      <td id=\"T_cd039_row5_col3\" class=\"data row5 col3\" >4,00</td>\n      <td id=\"T_cd039_row5_col4\" class=\"data row5 col4\" >342</td>\n      <td id=\"T_cd039_row5_col5\" class=\"data row5 col5\" >G79</td>\n      <td id=\"T_cd039_row5_col6\" class=\"data row5 col6\" >3</td>\n      <td id=\"T_cd039_row5_col7\" class=\"data row5 col7\" >0,01</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row6_col0\" class=\"data row6 col0\" >Clarens</td>\n      <td id=\"T_cd039_row6_col1\" class=\"data row6 col1\" >16.01.2022</td>\n      <td id=\"T_cd039_row6_col2\" class=\"data row6 col2\" >2</td>\n      <td id=\"T_cd039_row6_col3\" class=\"data row6 col3\" >2,00</td>\n      <td id=\"T_cd039_row6_col4\" class=\"data row6 col4\" >273</td>\n      <td id=\"T_cd039_row6_col5\" class=\"data row6 col5\" >G78</td>\n      <td id=\"T_cd039_row6_col6\" class=\"data row6 col6\" >5</td>\n      <td id=\"T_cd039_row6_col7\" class=\"data row6 col7\" >0,02</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row7_col0\" class=\"data row7 col0\" >Clarens</td>\n      <td id=\"T_cd039_row7_col1\" class=\"data row7 col1\" >16.01.2022</td>\n      <td id=\"T_cd039_row7_col2\" class=\"data row7 col2\" >1</td>\n      <td id=\"T_cd039_row7_col3\" class=\"data row7 col3\" >4,00</td>\n      <td id=\"T_cd039_row7_col4\" class=\"data row7 col4\" >67</td>\n      <td id=\"T_cd039_row7_col5\" class=\"data row7 col5\" >G27</td>\n      <td id=\"T_cd039_row7_col6\" class=\"data row7 col6\" >3</td>\n      <td id=\"T_cd039_row7_col7\" class=\"data row7 col7\" >0,04</td>\n    </tr>\n    <tr>\n      <td id=\"T_cd039_row8_col0\" class=\"data row8 col0\" >Clarens</td>\n      <td id=\"T_cd039_row8_col1\" class=\"data row8 col1\" >16.01.2022</td>\n      <td id=\"T_cd039_row8_col2\" class=\"data row8 col2\" >2</td>\n      <td id=\"T_cd039_row8_col3\" class=\"data row8 col3\" >2,00</td>\n      <td id=\"T_cd039_row8_col4\" class=\"data row8 col4\" >273</td>\n      <td id=\"T_cd039_row8_col5\" class=\"data row8 col5\" >G27</td>\n      <td id=\"T_cd039_row8_col6\" class=\"data row8 col6\" >8</td>\n      <td id=\"T_cd039_row8_col7\" class=\"data row8 col7\" >0,03</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x74cd68127730>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_data = pd.concat([start_amph_s, start_amph_c, start_clarens_c, start_clarens_s])\n",
    "start_data['pcs/m²'] = start_data[\"Quantité\"]/start_data[\"Aire\"]\n",
    "# start_data.loc[start_data.Code.isin(gfrags_c), 'Code'] = 'Gfrags'\n",
    "sd = start_data[[\"Plage\", \"Aire\", \"Position\", \"Substrat\", \"Date\", \"Code\", \"Quantité\", 'pcs/m²']].copy()\n",
    "sd.reset_index(inplace=True, drop=True)\n",
    "\n",
    "display_columns = [\"Plage\", \"Date\", \"Position\", \"Substrat\", \"Aire\",  \"Code\", \"Quantité\", \"pcs/m²\"]\n",
    "\n",
    "caption = f\"<b>{label}1 :</b> Les résultats de l'échantillon avant la combinaison des codes, des substrats et de la position\"\n",
    "sd = sd[display_columns].style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption).hide(axis=\"index\")\n",
    "\n",
    "glue(\"start_data\", sd, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9da2c5-3282-4539-b229-c2b05dca2e3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! locate all the duplicate values by sample id and area !\n",
    "# this gives a data frame that has the position and area for\n",
    "# each sample_id\n",
    "total_area_dup = work_data.drop_duplicates(['échantillon', 'area'])\n",
    "\n",
    "# ! combine the surface areas of the position vectors !\n",
    "# sum of the areas for each position at each sample\n",
    "# use the sample_id as index and sum the areas for each postition at each sample\n",
    "total_area = total_area_dup.groupby(['échantillon', 'Plage'], as_index=False).area.sum()\n",
    "total_area.set_index(\"échantillon\", inplace=True)\n",
    "\n",
    "# sum of the areas for each position at each sample\n",
    "# use the sample_id as index and sum the areas for each postition at each sample\n",
    "#total_area = total_area[['échantillon', 'area']].set_index('échantillon', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98818780-7c53-4e28-82a9-31cb72314d22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# apply the total area to the work_data, index on sample_id\n",
    "work_data['area_c'] = work_data['échantillon'].apply(lambda x: total_area.loc[x, \"area\"])\n",
    "work_data['area'] = work_data.area_c\n",
    "work_data.drop('area_c', axis=1, inplace=True)\n",
    "# the code total per sample with the combined area\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'quantité', 'code'], as_index=False)['quantité'].sum()\n",
    "work_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f3194a-2397-4d31-b819-13a86eab9776",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_1dd18 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_1dd18 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_1dd18 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_1dd18 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_1dd18 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_1dd18 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_1dd18\">\n  <caption><b>Table A5-2 :</b> La variable position est supprimée et les surfaces sont combinées pour chaque position de chaque échantillon. Cependant, le substrat à Clarens n'est pas corrigé.</caption>\n  <thead>\n    <tr>\n      <th id=\"T_1dd18_level0_col0\" class=\"col_heading level0 col0\" >échantillon</th>\n      <th id=\"T_1dd18_level0_col1\" class=\"col_heading level0 col1\" >Plage</th>\n      <th id=\"T_1dd18_level0_col2\" class=\"col_heading level0 col2\" >Substrat</th>\n      <th id=\"T_1dd18_level0_col3\" class=\"col_heading level0 col3\" >Aire</th>\n      <th id=\"T_1dd18_level0_col4\" class=\"col_heading level0 col4\" >Code</th>\n      <th id=\"T_1dd18_level0_col5\" class=\"col_heading level0 col5\" >Quantité</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_1dd18_row0_col0\" class=\"data row0 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_1dd18_row0_col1\" class=\"data row0 col1\" >Amphion</td>\n      <td id=\"T_1dd18_row0_col2\" class=\"data row0 col2\" >4</td>\n      <td id=\"T_1dd18_row0_col3\" class=\"data row0 col3\" >440</td>\n      <td id=\"T_1dd18_row0_col4\" class=\"data row0 col4\" >G79</td>\n      <td id=\"T_1dd18_row0_col5\" class=\"data row0 col5\" >3</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row1_col0\" class=\"data row1 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_1dd18_row1_col1\" class=\"data row1 col1\" >Amphion</td>\n      <td id=\"T_1dd18_row1_col2\" class=\"data row1 col2\" >4</td>\n      <td id=\"T_1dd18_row1_col3\" class=\"data row1 col3\" >440</td>\n      <td id=\"T_1dd18_row1_col4\" class=\"data row1 col4\" >G27</td>\n      <td id=\"T_1dd18_row1_col5\" class=\"data row1 col5\" >4</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row2_col0\" class=\"data row2 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_1dd18_row2_col1\" class=\"data row2 col1\" >Amphion</td>\n      <td id=\"T_1dd18_row2_col2\" class=\"data row2 col2\" >4</td>\n      <td id=\"T_1dd18_row2_col3\" class=\"data row2 col3\" >440</td>\n      <td id=\"T_1dd18_row2_col4\" class=\"data row2 col4\" >G78</td>\n      <td id=\"T_1dd18_row2_col5\" class=\"data row2 col5\" >8</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row3_col0\" class=\"data row3 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_1dd18_row3_col1\" class=\"data row3 col1\" >Amphion</td>\n      <td id=\"T_1dd18_row3_col2\" class=\"data row3 col2\" >4</td>\n      <td id=\"T_1dd18_row3_col3\" class=\"data row3 col3\" >440</td>\n      <td id=\"T_1dd18_row3_col4\" class=\"data row3 col4\" >G79</td>\n      <td id=\"T_1dd18_row3_col5\" class=\"data row3 col5\" >12</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row4_col0\" class=\"data row4 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_1dd18_row4_col1\" class=\"data row4 col1\" >Amphion</td>\n      <td id=\"T_1dd18_row4_col2\" class=\"data row4 col2\" >4</td>\n      <td id=\"T_1dd18_row4_col3\" class=\"data row4 col3\" >440</td>\n      <td id=\"T_1dd18_row4_col4\" class=\"data row4 col4\" >G78</td>\n      <td id=\"T_1dd18_row4_col5\" class=\"data row4 col5\" >86</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row5_col0\" class=\"data row5 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_1dd18_row5_col1\" class=\"data row5 col1\" >Amphion</td>\n      <td id=\"T_1dd18_row5_col2\" class=\"data row5 col2\" >4</td>\n      <td id=\"T_1dd18_row5_col3\" class=\"data row5 col3\" >440</td>\n      <td id=\"T_1dd18_row5_col4\" class=\"data row5 col4\" >G79</td>\n      <td id=\"T_1dd18_row5_col5\" class=\"data row5 col5\" >225</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row6_col0\" class=\"data row6 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_1dd18_row6_col1\" class=\"data row6 col1\" >Clarens</td>\n      <td id=\"T_1dd18_row6_col2\" class=\"data row6 col2\" >2</td>\n      <td id=\"T_1dd18_row6_col3\" class=\"data row6 col3\" >340</td>\n      <td id=\"T_1dd18_row6_col4\" class=\"data row6 col4\" >G78</td>\n      <td id=\"T_1dd18_row6_col5\" class=\"data row6 col5\" >5</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row7_col0\" class=\"data row7 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_1dd18_row7_col1\" class=\"data row7 col1\" >Clarens</td>\n      <td id=\"T_1dd18_row7_col2\" class=\"data row7 col2\" >2</td>\n      <td id=\"T_1dd18_row7_col3\" class=\"data row7 col3\" >340</td>\n      <td id=\"T_1dd18_row7_col4\" class=\"data row7 col4\" >G27</td>\n      <td id=\"T_1dd18_row7_col5\" class=\"data row7 col5\" >8</td>\n    </tr>\n    <tr>\n      <td id=\"T_1dd18_row8_col0\" class=\"data row8 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_1dd18_row8_col1\" class=\"data row8 col1\" >Clarens</td>\n      <td id=\"T_1dd18_row8_col2\" class=\"data row8 col2\" >4</td>\n      <td id=\"T_1dd18_row8_col3\" class=\"data row8 col3\" >340</td>\n      <td id=\"T_1dd18_row8_col4\" class=\"data row8 col4\" >G27</td>\n      <td id=\"T_1dd18_row8_col5\" class=\"data row8 col5\" >3</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x74ccdbf99c10>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_2"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (work_data[\"échantillon\"].isin(loc_dates_t))&(work_data.code.isin([*gfrags_c, code]))\n",
    "\n",
    "display_columns = [\"échantillon\", \"Plage\", \"Substrat\", \"Aire\",  \"Code\", \"Quantité\"]\n",
    "d = \"pcs/m²\"\n",
    "\n",
    "test = work_data[mask].copy()\n",
    "test = test.rename(columns={\"substrat\":\"Substrat\", \"area\":\"Aire\", \"date\":\"Date\", \"code\":\"Code\", \"quantité\":\"Quantité\"})\n",
    "test = test[display_columns].copy()\n",
    "# test.reset_index(inplace=True, drop=True)\n",
    "caption = f\"<b>{label}2 :</b> La variable position est supprimée et les surfaces sont combinées pour chaque position de chaque échantillon. Cependant, le substrat à Clarens n'est pas corrigé.\"\n",
    "sd_2 = test.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption).hide(axis='index')\n",
    "glue(\"start_data_2\", sd_2, display=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee52963c-eb6d-451f-87b4-9069b305456b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the code total per sample with the combined area\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'code'], as_index=False)['quantité'].sum()\n",
    "\n",
    "# add the regional component\n",
    "work_data['region'] = work_data.slug.apply(lambda x: regions.loc[x, 'alabel'])\n",
    "\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'quantité', 'code'], as_index=False)['quantité'].sum()\n",
    "# get the pcs/m²  for each object at each sample\n",
    "work_data['pcs/m²'] = work_data['quantité']/work_data.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8c53a7-4cfc-4552-a00a-d196f71bd337",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! there are samples that have different substrates on the same sample_id.!\n",
    "# there should be one substrate per sample_id. Identify the locations that have duplicate values\n",
    "some_data = work_data.copy()\n",
    "groupby = ['échantillon', voi]\n",
    "data = some_data.groupby(groupby, as_index=False)[vals].sum()\n",
    "\n",
    "# the samples with more than one substrate\n",
    "dd = data[data['échantillon'].duplicated()].copy()\n",
    "# select all the duplicated sample_ids from the work_data\n",
    "duplicated = work_data[work_data['échantillon'].isin(dd['échantillon'].unique())].copy()\n",
    "# select all the duplicated sample_ids from the work_data\n",
    "# change the substrat to [2]\n",
    "duplicated['substrat'] = 2 \n",
    "\n",
    "# select all the values that are not duplicated\n",
    "not_duplicated = work_data[~(work_data['échantillon'].isin(dd['échantillon'].unique()))].copy()\n",
    "\n",
    "# put it back together again\n",
    "work_data = pd.concat([duplicated, not_duplicated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39363708-fbc0-4484-8c2b-e99f4ce4cce3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_945c3 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_945c3 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_945c3 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_945c3 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_945c3 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_945c3 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_945c3\">\n  <caption><b>Table A5-3 :</b> Après avoir combiné les codes et supprimé la variable de la position, il reste des codes en double pour l'échantillon de Clarens.</caption>\n  <thead>\n    <tr>\n      <th id=\"T_945c3_level0_col0\" class=\"col_heading level0 col0\" >échantillon</th>\n      <th id=\"T_945c3_level0_col1\" class=\"col_heading level0 col1\" >Plage</th>\n      <th id=\"T_945c3_level0_col2\" class=\"col_heading level0 col2\" >Substrat</th>\n      <th id=\"T_945c3_level0_col3\" class=\"col_heading level0 col3\" >Aire</th>\n      <th id=\"T_945c3_level0_col4\" class=\"col_heading level0 col4\" >Code</th>\n      <th id=\"T_945c3_level0_col5\" class=\"col_heading level0 col5\" >Quantité</th>\n      <th id=\"T_945c3_level0_col6\" class=\"col_heading level0 col6\" >pcs/m²</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_945c3_row0_col0\" class=\"data row0 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_945c3_row0_col1\" class=\"data row0 col1\" >Clarens</td>\n      <td id=\"T_945c3_row0_col2\" class=\"data row0 col2\" >2</td>\n      <td id=\"T_945c3_row0_col3\" class=\"data row0 col3\" >340</td>\n      <td id=\"T_945c3_row0_col4\" class=\"data row0 col4\" >G78</td>\n      <td id=\"T_945c3_row0_col5\" class=\"data row0 col5\" >5</td>\n      <td id=\"T_945c3_row0_col6\" class=\"data row0 col6\" >0,01</td>\n    </tr>\n    <tr>\n      <td id=\"T_945c3_row1_col0\" class=\"data row1 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_945c3_row1_col1\" class=\"data row1 col1\" >Clarens</td>\n      <td id=\"T_945c3_row1_col2\" class=\"data row1 col2\" >2</td>\n      <td id=\"T_945c3_row1_col3\" class=\"data row1 col3\" >340</td>\n      <td id=\"T_945c3_row1_col4\" class=\"data row1 col4\" >G27</td>\n      <td id=\"T_945c3_row1_col5\" class=\"data row1 col5\" >8</td>\n      <td id=\"T_945c3_row1_col6\" class=\"data row1 col6\" >0,02</td>\n    </tr>\n    <tr>\n      <td id=\"T_945c3_row2_col0\" class=\"data row2 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_945c3_row2_col1\" class=\"data row2 col1\" >Clarens</td>\n      <td id=\"T_945c3_row2_col2\" class=\"data row2 col2\" >2</td>\n      <td id=\"T_945c3_row2_col3\" class=\"data row2 col3\" >340</td>\n      <td id=\"T_945c3_row2_col4\" class=\"data row2 col4\" >G27</td>\n      <td id=\"T_945c3_row2_col5\" class=\"data row2 col5\" >3</td>\n      <td id=\"T_945c3_row2_col6\" class=\"data row2 col6\" >0,01</td>\n    </tr>\n    <tr>\n      <td id=\"T_945c3_row3_col0\" class=\"data row3 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_945c3_row3_col1\" class=\"data row3 col1\" >Amphion</td>\n      <td id=\"T_945c3_row3_col2\" class=\"data row3 col2\" >4</td>\n      <td id=\"T_945c3_row3_col3\" class=\"data row3 col3\" >440</td>\n      <td id=\"T_945c3_row3_col4\" class=\"data row3 col4\" >G27</td>\n      <td id=\"T_945c3_row3_col5\" class=\"data row3 col5\" >4</td>\n      <td id=\"T_945c3_row3_col6\" class=\"data row3 col6\" >0,01</td>\n    </tr>\n    <tr>\n      <td id=\"T_945c3_row4_col0\" class=\"data row4 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_945c3_row4_col1\" class=\"data row4 col1\" >Amphion</td>\n      <td id=\"T_945c3_row4_col2\" class=\"data row4 col2\" >4</td>\n      <td id=\"T_945c3_row4_col3\" class=\"data row4 col3\" >440</td>\n      <td id=\"T_945c3_row4_col4\" class=\"data row4 col4\" >G78</td>\n      <td id=\"T_945c3_row4_col5\" class=\"data row4 col5\" >94</td>\n      <td id=\"T_945c3_row4_col6\" class=\"data row4 col6\" >0,21</td>\n    </tr>\n    <tr>\n      <td id=\"T_945c3_row5_col0\" class=\"data row5 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_945c3_row5_col1\" class=\"data row5 col1\" >Amphion</td>\n      <td id=\"T_945c3_row5_col2\" class=\"data row5 col2\" >4</td>\n      <td id=\"T_945c3_row5_col3\" class=\"data row5 col3\" >440</td>\n      <td id=\"T_945c3_row5_col4\" class=\"data row5 col4\" >G79</td>\n      <td id=\"T_945c3_row5_col5\" class=\"data row5 col5\" >240</td>\n      <td id=\"T_945c3_row5_col6\" class=\"data row5 col6\" >0,55</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x74cd6811b730>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_3"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (work_data[\"échantillon\"].isin(loc_dates_t))&(work_data.code.isin([*gfrags_c, code]))\n",
    "\n",
    "display_columns = [\"échantillon\", \"Plage\", \"Substrat\", \"Aire\",  \"Code\", \"Quantité\", \"pcs/m²\"]\n",
    "\n",
    "test = work_data[mask].copy()\n",
    "test = test.rename(columns={\"substrat\":\"Substrat\", \"area\":\"Aire\", \"date\":\"Date\", \"code\":\"Code\", \"quantité\":\"Quantité\"})\n",
    "test = test[display_columns].copy()\n",
    "\n",
    "caption = f\"<b>{label}3 :</b> Après avoir combiné les codes et supprimé la variable de la position, il reste des codes en double pour l'échantillon de Clarens.\"\n",
    "sd_3 = test.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption).hide(axis=\"index\")\n",
    "glue(\"start_data_3\", sd_3, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd0694d8-9f5f-4ad8-929a-49804d47fd8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! valid codes and definitions !\n",
    "# plastock did not use the same inventory as iqaasl\n",
    "# here we select only the codes in the plastock inventory\n",
    "pcodes = work_data.code.unique()\n",
    "\n",
    "# identify and remove codes for which there is no defintion\n",
    "# if the code is not defined then it can not be used\n",
    "t = [x for x in pcodes if x not in codes.index]\n",
    "wd_ni = work_data[~work_data.code.isin(t)].copy()\n",
    "\n",
    "# ! aggregating to Gfrags, Gcaps and Gfoams !\n",
    "# these items are not well divided into the composite subgroups\n",
    "# for example people often know what a cap is, but whether it \n",
    "# comes from a drink bottle or other type is not well considered\n",
    "# we combine the subcategories into more comprehensive groups.\n",
    "ti = rc.use_gfrags_gfoams_gcaps(wd_ni, codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b312536-835e-49d2-9c4c-4ffbee2c6280",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! groupby the sample id and code otherwise there are duplicate codes\n",
    "# after aggregating to Gfrags etc..\n",
    "work_data = ti.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "work_data['pcs/m²'] = work_data['quantité']/work_data['area']\n",
    "\n",
    "# accounting for objects not found at a sample:\n",
    "# the codes that were indentified are the unique codes\n",
    "# in the set of data, they are the 'inventory'\n",
    "codes_ip = work_data.code.unique()\n",
    "# the unique samples by id\n",
    "loc_dates = work_data['échantillon'].unique()\n",
    "\n",
    "# a copy for itterating\n",
    "wd = work_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f20caec-1c55-46df-afa6-1c2b0f1b36f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_39fed tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_39fed tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_39fed tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_39fed th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_39fed td {\n  padding: 4px;\n  text-align: center;\n}\n#T_39fed caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_39fed\">\n  <caption><b>Table A5-5 :</b> La densité de l'échantillon si les zones et les substrats ne sont pas combinés pour chaque échantillon.</caption>\n  <thead>\n    <tr>\n      <th id=\"T_39fed_level0_col0\" class=\"col_heading level0 col0\" >Plage</th>\n      <th id=\"T_39fed_level0_col1\" class=\"col_heading level0 col1\" >Date</th>\n      <th id=\"T_39fed_level0_col2\" class=\"col_heading level0 col2\" >Code</th>\n      <th id=\"T_39fed_level0_col3\" class=\"col_heading level0 col3\" >pcs/m²</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_39fed_row0_col0\" class=\"data row0 col0\" >Amphion</td>\n      <td id=\"T_39fed_row0_col1\" class=\"data row0 col1\" >01.02.2022</td>\n      <td id=\"T_39fed_row0_col2\" class=\"data row0 col2\" >G27</td>\n      <td id=\"T_39fed_row0_col3\" class=\"data row0 col3\" >0,01</td>\n    </tr>\n    <tr>\n      <td id=\"T_39fed_row1_col0\" class=\"data row1 col0\" >Amphion</td>\n      <td id=\"T_39fed_row1_col1\" class=\"data row1 col1\" >01.02.2022</td>\n      <td id=\"T_39fed_row1_col2\" class=\"data row1 col2\" >Gfrags</td>\n      <td id=\"T_39fed_row1_col3\" class=\"data row1 col3\" >0,56</td>\n    </tr>\n    <tr>\n      <td id=\"T_39fed_row2_col0\" class=\"data row2 col0\" >Clarens</td>\n      <td id=\"T_39fed_row2_col1\" class=\"data row2 col1\" >16.01.2022</td>\n      <td id=\"T_39fed_row2_col2\" class=\"data row2 col2\" >G27</td>\n      <td id=\"T_39fed_row2_col3\" class=\"data row2 col3\" >0,04</td>\n    </tr>\n    <tr>\n      <td id=\"T_39fed_row3_col0\" class=\"data row3 col0\" >Clarens</td>\n      <td id=\"T_39fed_row3_col1\" class=\"data row3 col1\" >16.01.2022</td>\n      <td id=\"T_39fed_row3_col2\" class=\"data row3 col2\" >Gfrags</td>\n      <td id=\"T_39fed_row3_col3\" class=\"data row3 col3\" >0,02</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x74cd68191580>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_4"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_data.loc[start_data.Code.isin(gfrags_c), 'Code'] = 'Gfrags'\n",
    "\n",
    "display_columns = [\"Plage\", \"Date\", \"Position\", \"Substrat\", \"Aire\",  \"Code\", \"Quantité\", \"pcs/m²\"]\n",
    "\n",
    "start_data = start_data.groupby([\"Plage\", \"Date\", \"Aire\", \"Code\"], as_index=False)[\"Quantité\"].sum()\n",
    "\n",
    "start_data[\"pcs/m²\"] = start_data[\"Quantité\"]/start_data.Aire\n",
    "sd_x = start_data.groupby([\"Plage\", \"Date\", \"Code\"], as_index=False)[\"pcs/m²\"].mean()\n",
    "\n",
    "caption =  f\"<b>{label}5 :</b> La densité de l'échantillon si les zones et les substrats ne sont pas combinés pour chaque échantillon.\" \n",
    "sd_x = sd_x.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption).hide(axis=\"index\")\n",
    "glue(\"start_data_4\", sd_x, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dcec826-504d-4ddd-86dc-2b664bc8ef41",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# a copy for itterating\n",
    "wd = work_data.copy()\n",
    "\n",
    "rows = []\n",
    "for a_loc in loc_dates:\n",
    "    r = wd.loc[wd['échantillon'] == a_loc].copy()\n",
    "    r.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    t = r.loc[0][['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug']].values\n",
    "    asamp = [x for x in t]\n",
    "    used_codes = r.code.unique()\n",
    "    unused = [x for x in codes_ip if x not in used_codes]\n",
    "    for element in unused:\n",
    "        arow = [*asamp, element, 0, 0]\n",
    "        rows.append(arow)\n",
    "        \n",
    "\n",
    "# now all the data has the same number of records per sample\n",
    "# for each sample we can now say what was found and what was\n",
    "# not found with respect to all the results\n",
    "work_x = pd.DataFrame(rows, columns=['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug', 'code', 'quantité', 'pcs/m²'])\n",
    "work_data = pd.concat([work_x, work_data])\n",
    "\n",
    "\n",
    "# add the regional component\n",
    "work_data['region'] = work_data.slug.apply(lambda x: regions.loc[x, 'alabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ca1a66c-911a-496e-ae2d-277bee82d5f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n#T_e9e68 tr:nth-child(even) {\n  background-color: rgba(139, 69, 19, 0.08);\n}\n#T_e9e68 tr:nth-child(odd) {\n  background: #FFF;\n}\n#T_e9e68 tr {\n  font-size: 14px;\n  padding: 6px;\n}\n#T_e9e68 th:nth-child(1) {\n  background-color: #FFF;\n  white-space: nowrap;\n  word-break: keep-all;\n}\n#T_e9e68 td {\n  padding: 4px;\n  text-align: center;\n}\n#T_e9e68 caption {\n  caption-side: bottom;\n  font-size: 14px;\n  text-align: left;\n  margin-top: 14px;\n}\n</style>\n<table id=\"T_e9e68\">\n  <caption><b>Table A5-4 :</b> The density of sample if the areas are combined. The result for each sample is the sum of the different results for the different positions and substrates for each sample.</caption>\n  <thead>\n    <tr>\n      <th id=\"T_e9e68_level0_col0\" class=\"col_heading level0 col0\" >échantillon</th>\n      <th id=\"T_e9e68_level0_col1\" class=\"col_heading level0 col1\" >Plage</th>\n      <th id=\"T_e9e68_level0_col2\" class=\"col_heading level0 col2\" >Substrat</th>\n      <th id=\"T_e9e68_level0_col3\" class=\"col_heading level0 col3\" >Aire</th>\n      <th id=\"T_e9e68_level0_col4\" class=\"col_heading level0 col4\" >Code</th>\n      <th id=\"T_e9e68_level0_col5\" class=\"col_heading level0 col5\" >Quantité</th>\n      <th id=\"T_e9e68_level0_col6\" class=\"col_heading level0 col6\" >pcs/m²</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_e9e68_row0_col0\" class=\"data row0 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_e9e68_row0_col1\" class=\"data row0 col1\" >Amphion</td>\n      <td id=\"T_e9e68_row0_col2\" class=\"data row0 col2\" >4</td>\n      <td id=\"T_e9e68_row0_col3\" class=\"data row0 col3\" >440</td>\n      <td id=\"T_e9e68_row0_col4\" class=\"data row0 col4\" >G27</td>\n      <td id=\"T_e9e68_row0_col5\" class=\"data row0 col5\" >4</td>\n      <td id=\"T_e9e68_row0_col6\" class=\"data row0 col6\" >0,01</td>\n    </tr>\n    <tr>\n      <td id=\"T_e9e68_row1_col0\" class=\"data row1 col0\" >('amphion', '01.02.2022')</td>\n      <td id=\"T_e9e68_row1_col1\" class=\"data row1 col1\" >Amphion</td>\n      <td id=\"T_e9e68_row1_col2\" class=\"data row1 col2\" >4</td>\n      <td id=\"T_e9e68_row1_col3\" class=\"data row1 col3\" >440</td>\n      <td id=\"T_e9e68_row1_col4\" class=\"data row1 col4\" >Gfrags</td>\n      <td id=\"T_e9e68_row1_col5\" class=\"data row1 col5\" >334</td>\n      <td id=\"T_e9e68_row1_col6\" class=\"data row1 col6\" >0,76</td>\n    </tr>\n    <tr>\n      <td id=\"T_e9e68_row2_col0\" class=\"data row2 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_e9e68_row2_col1\" class=\"data row2 col1\" >Clarens</td>\n      <td id=\"T_e9e68_row2_col2\" class=\"data row2 col2\" >2</td>\n      <td id=\"T_e9e68_row2_col3\" class=\"data row2 col3\" >340</td>\n      <td id=\"T_e9e68_row2_col4\" class=\"data row2 col4\" >G27</td>\n      <td id=\"T_e9e68_row2_col5\" class=\"data row2 col5\" >11</td>\n      <td id=\"T_e9e68_row2_col6\" class=\"data row2 col6\" >0,03</td>\n    </tr>\n    <tr>\n      <td id=\"T_e9e68_row3_col0\" class=\"data row3 col0\" >('clarens', '16.01.2022')</td>\n      <td id=\"T_e9e68_row3_col1\" class=\"data row3 col1\" >Clarens</td>\n      <td id=\"T_e9e68_row3_col2\" class=\"data row3 col2\" >2</td>\n      <td id=\"T_e9e68_row3_col3\" class=\"data row3 col3\" >340</td>\n      <td id=\"T_e9e68_row3_col4\" class=\"data row3 col4\" >Gfrags</td>\n      <td id=\"T_e9e68_row3_col5\" class=\"data row3 col5\" >5</td>\n      <td id=\"T_e9e68_row3_col6\" class=\"data row3 col6\" >0,01</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x74ccdbef76d0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "start_data_5"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (work_data[\"échantillon\"].isin(loc_dates_t))&(work_data.code.isin([\"Gfrags\", \"G27\"]))\n",
    "display_columns = [\"échantillon\", \"Plage\", \"Substrat\", \"Aire\",  \"Code\", \"Quantité\", \"pcs/m²\"]\n",
    "test = work_data[mask].copy()\n",
    "test = test.rename(columns={\"substrat\":\"Substrat\", \"area\":\"Aire\", \"date\":\"Date\", \"code\":\"Code\", \"quantité\":\"Quantité\"})\n",
    "test = test[display_columns].copy()\n",
    "\n",
    "caption =  f\"<b>{label}4 :</b> The density of sample if the areas are combined. The result for each sample is the sum of the different results for the different positions and substrates for each sample.\"\n",
    "sd_5 = test.style.set_table_styles(table_css_styles).format(**psc.format_kwargs).set_caption(caption).hide(axis=\"index\")\n",
    "glue(\"start_data_5\", sd_5, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e9ced6-3c60-4de3-a8ff-3bdf7375a5f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "work_data.to_csv('data/end_pipe/macro_data_msquared.csv', index=False)\n",
    "work_data_example = work_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ac9be-e6b2-44ad-a2be-7c6edb04f112",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exemple\n",
    "\n",
    "#### Mètres carrés\n",
    "\n",
    "Pour illustrer les changements apportés aux données, considérons deux échantillons et deux codes (G27, Gfrags). Le premier échantillon est Amphion le 2022-02-01 et le second est Clarens le 2022-01-16. À Amphion, il y a plusieurs valeurs pour les mêmes codes le même jour. Il en va de même pour Clarens, mais à Clarens, il y a également deux substrats pour la plage. Notez que les codes G78 et G79 font partie du code combiné Gfrags.\n",
    "\n",
    "```{glue} start_data\n",
    "```\n",
    "\n",
    "Pour combiner les données, nous devons additionner les surfaces pour chaque échantillon, appliquer la nouvelle surface à tous les comptages d'objets pour cet échantillon et ce jour, et supprimer la variable de position. Pour Amphion, la surface totale est de 342 + 98 = 440 m², pour Clarens 273 + 67 = 340 m².\n",
    "\n",
    "```{glue} start_data_2\n",
    "``` \n",
    "\n",
    "Après avoir combiné tous les totaux de codes pour chaque échantillon et remplacé le substrat 4 par le substrat 2 dans toutes les localités qui ont des valeurs de substrat distinctes pour la position, nous nous retrouvons encore avec des codes en double sur un échantillon.\n",
    "\n",
    "```{glue} start_data_3\n",
    "``` \n",
    "\n",
    "Dans la dernière étape, les codes qui doivent être combinés (G78 et G79) sont placés sous un seul code et les données sont agrégées à l'identifiant de l'échantillon (date et lieu de l'échantillon).  \n",
    "\n",
    "```{glue} start_data_5\n",
    "```\n",
    "\n",
    "#### La différence\n",
    "\n",
    "Si les surfaces des positions ne sont pas combinées, les valeurs attendues sont beaucoup plus faibles. En effet, nous sommes obligés de prendre la moyenne de la densité des deux positions et des substrats pour chaque échantillon. \n",
    "\n",
    "```{glue} start_data_4\n",
    "``` \n",
    "\n",
    "__Problème de communication :__ Cela peut être difficile à communiquer. La moyenne pour une région est la moyenne de la densité totale par échantillon. C'est-à-dire le nombre total d'objets divisé par la surface totale. Cependant, dans ce cas, la moyenne de la région est la moyenne des moyennes par échantillon.\n",
    "\n",
    "Cela signifie que la médiane d'une région serait la médiane de la moyenne des moyennes par échantillon. \n",
    "\n",
    "\n",
    "#### Mètres linéaires\n",
    "\n",
    "L'opération de transformation des données en mètres linéaires est différente. Pour convertir toutes les plages en une seule section, nous abandonnons la variable superficie et la remplaçons par les données de longueur fournies. La longueur est la même pour les deux sections de chaque plage (les surfaces sont différentes), nous avons donc divisé la somme de tous les objets par la longueur donnée pour l'échantillon. Ce processus est conforme à la norme décrite dans le guide de surveillance des déchets marins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee325418-ef53-42e0-b3a7-41a0e63f362f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# reading in data\n",
    "new_datai = pd.read_csv(\"data/end_pipe/macro_current.csv\")\n",
    "beach_data = pd.read_csv(\"data/end_pipe/pstock_beaches_current.csv\")\n",
    "\n",
    "\n",
    "# adding the lenght of each sample to the results\n",
    "length_key = beach_data[[\"Plage\",\"length\"]].drop_duplicates(\"Plage\").set_index(\"Plage\")\n",
    "work_datai = new_datai[[\"Plage\", *new_column_names.keys()]].copy()\n",
    "work_datai.rename(columns=new_column_names, inplace=True)\n",
    "work_datai[\"length\"] = work_datai.Plage.apply(lambda x: length_key.loc[x, \"length\"])\n",
    "\n",
    "# making a sample id from the location and date\n",
    "work_datai[\"slug\"] = work_datai.Plage.apply(lambda x: slugify(x))\n",
    "work_datai[\"echantillon\"] = list(zip(work_datai.slug, work_datai['date']))\n",
    "work_datai['date'] = pd.to_datetime(work_datai[\"date\"], format=\"mixed\", dayfirst=True)\n",
    "work_datai.dropna(inplace=True)\n",
    "\n",
    "# defining the data type of columns\n",
    "work_datai[[\"position\", \"substrat\"]] = work_datai[[\"position\", \"substrat\"]].astype(\"int\")\n",
    "\n",
    "# changing the column name to human readable\n",
    "work_datai['échantillon'] = work_datai['echantillon']\n",
    "work_datai.drop(['echantillon'], inplace=True, axis=1)\n",
    "\n",
    "# removing the position variable from data and\n",
    "# grouping by sample id and code to get the total per sample per code\n",
    "work_datai = work_datai.groupby(['échantillon', 'Plage', 'substrat', 'date', 'length', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "\n",
    "# divide that by length\n",
    "work_datai['pcs/m'] = work_datai['quantité']/work_datai['length']\n",
    "\n",
    "# add the region\n",
    "work_datai['region'] = work_datai.slug.apply(lambda x: regions.loc[x, 'alabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b630682-b5af-4834-aead-886e668ab981",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! combining the substrates for beaches where there are two substrates !\n",
    "voi = 'substrat'\n",
    "vals = \"pcs/m\"\n",
    "some_data = work_datai.copy()\n",
    "groupby = ['échantillon', voi]\n",
    "data = some_data.groupby(groupby, as_index=False)[vals].sum()\n",
    "\n",
    "# these are the duplicate values that need to be changed\n",
    "dd = data[data['échantillon'].duplicated()].copy()\n",
    "\n",
    "duplicated = work_datai[work_datai['échantillon'].isin(dd['échantillon'].unique())].copy()\n",
    "duplicated['substrat'] = 2 \n",
    "\n",
    "# notduplicated\n",
    "not_duplicated = work_datai[~(work_datai['échantillon'].isin(dd['échantillon'].unique()))].copy()\n",
    "\n",
    "# put it back to gether again\n",
    "work_datai = pd.concat([duplicated, not_duplicated])\n",
    "\n",
    "# groupby the new substrat values and calculate pcs/m\n",
    "work_datai = work_datai.groupby(['échantillon', 'Plage', 'region', 'substrat', 'date', 'length', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "work_datai['pcs/m'] = work_datai['quantité']/work_datai['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d02150b6-e677-4bed-9c12-22a4a1051a30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! defining the total inventory of the current data !\n",
    "# accounting for objects not found at a sample:\n",
    "# the codes that were indentified at least once = inventory\n",
    "# defining the components of the inventory\n",
    "codes_ip = work_datai.code.unique()\n",
    "\n",
    "# the unique samples\n",
    "loc_dates = work_datai['échantillon'].unique()\n",
    "\n",
    "# a copy for itterating\n",
    "wd = work_datai.copy()\n",
    "\n",
    "# for each sample (échantillon) indentify the codes that were not\n",
    "# found by indentifying all the codes that were found in all surveys\n",
    "# and removing the codes that were not identified at that sample.\n",
    "# for each unidentified code per sample, add a row with the sample\n",
    "# id and the code. give the row a quantity of zero.\n",
    "rows = []\n",
    "for a_loc in loc_dates:\n",
    "    r = wd.loc[wd['échantillon'] == a_loc].copy()\n",
    "    r.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    t = r.loc[0][['échantillon', 'Plage', 'region', 'substrat', 'date', 'length', 'slug']].values\n",
    "    asamp = [x for x in t]\n",
    "    used_codes = r.code.unique()\n",
    "    unused = [x for x in codes_ip if x not in used_codes]\n",
    "    for element in unused:\n",
    "        arow = [*asamp, element, 0, 0]\n",
    "        rows.append(arow)\n",
    "        \n",
    "\n",
    "work_x = pd.DataFrame(rows, columns=['échantillon', 'Plage', 'region', 'substrat', 'date', 'length', 'slug', 'code', 'quantité', 'pcs/m'])\n",
    "work_datai = pd.concat([work_x, work_datai])\n",
    "\n",
    "work_datai.to_csv(\"data/end_pipe/macro_data_linearm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6630bb21-7043-4683-8191-da850f35c832",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# micro plastics\n",
    "\n",
    "# these samples were not completed\n",
    "\n",
    "# drop_these = ['VD_Cul_2', 'VD_Vid_13', 'VD_Vid_8', 'VS_Bou_12']\n",
    "\n",
    "\n",
    "# work_data = pd.read_csv(\"data/inprocess/micros_new_integrated.csv\")\n",
    "# work_data = work_data[~work_data[\"échantillon\"].isin(drop_these)].copy()\n",
    "\n",
    "\n",
    "# work_data.to_csv(\"data/end_pipe/long_form_micro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82bdb7f-e987-4f52-acdb-4dad0c12b9a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Analyse et inférence\n",
    "\n",
    "We used two methods of approximation to infer the expected results: _Random Forest Regression_ and _Bayesian grid approximation_. The random forest regression is centered around the average of the observed data. The samples drawn from the random forest regression do not approximate the distribution of the observed results, which are skewed. For predictions we have opted for the Bayesian grid approximation.\n",
    "\n",
    "__Bayesian Grid Approximation:__\n",
    "<br />\n",
    "\n",
    "1. **Type of Model**: This approach is grounded in Bayesian statistics. It's not a specific model but a method for estimating or approximating the posterior distribution of model parameters.\n",
    "2. **How it Works**: Involves specifying a prior distribution for the parameters, a likelihood function based on the data, and then using computational techniques (like grid approximation) to estimate the posterior distribution of the parameters.\n",
    "3. **Key Features**:\n",
    "   - **Uncertainty Estimation**: Provides a probabilistic interpretation and a way to estimate uncertainty in predictions.\n",
    "   - **Prior Knowledge**: Incorporates prior knowledge or beliefs about the parameters through the prior distribution.\n",
    "   - **Computationally Intensive**: For high-dimensional parameter spaces, grid approximation can become impractical.\n",
    "   - **Flexibility**: Can be applied to a wide range of models, including linear models, hierarchical models, etc.\n",
    "\n",
    "__Key Differences with random forest:__\n",
    "<br />\n",
    "\n",
    "- **Fundamental Approach**: Random Forest is a machine learning algorithm based on decision trees, while Bayesian Grid Approximation is a statistical method for estimating parameter distributions.\n",
    "- **Output**: Random Forest provides a single predictive model. Bayesian methods provide a distribution of possible models, giving a sense of uncertainty.\n",
    "- **Complexity and Computation**: Random Forest is generally straightforward and less computationally intensive compared to Bayesian methods, especially for large datasets or models with many parameters.\n",
    "- **Interpretability**: Random Forests can be less interpretable due to the ensemble nature of many trees, whereas Bayesian methods offer probabilistic interpretations that can be insightful but might require a deeper statistical understanding.\n",
    "\n",
    "Each method has its strengths and is suitable for different kinds of problems and data sets. The choice between them depends on the specific requirements of the analysis, such as the need for uncertainty quantification, computational resources, and the nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dc73f86-63fa-4616-88e1-6d26d7a4d5f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# reading in data\n",
    "# new_data = pd.read_csv(\"data/end_pipe/macro_current.csv\")\n",
    "work_data = pd.read_csv(\"data/end_pipe/macro_data_linearm.csv\")\n",
    "beach_data = pd.read_csv(\"data/end_pipe/pstock_beaches_current.csv\")\n",
    "\n",
    "# historical data\n",
    "hist_leman = pd.read_csv(\"data/end_pipe/hist_leman.csv\")\n",
    "# ghi = pd.read_csv('data/end_pipe/iqaasl.csv')\n",
    "hiqaasl = hist_leman.copy()\n",
    "hiqaasl.rename(columns={\"sample_id\":\"loc_date\", \"location\":\"slug\", 'pcs/m':'pcs_m'}, inplace=True)\n",
    "iq_cols = ['loc_date', 'date', 'slug', 'code', 'quantity', 'city', 'feature_name', 'feature_type', 'parent_boundary', 'pcs_m', 'project', 'region']\n",
    "\n",
    "ghi = hiqaasl[iq_cols].copy()\n",
    "\n",
    "\n",
    "\n",
    "# most recent results not plastock\n",
    "ssp=pd.read_csv('data/end_pipe/swt_all.csv')\n",
    "\n",
    "# # the independent variables are in asl_beaches file\n",
    "beach_data_f = pd.read_csv(\"data/end_pipe/asl_beaches.csv\").set_index('Plage')\n",
    "\n",
    "# # code definitions\n",
    "# codes = pd.read_csv('data/end_pipe/codes.csv').set_index('code')\n",
    "\n",
    "# add the regional component\n",
    "# the regional labels for each survey location\n",
    "regions = pd.read_csv(\"data/end_pipe/lac_leman_regions.csv\")\n",
    "regions.set_index('slug', drop=True, inplace=True)\n",
    "\n",
    "# # the city designation is used for reporting\n",
    "# # the city name of the survey locations\n",
    "# city_map = pd.read_csv('data/end_pipe/city_map.csv')\n",
    "# city_map.set_index('slug', inplace=True)\n",
    "\n",
    "codes_ip = work_data.code.unique()\n",
    "\n",
    "change_names = ['preverenges', 'tolochenaz', 'versoix', 'vidy', 'cully']\n",
    "\n",
    "plastock_cols = ['loc_date', 'date','slug','region', 'code', 'quantity', 'city', 'feature_name', 'feature_type','parent_boundary', 'pcs_m']\n",
    "features = ['frequentation', 'situation', 'orientation', 'distance']\n",
    "\n",
    "changeus = work_data[work_data.slug.isin(change_names)].copy()\n",
    "donotchange = work_data[~work_data.slug.isin(change_names)].copy()\n",
    "\n",
    "new_slug = {\n",
    "    'cully': 'cully-p',\n",
    "    'preverenges': 'preverenges-p',\n",
    "    'tolochenaz': 'tolochenaz-p',\n",
    "    'versoix':'versoix-p',\n",
    "    'vidy': 'vidy-p'}\n",
    "\n",
    "# they have the same name as locations in iqaasl\n",
    "changeus['new_slug'] = changeus.slug.apply(lambda x: new_slug[x])\n",
    "changeus['slug'] = changeus.new_slug\n",
    "changeus.drop('new_slug', inplace=True, axis=1)\n",
    "\n",
    "# the plastock data with the converted names\n",
    "wd_nn = pd.concat([changeus, donotchange])\n",
    "\n",
    "# # plastock did not use the same inventory as iqaasl\n",
    "# # here we select only the codes in the plastock inventory\n",
    "# pcodes = wd_nn.code.unique()\n",
    "\n",
    "# identify and remove codes for which there is no defintion\n",
    "# if the code is not defined then it can not be used\n",
    "t = [x for x in codes_ip if x not in codes.index]\n",
    "wd_ni = wd_nn[~wd_nn.code.isin(t)].copy()\n",
    "\n",
    "\n",
    "# ! aggregating plastic caps, fragmented plastics, fragmented foams !\n",
    "# these items are not well divided into the composite subgroups\n",
    "# for example people often know what a cap is, but whether it \n",
    "# comes from a drink bottle or other type is not well considered\n",
    "# we combine the subcategories into more comprehensive groups.\n",
    "ti = rc.use_gfrags_gfoams_gcaps(wd_ni, codes)\n",
    "\n",
    "\n",
    "# formatting data for reporting\n",
    "# aggregate along all land-use and topo variables.\n",
    "ti = ti.groupby(['échantillon', 'Plage', 'region', 'date', 'substrat', 'length', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "\n",
    "# !combinining with previous results!\n",
    "# these are the default arguments for the report class\n",
    "# the language maps gives the code definitions in english, german and french\n",
    "# the top_label asserts the top level aggregation for the set of data defined by\n",
    "# start, end dates and feature_name. These arguments are for the plastock data\n",
    "language_maps = rc.language_maps()\n",
    "top_label= ['feature_name', 'lac-leman']\n",
    "\n",
    "# the default language is english in the report column class\n",
    "# there are column names that need to be changed\n",
    "new_names = {'échantillon': 'loc_date', 'pcs/m': 'pcs_m'}\n",
    "ti.rename(columns={**new_names,'quantité': 'quantity'}, inplace=True)\n",
    "\n",
    "# define the pcs/m column and the data to merge\n",
    "ti['pcs_m'] = ti.quantity/ti.length\n",
    "\n",
    "# adding and renaming columns according to reportclass requirements\n",
    "# these values can be indexed on the IQAASL data\n",
    "ti['city'] = ti.slug.apply(lambda x: city_map.loc[x])\n",
    "ti['feature_name'] = 'lac-leman'\n",
    "ti['feature_type'] = 'l'\n",
    "ti['parent_boundary'] = 'rhone'\n",
    "\n",
    "# ! adding feature columns to survey data !\n",
    "# they can be merged on the Plage column and the index\n",
    "# these are used for modeling\n",
    "env_plastock = ti.merge(beach_data_f[features], left_on='Plage', right_index=True)\n",
    "env_plastock = env_plastock[[*plastock_cols, *features, 'substrat']]\n",
    "\n",
    "# ! the data for reporting !\n",
    "ti_work = ti[plastock_cols].copy()\n",
    "\n",
    "# this data is formatted to work with the reporting structure of IQAASL\n",
    "# the landuse data is not included here.\n",
    "ti_work = ti_work.groupby(plastock_cols, as_index=False).agg(psc.unit_agg)\n",
    "ti_work['project']='Pla\\'stock'\n",
    "\n",
    "# merge the data and select only the current codes from plastock\n",
    "txi = pd.concat([ghi, ti_work[[*plastock_cols, 'project']].copy()])\n",
    "txi.reset_index(inplace=True)\n",
    "txi = txi[txi.code.isin(ti_work.code.unique())]\n",
    "\n",
    "# a report that includes both sets of data\n",
    "boundaries = dict(start_date=\"2015-11-15\", end_date=\"2023-01-01\", feature_name=\"lac-leman\", language=\"fr\")\n",
    "current = rc.ReportClass(txi.copy(), boundaries=boundaries, language=\"fr\", lang_maps=language_maps, top_label=top_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29203936-b867-4791-9473-648c6ec3f756",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "mc, weight = current.most_common\n",
    "mc.index\n",
    "\n",
    "# they can be merged on the Plage column and the index\n",
    "# env_plastock = ti.merge(beach_datax[features], left_on='Plage', right_index=True)\n",
    "\n",
    "# ! creation of composite variables !\n",
    "t_and_f = env_plastock.loc[:, ['loc_date', 'slug','date','code', 'pcs_m', 'quantity', 'frequentation', 'situation', 'distance', 'substrat', 'region']].copy()\n",
    "\n",
    "# the substrat and distance features are being combined\n",
    "# the two lowest and the two highest of each group are being combined\n",
    "# substrat is a matter of combining different granularities. They are being grouped as\n",
    "# sand and gravel.\n",
    "# distance is now grouped by locations either less than or equal to 500 meters\n",
    "t_and_f.loc[t_and_f.substrat <= 2, 'substrat'] = 1\n",
    "t_and_f.loc[t_and_f.substrat > 2, 'substrat'] = 2\n",
    "t_and_f.loc[t_and_f.distance <= 2, 'distance'] = 1\n",
    "t_and_f.loc[t_and_f.distance > 2, 'distance'] = 2\n",
    "t_and_f.loc[t_and_f.frequentation <= 2, 'frequentation'] = 2\n",
    "\n",
    "# ! the data used in the models !\n",
    "f_combi = t_and_f.copy()\n",
    "\n",
    "f_combi.rename(columns={'frequentation':'fréquentation', 'loc_date': 'échantillon'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbfca710-6be8-4d51-9448-27f9739195e5",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def sum_a_b(zipped):\n",
    "    f = []\n",
    "    for element in zipped:\n",
    "        # # print(element[0])\n",
    "        # # the new beta distribution would be\n",
    "        # # total success, (total tries - total success)\n",
    "        # obs = element[0]\n",
    "        # obs2 = element[1]\n",
    "        \n",
    "        # new_element_0 = np.array([obs[0], obs[1] - obs[0]])\n",
    "        # new_element_1 = np.array([obs2[0], obs2[1] - obs2[0]])\n",
    "        t3 = element[0] + element[1]\n",
    "        if t3[0] < 1 :\n",
    "            t3 = np.array([1, 250])\n",
    "        if t3[1] < 1:\n",
    "            t3 = np.array([t3[0], 1])\n",
    "        \n",
    "        f.append(t3)\n",
    "    return f\n",
    "def draw_a_beta_value(posteriors):\n",
    "    # d = next(generator)\n",
    "    # drawing a random number from the beta distribution\n",
    "    # this is the the chance p, that a binomial distribution will\n",
    "    # result in True.\n",
    "    my_beta = [beta.rvs(x[0], x[1], size=1) for x in posteriors]\n",
    "    return my_beta\n",
    "\n",
    "\n",
    "def calculate_likelihood(*, aggregated_data: pd.DataFrame, bin_density_column: str, pcs_column: str = 'pcs/m',\n",
    "                         grid_range: np.ndarray = None, bins: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the likelihood of observing the aggregated pcs/m data for each grid point and bin density value.\n",
    "\n",
    "    Args:\n",
    "        aggregated_data (pd.DataFrame): The aggregated data to be used for likelihood calculation.\n",
    "        bin_density_column (str): The column representing bin density numbers.\n",
    "        pcs_column (str, optional): The pcs/m column to use for calculation. Defaults to 'pcs/m'.\n",
    "        grid_range (np.ndarray, optional): The range of grid values. Defaults to np.linspace(0, 9.99, 1000).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with likelihood values for each grid value and bin density number.\n",
    "    \"\"\"\n",
    "    likelihood_df = pd.DataFrame(index=grid_range)\n",
    "    likelihoods = []\n",
    "    for bin_value in bins:\n",
    "        bin_data = aggregated_data[aggregated_data[bin_density_column] == bin_value]\n",
    "        \n",
    "        if bin_data.empty:\n",
    "            likelihoods = [np.array([1, 1]) for grid_point in grid_range]\n",
    "        else:\n",
    "            for grid_point in grid_range:\n",
    "                passed = (bin_data[pcs_column] > grid_point).sum()\n",
    "                tries = len(bin_data)\n",
    "                fails = tries - passed\n",
    "                if passed < 1:\n",
    "                    fails=250\n",
    "                likelihood = np.array([passed, fails])\n",
    "                likelihoods.append(likelihood)\n",
    "    likelihood_df[f'Likelihood_{bin_value}'] = likelihoods\n",
    "    return likelihood_df\n",
    "\n",
    "\n",
    "def binomial_probability_of_failure(generator):\n",
    "    # in this case failure means exceeding the value\n",
    "    # for trash a success is never exceeding the value\n",
    "    d = next(generator)\n",
    "    di = [x[0] for x in d]\n",
    "    yield di\n",
    "def define_posterior(likelihood, prior, grid_val_index: np.array = None):\n",
    "    # the alpha, beta parameters of the likelihood and prior are assembled\n",
    "    alpha_beta = list(zip(likelihood, prior))\n",
    "    # this is a generator that yields the sum of the alpha, beta parameters\n",
    "    # of the likelihood and prior. It generates one value for each point on the grid.\n",
    "    a_b_sum = sum_a_b(alpha_beta)\n",
    "    \n",
    "    posteriors = [beta(x[0], x[1]).mean() for x in a_b_sum]\n",
    "    for i in grid_val_index:\n",
    "        # the sum of successes and failures for the scenario at the given\n",
    "        # grid value are used as the alpha, beta parameters of the beta distribtion\n",
    "        # for the binomial/bernouli probability that a sample will exceed the grid\n",
    "        # value i.\n",
    "        st = binomial_probability_of_failure(draw_a_beta_value(a_b_sum))\n",
    "        val = next(st)\n",
    "        posteriors.append(val)\n",
    "    \n",
    "    # return posterior probabilities with gird index and column labels\n",
    "    post_grid_pstock = pd.DataFrame(posteriors, index=grid_val_index, columns=prior.columns)\n",
    "    \n",
    "    # identify the x scale of the grid\n",
    "    post_grid_pstock['X'] = post_grid_pstock.index\n",
    "    \n",
    "    # this column is the normalized probabilities that a sample\n",
    "    # will exceed a value on the grid.\n",
    "    post_grid_pstock['norm'] = post_grid_pstock['Bin_1'] / post_grid_pstock['Bin_1'].sum()\n",
    "    \n",
    "    return post_grid_pstock\n",
    "order = [\"Haut lac\", \"Grand lac\",  \"Petit lac\"]\n",
    "\n",
    "def region_and_code(df, code, regions=order):\n",
    "    # returns the survey results for a region and a code\n",
    "    ds = []\n",
    "    for region in regions:\n",
    "        mask = (df.code == code)&(df.region == region)\n",
    "        d = df[mask]\n",
    "        d = d.groupby(['loc_date', 'project', 'region'], as_index=False).pcs_m.sum()\n",
    "        d[\"region\"] = ordinal[region]\n",
    "        ds.append(d)\n",
    "    return ds\n",
    "\n",
    "def region_samp_total(df, regions=order):\n",
    "    ds = []\n",
    "    for region in regions:\n",
    "        mask = (df.region == region)\n",
    "        d = df[mask]\n",
    "        d = d.groupby(['loc_date', 'project', 'region'], as_index=False).pcs_m.sum()\n",
    "        d[\"region\"] = ordinal[region]\n",
    "        ds.append(d)\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "412ba060-1da9-4d5e-ad35-d8fe2ba729b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "prior_data = current.w_df.copy()\n",
    "prior_data = prior_data[~prior_data.isna()]\n",
    "\n",
    "prior_data['region'] = prior_data.slug.apply(lambda x: regions.loc[x, 'alabel'])\n",
    "prior_data = prior_data.loc[prior_data.code.isin(mc.index)]\n",
    "prd= prior_data[prior_data.project == \"IQAASL\"].copy()\n",
    "ps= prior_data[prior_data.project == \"Pla\\'stock\"].copy()\n",
    "\n",
    "\n",
    "grid_val_index = np.linspace(0, 19.99, 2000)\n",
    "groupby_columns = ['sample_id', 'location', 'date', 'city', 'orchards', 'vineyards', 'buildings', 'forest',\n",
    "                   'undefined', 'public_services', 'streets']\n",
    "\n",
    "ordinal = {x:i+1 for i,x in enumerate(order)}\n",
    "\n",
    "beta_prior = pstk.calculate_beta_prior(grid_range=grid_val_index, bin_density_numbers=[1])\n",
    "\n",
    "code_results = {}\n",
    "for acode in mc.index:\n",
    "    u = region_and_code(prd.copy(), acode)\n",
    "    pk = region_and_code(ps.copy(), acode)\n",
    "    \n",
    "    hlprior = u[0]\n",
    "    hlc = pk[0]\n",
    "    results = {}\n",
    "    for i, n in enumerate(order):\n",
    "        hlx = calculate_likelihood(aggregated_data=u[i].copy(), bin_density_column='region', pcs_column='pcs_m', grid_range=grid_val_index, bins=[i+1])\n",
    "        hcx = calculate_likelihood(aggregated_data=pk[i].copy(), bin_density_column='region', pcs_column='pcs_m', grid_range=grid_val_index, bins=[i+1])\n",
    "        hl_v = [x[0] for x in hlx.values]\n",
    "        hc_x = [x[0] for x in hcx.values]\n",
    "        b_v = [x[0] for x in beta_prior.values]\n",
    "    \n",
    "        # the prior distribution\n",
    "        ab = list(zip(hl_v, b_v))\n",
    "        summed = sum_a_b(ab)\n",
    "    \n",
    "        # the likelihoood\n",
    "        summedl = sum_a_b(list(zip(hc_x, b_v)))\n",
    "    \n",
    "        # the posterior\n",
    "        sall = sum_a_b(list(zip(hl_v, hc_x)))\n",
    "    \n",
    "        prior_mean =  [beta(x[0], x[1]).mean() for x in summed]\n",
    "        likeli = [beta(x[0], x[1]).mean() for x in summedl]\n",
    "    \n",
    "        p_fail = [beta(x[0], x[1]).mean() for x in sall]\n",
    "        p_normed = p_fail/np.sum(p_fail)\n",
    "    \n",
    "        res_df = pd.DataFrame(index=grid_val_index)\n",
    "        res_df['alpha-beta-post'] = sall\n",
    "        res_df['prior-mean'] = prior_mean\n",
    "        res_df['observed-mean'] = likeli\n",
    "        res_df[\"beta-post\"] = p_fail\n",
    "        res_df[\"beta-norm\"] = p_normed\n",
    "        res_df[\"bi-post\"] = res_df[\"prior-mean\"]*res_df[\"observed-mean\"]\n",
    "        res_df[\"bi-norm\"] = res_df[\"bi-post\"]/res_df[\"bi-post\"].sum()\n",
    "        res_df[\"X\"] = res_df.index\n",
    "        results.update({n:res_df})\n",
    "    code_results.update({acode:results})\n",
    "\n",
    "samples = []\n",
    "for acode in mc.index:\n",
    "    cr = code_results[acode]\n",
    "    res = {}\n",
    "    for place in order:\n",
    "        rv = multinomial(1, cr[place][\"bi-norm\"].values)\n",
    "        y = rv.rvs(500)\n",
    "        indexes = []\n",
    "        for i in range(0, len(y)):\n",
    "            nip = np.nonzero(y[i])[0]\n",
    "            indexes.extend(nip)\n",
    "        new_bi = pd.DataFrame(grid_val_index, columns=[\"X\"])\n",
    "        samps = new_bi.loc[indexes, \"X\"]\n",
    "        res.update({place:samps})\n",
    "    samples.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e338bd18-f1c5-406b-8665-f3d7eaa621e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "pst = region_samp_total(prd.copy(), regions=order)\n",
    "cst = region_samp_total(ps.copy(), regions=order)\n",
    "\n",
    "resultst = {}\n",
    "for i, n in enumerate(order):\n",
    "    hlx = calculate_likelihood(aggregated_data=pst[i].copy(), bin_density_column='region', pcs_column='pcs_m', grid_range=grid_val_index, bins=[i+1])\n",
    "    hcx = calculate_likelihood(aggregated_data=cst[i].copy(), bin_density_column='region', pcs_column='pcs_m', grid_range=grid_val_index, bins=[i+1])\n",
    "    hl_v = [x[0] for x in hlx.values]\n",
    "    hc_x = [x[0] for x in hcx.values]\n",
    "    b_v = [x[0] for x in beta_prior.values]\n",
    "\n",
    "    # the prior distribution\n",
    "    ab = list(zip(hl_v, b_v))\n",
    "    summed = sum_a_b(ab)\n",
    "\n",
    "    # the likelihoood\n",
    "    summedl = sum_a_b(list(zip(hc_x, b_v)))\n",
    "\n",
    "    # the posterior\n",
    "    sall = sum_a_b(list(zip(hl_v, hc_x)))\n",
    "\n",
    "    prior_mean =  [beta(x[0], x[1]).mean() for x in summed]\n",
    "    likeli = [beta(x[0], x[1]).mean() for x in summedl]\n",
    "\n",
    "    p_fail = [beta(x[0], x[1]).mean() for x in sall]\n",
    "    p_normed = p_fail/np.sum(p_fail)\n",
    "\n",
    "    res_df = pd.DataFrame(index=grid_val_index)\n",
    "    res_df['alpha-beta-post'] = sall\n",
    "    res_df['prior-mean'] = prior_mean\n",
    "    res_df['observed-mean'] = likeli\n",
    "    res_df[\"beta-post\"] = p_fail\n",
    "    res_df[\"beta-norm\"] = p_normed\n",
    "    res_df[\"bi-post\"] = res_df[\"prior-mean\"]*res_df[\"observed-mean\"]\n",
    "    res_df[\"bi-norm\"] = res_df[\"bi-post\"]/res_df[\"bi-post\"].sum()\n",
    "    res_df[\"X\"] = res_df.index\n",
    "    resultst.update({n:res_df})\n",
    "samplest = []\n",
    "for place in order:\n",
    "    rv = multinomial(1, resultst[place][\"bi-norm\"].values)\n",
    "    y = rv.rvs(500)\n",
    "    indexes = []\n",
    "    for i in range(0, len(y)):\n",
    "        nip = np.nonzero(y[i])[0]\n",
    "        indexes.extend(nip)\n",
    "    new_bi = pd.DataFrame(grid_val_index, columns=[\"X\"])\n",
    "    samps = new_bi.loc[indexes, \"X\"]\n",
    "    res.update({place:samps})\n",
    "    samplest.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11259777-a845-4023-b729-536aa988e3ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Haut lac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06b78941-0c56-46ec-b611-b44578e9147c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dbe9c tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_dbe9c tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_dbe9c tr {\n",
       "  font-size: 10px;\n",
       "}\n",
       "#T_dbe9c th {\n",
       "  background-color: #FFF;\n",
       "  font-size: 12px;\n",
       "  text-align: left;\n",
       "  width: auto;\n",
       "  word-break: keep-all;\n",
       "}\n",
       "#T_dbe9c td {\n",
       "  padding: 4px;\n",
       "  font-size: 12px;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_dbe9c caption {\n",
       "  caption-side: bottom;\n",
       "  font-size: 1em;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dbe9c\">\n",
       "  <caption><b>Table A5-6 :</b> Haut lac, la distribution attendue des résultats des échantillons pour 2024.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dbe9c_level0_col0\" class=\"col_heading level0 col0\" >moyenne</th>\n",
       "      <th id=\"T_dbe9c_level0_col1\" class=\"col_heading level0 col1\" >écart-type</th>\n",
       "      <th id=\"T_dbe9c_level0_col2\" class=\"col_heading level0 col2\" >min</th>\n",
       "      <th id=\"T_dbe9c_level0_col3\" class=\"col_heading level0 col3\" >25%</th>\n",
       "      <th id=\"T_dbe9c_level0_col4\" class=\"col_heading level0 col4\" >50%</th>\n",
       "      <th id=\"T_dbe9c_level0_col5\" class=\"col_heading level0 col5\" >75%</th>\n",
       "      <th id=\"T_dbe9c_level0_col6\" class=\"col_heading level0 col6\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe9c_level0_row0\" class=\"row_heading level0 row0\" >Haut lac</th>\n",
       "      <td id=\"T_dbe9c_row0_col0\" class=\"data row0 col0\" >3,17</td>\n",
       "      <td id=\"T_dbe9c_row0_col1\" class=\"data row0 col1\" >3,16</td>\n",
       "      <td id=\"T_dbe9c_row0_col2\" class=\"data row0 col2\" >0,00</td>\n",
       "      <td id=\"T_dbe9c_row0_col3\" class=\"data row0 col3\" >0,82</td>\n",
       "      <td id=\"T_dbe9c_row0_col4\" class=\"data row0 col4\" >2,26</td>\n",
       "      <td id=\"T_dbe9c_row0_col5\" class=\"data row0 col5\" >4,45</td>\n",
       "      <td id=\"T_dbe9c_row0_col6\" class=\"data row0 col6\" >16,40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x74ccdbf09550>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "start_data_6"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_language = current.language\n",
    "display_language_map = current.lang_maps[display_language]\n",
    "columns = ['mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "hl_stot = pd.DataFrame(samplest[0][\"Haut lac\"].describe()).T\n",
    "hl_stot  = hl_stot[columns]\n",
    "\n",
    "hl_stot.index = [\"Haut lac\"]\n",
    "hl_stot = rc.translated_and_style_for_display(hl_stot, display_language_map, display_language, gradient=False)\n",
    "\n",
    "caption =  f\"<b>{label}6 :</b> Haut lac, la distribution attendue des résultats des échantillons pour 2024.\" \n",
    "glue(\"start_data_6\", hl_stot.set_caption(caption), display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7369fa1-6828-4aa3-9b4a-4fc62c5a5191",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_916a8 tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_916a8 tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_916a8 tr {\n",
       "  font-size: 10px;\n",
       "}\n",
       "#T_916a8 th {\n",
       "  background-color: #FFF;\n",
       "  font-size: 12px;\n",
       "  text-align: left;\n",
       "  width: auto;\n",
       "  word-break: keep-all;\n",
       "}\n",
       "#T_916a8 td {\n",
       "  padding: 4px;\n",
       "  font-size: 12px;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_916a8 caption {\n",
       "  caption-side: bottom;\n",
       "  font-size: 1em;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_916a8\">\n",
       "  <caption><b>Table A5-7 :</b> Haut lac, La distribution attendue des objets les plus courants 2024..</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_916a8_level0_col0\" class=\"col_heading level0 col0\" >moyenne</th>\n",
       "      <th id=\"T_916a8_level0_col1\" class=\"col_heading level0 col1\" >écart-type</th>\n",
       "      <th id=\"T_916a8_level0_col2\" class=\"col_heading level0 col2\" >min</th>\n",
       "      <th id=\"T_916a8_level0_col3\" class=\"col_heading level0 col3\" >25%</th>\n",
       "      <th id=\"T_916a8_level0_col4\" class=\"col_heading level0 col4\" >50%</th>\n",
       "      <th id=\"T_916a8_level0_col5\" class=\"col_heading level0 col5\" >75%</th>\n",
       "      <th id=\"T_916a8_level0_col6\" class=\"col_heading level0 col6\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row0\" class=\"row_heading level0 row0\" >Fragments de plastique: g80, g79, g78, g77, g76, g75</th>\n",
       "      <td id=\"T_916a8_row0_col0\" class=\"data row0 col0\" >1,23</td>\n",
       "      <td id=\"T_916a8_row0_col1\" class=\"data row0 col1\" >1,49</td>\n",
       "      <td id=\"T_916a8_row0_col2\" class=\"data row0 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row0_col3\" class=\"data row0 col3\" >0,19</td>\n",
       "      <td id=\"T_916a8_row0_col4\" class=\"data row0 col4\" >0,78</td>\n",
       "      <td id=\"T_916a8_row0_col5\" class=\"data row0 col5\" >1,65</td>\n",
       "      <td id=\"T_916a8_row0_col6\" class=\"data row0 col6\" >8,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row1\" class=\"row_heading level0 row1\" >Mégots et filtres à cigarettes</th>\n",
       "      <td id=\"T_916a8_row1_col0\" class=\"data row1 col0\" >0,52</td>\n",
       "      <td id=\"T_916a8_row1_col1\" class=\"data row1 col1\" >0,73</td>\n",
       "      <td id=\"T_916a8_row1_col2\" class=\"data row1 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row1_col3\" class=\"data row1 col3\" >0,09</td>\n",
       "      <td id=\"T_916a8_row1_col4\" class=\"data row1 col4\" >0,26</td>\n",
       "      <td id=\"T_916a8_row1_col5\" class=\"data row1 col5\" >0,58</td>\n",
       "      <td id=\"T_916a8_row1_col6\" class=\"data row1 col6\" >4,82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row2\" class=\"row_heading level0 row2\" >Fragments de polystyrène expansé: g81, g82, g83</th>\n",
       "      <td id=\"T_916a8_row2_col0\" class=\"data row2 col0\" >0,58</td>\n",
       "      <td id=\"T_916a8_row2_col1\" class=\"data row2 col1\" >1,01</td>\n",
       "      <td id=\"T_916a8_row2_col2\" class=\"data row2 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row2_col3\" class=\"data row2 col3\" >0,12</td>\n",
       "      <td id=\"T_916a8_row2_col4\" class=\"data row2 col4\" >0,27</td>\n",
       "      <td id=\"T_916a8_row2_col5\" class=\"data row2 col5\" >0,67</td>\n",
       "      <td id=\"T_916a8_row2_col6\" class=\"data row2 col6\" >11,76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row3\" class=\"row_heading level0 row3\" >Emballages de bonbons, de snacks</th>\n",
       "      <td id=\"T_916a8_row3_col0\" class=\"data row3 col0\" >0,39</td>\n",
       "      <td id=\"T_916a8_row3_col1\" class=\"data row3 col1\" >0,96</td>\n",
       "      <td id=\"T_916a8_row3_col2\" class=\"data row3 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row3_col3\" class=\"data row3 col3\" >0,07</td>\n",
       "      <td id=\"T_916a8_row3_col4\" class=\"data row3 col4\" >0,18</td>\n",
       "      <td id=\"T_916a8_row3_col5\" class=\"data row3 col5\" >0,43</td>\n",
       "      <td id=\"T_916a8_row3_col6\" class=\"data row3 col6\" >15,25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row4\" class=\"row_heading level0 row4\" >Coton-tige</th>\n",
       "      <td id=\"T_916a8_row4_col0\" class=\"data row4 col0\" >0,25</td>\n",
       "      <td id=\"T_916a8_row4_col1\" class=\"data row4 col1\" >0,73</td>\n",
       "      <td id=\"T_916a8_row4_col2\" class=\"data row4 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row4_col3\" class=\"data row4 col3\" >0,06</td>\n",
       "      <td id=\"T_916a8_row4_col4\" class=\"data row4 col4\" >0,14</td>\n",
       "      <td id=\"T_916a8_row4_col5\" class=\"data row4 col5\" >0,30</td>\n",
       "      <td id=\"T_916a8_row4_col6\" class=\"data row4 col6\" >15,52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row5\" class=\"row_heading level0 row5\" >Couvercles en plastique bouteille:  g21, g22, g23, g24</th>\n",
       "      <td id=\"T_916a8_row5_col0\" class=\"data row5 col0\" >0,25</td>\n",
       "      <td id=\"T_916a8_row5_col1\" class=\"data row5 col1\" >0,82</td>\n",
       "      <td id=\"T_916a8_row5_col2\" class=\"data row5 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row5_col3\" class=\"data row5 col3\" >0,04</td>\n",
       "      <td id=\"T_916a8_row5_col4\" class=\"data row5 col4\" >0,09</td>\n",
       "      <td id=\"T_916a8_row5_col5\" class=\"data row5 col5\" >0,25</td>\n",
       "      <td id=\"T_916a8_row5_col6\" class=\"data row5 col6\" >14,18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row6\" class=\"row_heading level0 row6\" >Bâche, feuille plastique industrielle</th>\n",
       "      <td id=\"T_916a8_row6_col0\" class=\"data row6 col0\" >1,54</td>\n",
       "      <td id=\"T_916a8_row6_col1\" class=\"data row6 col1\" >3,34</td>\n",
       "      <td id=\"T_916a8_row6_col2\" class=\"data row6 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row6_col3\" class=\"data row6 col3\" >0,02</td>\n",
       "      <td id=\"T_916a8_row6_col4\" class=\"data row6 col4\" >0,05</td>\n",
       "      <td id=\"T_916a8_row6_col5\" class=\"data row6 col5\" >0,70</td>\n",
       "      <td id=\"T_916a8_row6_col6\" class=\"data row6 col6\" >18,91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row7\" class=\"row_heading level0 row7\" >Pellets industriels (gpi)</th>\n",
       "      <td id=\"T_916a8_row7_col0\" class=\"data row7 col0\" >0,49</td>\n",
       "      <td id=\"T_916a8_row7_col1\" class=\"data row7 col1\" >2,20</td>\n",
       "      <td id=\"T_916a8_row7_col2\" class=\"data row7 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row7_col3\" class=\"data row7 col3\" >0,04</td>\n",
       "      <td id=\"T_916a8_row7_col4\" class=\"data row7 col4\" >0,13</td>\n",
       "      <td id=\"T_916a8_row7_col5\" class=\"data row7 col5\" >0,27</td>\n",
       "      <td id=\"T_916a8_row7_col6\" class=\"data row7 col6\" >19,98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row8\" class=\"row_heading level0 row8\" >Fragments de plastique angulaires <5mm</th>\n",
       "      <td id=\"T_916a8_row8_col0\" class=\"data row8 col0\" >0,49</td>\n",
       "      <td id=\"T_916a8_row8_col1\" class=\"data row8 col1\" >1,71</td>\n",
       "      <td id=\"T_916a8_row8_col2\" class=\"data row8 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row8_col3\" class=\"data row8 col3\" >0,06</td>\n",
       "      <td id=\"T_916a8_row8_col4\" class=\"data row8 col4\" >0,17</td>\n",
       "      <td id=\"T_916a8_row8_col5\" class=\"data row8 col5\" >0,42</td>\n",
       "      <td id=\"T_916a8_row8_col6\" class=\"data row8 col6\" >15,35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row9\" class=\"row_heading level0 row9\" >Déchets de construction en plastique</th>\n",
       "      <td id=\"T_916a8_row9_col0\" class=\"data row9 col0\" >0,33</td>\n",
       "      <td id=\"T_916a8_row9_col1\" class=\"data row9 col1\" >1,31</td>\n",
       "      <td id=\"T_916a8_row9_col2\" class=\"data row9 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row9_col3\" class=\"data row9 col3\" >0,05</td>\n",
       "      <td id=\"T_916a8_row9_col4\" class=\"data row9 col4\" >0,14</td>\n",
       "      <td id=\"T_916a8_row9_col5\" class=\"data row9 col5\" >0,36</td>\n",
       "      <td id=\"T_916a8_row9_col6\" class=\"data row9 col6\" >19,77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row10\" class=\"row_heading level0 row10\" >Mousse de plastique pour l'isolation thermique</th>\n",
       "      <td id=\"T_916a8_row10_col0\" class=\"data row10 col0\" >0,37</td>\n",
       "      <td id=\"T_916a8_row10_col1\" class=\"data row10 col1\" >1,31</td>\n",
       "      <td id=\"T_916a8_row10_col2\" class=\"data row10 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row10_col3\" class=\"data row10 col3\" >0,05</td>\n",
       "      <td id=\"T_916a8_row10_col4\" class=\"data row10 col4\" >0,16</td>\n",
       "      <td id=\"T_916a8_row10_col5\" class=\"data row10 col5\" >0,35</td>\n",
       "      <td id=\"T_916a8_row10_col6\" class=\"data row10 col6\" >16,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row11\" class=\"row_heading level0 row11\" >Cartouches de fusil de chasse</th>\n",
       "      <td id=\"T_916a8_row11_col0\" class=\"data row11 col0\" >0,33</td>\n",
       "      <td id=\"T_916a8_row11_col1\" class=\"data row11 col1\" >1,84</td>\n",
       "      <td id=\"T_916a8_row11_col2\" class=\"data row11 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row11_col3\" class=\"data row11 col3\" >0,01</td>\n",
       "      <td id=\"T_916a8_row11_col4\" class=\"data row11 col4\" >0,04</td>\n",
       "      <td id=\"T_916a8_row11_col5\" class=\"data row11 col5\" >0,11</td>\n",
       "      <td id=\"T_916a8_row11_col6\" class=\"data row11 col6\" >18,78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row12\" class=\"row_heading level0 row12\" >Bâtonnets de sucette</th>\n",
       "      <td id=\"T_916a8_row12_col0\" class=\"data row12 col0\" >0,27</td>\n",
       "      <td id=\"T_916a8_row12_col1\" class=\"data row12 col1\" >1,66</td>\n",
       "      <td id=\"T_916a8_row12_col2\" class=\"data row12 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row12_col3\" class=\"data row12 col3\" >0,02</td>\n",
       "      <td id=\"T_916a8_row12_col4\" class=\"data row12 col4\" >0,04</td>\n",
       "      <td id=\"T_916a8_row12_col5\" class=\"data row12 col5\" >0,10</td>\n",
       "      <td id=\"T_916a8_row12_col6\" class=\"data row12 col6\" >19,14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_916a8_level0_row13\" class=\"row_heading level0 row13\" >Pailles et agitateurs</th>\n",
       "      <td id=\"T_916a8_row13_col0\" class=\"data row13 col0\" >3,17</td>\n",
       "      <td id=\"T_916a8_row13_col1\" class=\"data row13 col1\" >3,16</td>\n",
       "      <td id=\"T_916a8_row13_col2\" class=\"data row13 col2\" >0,00</td>\n",
       "      <td id=\"T_916a8_row13_col3\" class=\"data row13 col3\" >0,82</td>\n",
       "      <td id=\"T_916a8_row13_col4\" class=\"data row13 col4\" >2,26</td>\n",
       "      <td id=\"T_916a8_row13_col5\" class=\"data row13 col5\" >4,45</td>\n",
       "      <td id=\"T_916a8_row13_col6\" class=\"data row13 col6\" >16,40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x74ccdb22f9d0>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "start_data_7"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['mean', 'std', 'min', '25%', '50%', '75%', 'max', 'objet']\n",
    "predictions = []\n",
    "for i, n in enumerate(mc.index):\n",
    "    xi = samples[i][\"Haut lac\"].describe()\n",
    "    xi.loc[\"objet\"] = n\n",
    "    predictions.append(pd.DataFrame(xi).T)\n",
    "hl_predictions = pd.concat(predictions)\n",
    "hl_predictions = hl_predictions[columns]\n",
    "hl_predictions.set_index('objet', inplace=True, drop=True)\n",
    "hl_predictions.index.name = None\n",
    "haut_lac = rc.translated_and_style_for_display(hl_predictions, display_language_map, display_language, gradient=False)\n",
    "caption =  f\"<b>{label}7 :</b> Haut lac, La distribution attendue des objets les plus courants 2024..\" \n",
    "glue(\"start_data_7\", haut_lac.set_caption(caption), display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73982dd3-693d-4cd5-9898-4793d427ea3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Grand lac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c99a24a-7197-44cf-991a-9c10333aa600",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_642a0 tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_642a0 tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_642a0 tr {\n",
       "  font-size: 10px;\n",
       "}\n",
       "#T_642a0 th {\n",
       "  background-color: #FFF;\n",
       "  font-size: 12px;\n",
       "  text-align: left;\n",
       "  width: auto;\n",
       "  word-break: keep-all;\n",
       "}\n",
       "#T_642a0 td {\n",
       "  padding: 4px;\n",
       "  font-size: 12px;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_642a0 caption {\n",
       "  caption-side: bottom;\n",
       "  font-size: 1em;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_642a0\">\n",
       "  <caption><b>Table A5-8 :</b> Grand lac, la distribution attendue des résultats des échantillons pour 2024.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_642a0_level0_col0\" class=\"col_heading level0 col0\" >moyenne</th>\n",
       "      <th id=\"T_642a0_level0_col1\" class=\"col_heading level0 col1\" >écart-type</th>\n",
       "      <th id=\"T_642a0_level0_col2\" class=\"col_heading level0 col2\" >min</th>\n",
       "      <th id=\"T_642a0_level0_col3\" class=\"col_heading level0 col3\" >25%</th>\n",
       "      <th id=\"T_642a0_level0_col4\" class=\"col_heading level0 col4\" >50%</th>\n",
       "      <th id=\"T_642a0_level0_col5\" class=\"col_heading level0 col5\" >75%</th>\n",
       "      <th id=\"T_642a0_level0_col6\" class=\"col_heading level0 col6\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_642a0_level0_row0\" class=\"row_heading level0 row0\" >Grand lac</th>\n",
       "      <td id=\"T_642a0_row0_col0\" class=\"data row0 col0\" >2,20</td>\n",
       "      <td id=\"T_642a0_row0_col1\" class=\"data row0 col1\" >2,25</td>\n",
       "      <td id=\"T_642a0_row0_col2\" class=\"data row0 col2\" >0,00</td>\n",
       "      <td id=\"T_642a0_row0_col3\" class=\"data row0 col3\" >0,71</td>\n",
       "      <td id=\"T_642a0_row0_col4\" class=\"data row0 col4\" >1,59</td>\n",
       "      <td id=\"T_642a0_row0_col5\" class=\"data row0 col5\" >2,95</td>\n",
       "      <td id=\"T_642a0_row0_col6\" class=\"data row0 col6\" >19,95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x74ccdbf09d00>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "start_data_8"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "gl_stot = pd.DataFrame(samplest[0][\"Grand lac\"].describe()).T\n",
    "gl_stot  = gl_stot[columns]\n",
    "\n",
    "gl_stot.index = [\"Grand lac\"]\n",
    "gl_stot = rc.translated_and_style_for_display(gl_stot, display_language_map, display_language, gradient=False)\n",
    "caption =  f\"<b>{label}8 :</b> Grand lac, la distribution attendue des résultats des échantillons pour 2024.\" \n",
    "glue(\"start_data_8\", gl_stot.set_caption(caption), display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d87a8af-b5c2-4ee1-91e8-de868442a1cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8c14f tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_8c14f tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_8c14f tr {\n",
       "  font-size: 10px;\n",
       "}\n",
       "#T_8c14f th {\n",
       "  background-color: #FFF;\n",
       "  font-size: 12px;\n",
       "  text-align: left;\n",
       "  width: auto;\n",
       "  word-break: keep-all;\n",
       "}\n",
       "#T_8c14f td {\n",
       "  padding: 4px;\n",
       "  font-size: 12px;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_8c14f caption {\n",
       "  caption-side: bottom;\n",
       "  font-size: 1em;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8c14f\">\n",
       "  <caption><b>Table A5-9 :</b> Grand lac, La distribution attendue des objets les plus courants 2024.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8c14f_level0_col0\" class=\"col_heading level0 col0\" >moyenne</th>\n",
       "      <th id=\"T_8c14f_level0_col1\" class=\"col_heading level0 col1\" >écart-type</th>\n",
       "      <th id=\"T_8c14f_level0_col2\" class=\"col_heading level0 col2\" >min</th>\n",
       "      <th id=\"T_8c14f_level0_col3\" class=\"col_heading level0 col3\" >25%</th>\n",
       "      <th id=\"T_8c14f_level0_col4\" class=\"col_heading level0 col4\" >50%</th>\n",
       "      <th id=\"T_8c14f_level0_col5\" class=\"col_heading level0 col5\" >75%</th>\n",
       "      <th id=\"T_8c14f_level0_col6\" class=\"col_heading level0 col6\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row0\" class=\"row_heading level0 row0\" >Fragments de plastique: g80, g79, g78, g77, g76, g75</th>\n",
       "      <td id=\"T_8c14f_row0_col0\" class=\"data row0 col0\" >1,07</td>\n",
       "      <td id=\"T_8c14f_row0_col1\" class=\"data row0 col1\" >1,69</td>\n",
       "      <td id=\"T_8c14f_row0_col2\" class=\"data row0 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row0_col3\" class=\"data row0 col3\" >0,19</td>\n",
       "      <td id=\"T_8c14f_row0_col4\" class=\"data row0 col4\" >0,51</td>\n",
       "      <td id=\"T_8c14f_row0_col5\" class=\"data row0 col5\" >1,27</td>\n",
       "      <td id=\"T_8c14f_row0_col6\" class=\"data row0 col6\" >15,93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row1\" class=\"row_heading level0 row1\" >Mégots et filtres à cigarettes</th>\n",
       "      <td id=\"T_8c14f_row1_col0\" class=\"data row1 col0\" >0,49</td>\n",
       "      <td id=\"T_8c14f_row1_col1\" class=\"data row1 col1\" >0,72</td>\n",
       "      <td id=\"T_8c14f_row1_col2\" class=\"data row1 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row1_col3\" class=\"data row1 col3\" >0,08</td>\n",
       "      <td id=\"T_8c14f_row1_col4\" class=\"data row1 col4\" >0,22</td>\n",
       "      <td id=\"T_8c14f_row1_col5\" class=\"data row1 col5\" >0,53</td>\n",
       "      <td id=\"T_8c14f_row1_col6\" class=\"data row1 col6\" >6,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row2\" class=\"row_heading level0 row2\" >Fragments de polystyrène expansé: g81, g82, g83</th>\n",
       "      <td id=\"T_8c14f_row2_col0\" class=\"data row2 col0\" >0,37</td>\n",
       "      <td id=\"T_8c14f_row2_col1\" class=\"data row2 col1\" >0,99</td>\n",
       "      <td id=\"T_8c14f_row2_col2\" class=\"data row2 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row2_col3\" class=\"data row2 col3\" >0,05</td>\n",
       "      <td id=\"T_8c14f_row2_col4\" class=\"data row2 col4\" >0,15</td>\n",
       "      <td id=\"T_8c14f_row2_col5\" class=\"data row2 col5\" >0,34</td>\n",
       "      <td id=\"T_8c14f_row2_col6\" class=\"data row2 col6\" >14,51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row3\" class=\"row_heading level0 row3\" >Emballages de bonbons, de snacks</th>\n",
       "      <td id=\"T_8c14f_row3_col0\" class=\"data row3 col0\" >0,21</td>\n",
       "      <td id=\"T_8c14f_row3_col1\" class=\"data row3 col1\" >0,20</td>\n",
       "      <td id=\"T_8c14f_row3_col2\" class=\"data row3 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row3_col3\" class=\"data row3 col3\" >0,06</td>\n",
       "      <td id=\"T_8c14f_row3_col4\" class=\"data row3 col4\" >0,14</td>\n",
       "      <td id=\"T_8c14f_row3_col5\" class=\"data row3 col5\" >0,31</td>\n",
       "      <td id=\"T_8c14f_row3_col6\" class=\"data row3 col6\" >1,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row4\" class=\"row_heading level0 row4\" >Coton-tige</th>\n",
       "      <td id=\"T_8c14f_row4_col0\" class=\"data row4 col0\" >0,16</td>\n",
       "      <td id=\"T_8c14f_row4_col1\" class=\"data row4 col1\" >0,17</td>\n",
       "      <td id=\"T_8c14f_row4_col2\" class=\"data row4 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row4_col3\" class=\"data row4 col3\" >0,04</td>\n",
       "      <td id=\"T_8c14f_row4_col4\" class=\"data row4 col4\" >0,10</td>\n",
       "      <td id=\"T_8c14f_row4_col5\" class=\"data row4 col5\" >0,22</td>\n",
       "      <td id=\"T_8c14f_row4_col6\" class=\"data row4 col6\" >0,76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row5\" class=\"row_heading level0 row5\" >Couvercles en plastique bouteille:  g21, g22, g23, g24</th>\n",
       "      <td id=\"T_8c14f_row5_col0\" class=\"data row5 col0\" >0,27</td>\n",
       "      <td id=\"T_8c14f_row5_col1\" class=\"data row5 col1\" >1,34</td>\n",
       "      <td id=\"T_8c14f_row5_col2\" class=\"data row5 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row5_col3\" class=\"data row5 col3\" >0,02</td>\n",
       "      <td id=\"T_8c14f_row5_col4\" class=\"data row5 col4\" >0,08</td>\n",
       "      <td id=\"T_8c14f_row5_col5\" class=\"data row5 col5\" >0,18</td>\n",
       "      <td id=\"T_8c14f_row5_col6\" class=\"data row5 col6\" >19,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row6\" class=\"row_heading level0 row6\" >Bâche, feuille plastique industrielle</th>\n",
       "      <td id=\"T_8c14f_row6_col0\" class=\"data row6 col0\" >0,35</td>\n",
       "      <td id=\"T_8c14f_row6_col1\" class=\"data row6 col1\" >1,63</td>\n",
       "      <td id=\"T_8c14f_row6_col2\" class=\"data row6 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row6_col3\" class=\"data row6 col3\" >0,04</td>\n",
       "      <td id=\"T_8c14f_row6_col4\" class=\"data row6 col4\" >0,11</td>\n",
       "      <td id=\"T_8c14f_row6_col5\" class=\"data row6 col5\" >0,24</td>\n",
       "      <td id=\"T_8c14f_row6_col6\" class=\"data row6 col6\" >19,73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row7\" class=\"row_heading level0 row7\" >Pellets industriels (gpi)</th>\n",
       "      <td id=\"T_8c14f_row7_col0\" class=\"data row7 col0\" >0,78</td>\n",
       "      <td id=\"T_8c14f_row7_col1\" class=\"data row7 col1\" >1,09</td>\n",
       "      <td id=\"T_8c14f_row7_col2\" class=\"data row7 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row7_col3\" class=\"data row7 col3\" >0,12</td>\n",
       "      <td id=\"T_8c14f_row7_col4\" class=\"data row7 col4\" >0,42</td>\n",
       "      <td id=\"T_8c14f_row7_col5\" class=\"data row7 col5\" >1,02</td>\n",
       "      <td id=\"T_8c14f_row7_col6\" class=\"data row7 col6\" >8,92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row8\" class=\"row_heading level0 row8\" >Fragments de plastique angulaires <5mm</th>\n",
       "      <td id=\"T_8c14f_row8_col0\" class=\"data row8 col0\" >0,60</td>\n",
       "      <td id=\"T_8c14f_row8_col1\" class=\"data row8 col1\" >1,52</td>\n",
       "      <td id=\"T_8c14f_row8_col2\" class=\"data row8 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row8_col3\" class=\"data row8 col3\" >0,07</td>\n",
       "      <td id=\"T_8c14f_row8_col4\" class=\"data row8 col4\" >0,27</td>\n",
       "      <td id=\"T_8c14f_row8_col5\" class=\"data row8 col5\" >0,70</td>\n",
       "      <td id=\"T_8c14f_row8_col6\" class=\"data row8 col6\" >19,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row9\" class=\"row_heading level0 row9\" >Déchets de construction en plastique</th>\n",
       "      <td id=\"T_8c14f_row9_col0\" class=\"data row9 col0\" >0,51</td>\n",
       "      <td id=\"T_8c14f_row9_col1\" class=\"data row9 col1\" >2,31</td>\n",
       "      <td id=\"T_8c14f_row9_col2\" class=\"data row9 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row9_col3\" class=\"data row9 col3\" >0,01</td>\n",
       "      <td id=\"T_8c14f_row9_col4\" class=\"data row9 col4\" >0,02</td>\n",
       "      <td id=\"T_8c14f_row9_col5\" class=\"data row9 col5\" >0,04</td>\n",
       "      <td id=\"T_8c14f_row9_col6\" class=\"data row9 col6\" >18,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row10\" class=\"row_heading level0 row10\" >Mousse de plastique pour l'isolation thermique</th>\n",
       "      <td id=\"T_8c14f_row10_col0\" class=\"data row10 col0\" >0,16</td>\n",
       "      <td id=\"T_8c14f_row10_col1\" class=\"data row10 col1\" >0,91</td>\n",
       "      <td id=\"T_8c14f_row10_col2\" class=\"data row10 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row10_col3\" class=\"data row10 col3\" >0,02</td>\n",
       "      <td id=\"T_8c14f_row10_col4\" class=\"data row10 col4\" >0,05</td>\n",
       "      <td id=\"T_8c14f_row10_col5\" class=\"data row10 col5\" >0,10</td>\n",
       "      <td id=\"T_8c14f_row10_col6\" class=\"data row10 col6\" >12,97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row11\" class=\"row_heading level0 row11\" >Cartouches de fusil de chasse</th>\n",
       "      <td id=\"T_8c14f_row11_col0\" class=\"data row11 col0\" >0,37</td>\n",
       "      <td id=\"T_8c14f_row11_col1\" class=\"data row11 col1\" >1,97</td>\n",
       "      <td id=\"T_8c14f_row11_col2\" class=\"data row11 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row11_col3\" class=\"data row11 col3\" >0,01</td>\n",
       "      <td id=\"T_8c14f_row11_col4\" class=\"data row11 col4\" >0,02</td>\n",
       "      <td id=\"T_8c14f_row11_col5\" class=\"data row11 col5\" >0,05</td>\n",
       "      <td id=\"T_8c14f_row11_col6\" class=\"data row11 col6\" >18,30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row12\" class=\"row_heading level0 row12\" >Bâtonnets de sucette</th>\n",
       "      <td id=\"T_8c14f_row12_col0\" class=\"data row12 col0\" >0,18</td>\n",
       "      <td id=\"T_8c14f_row12_col1\" class=\"data row12 col1\" >1,17</td>\n",
       "      <td id=\"T_8c14f_row12_col2\" class=\"data row12 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row12_col3\" class=\"data row12 col3\" >0,01</td>\n",
       "      <td id=\"T_8c14f_row12_col4\" class=\"data row12 col4\" >0,03</td>\n",
       "      <td id=\"T_8c14f_row12_col5\" class=\"data row12 col5\" >0,07</td>\n",
       "      <td id=\"T_8c14f_row12_col6\" class=\"data row12 col6\" >15,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c14f_level0_row13\" class=\"row_heading level0 row13\" >Pailles et agitateurs</th>\n",
       "      <td id=\"T_8c14f_row13_col0\" class=\"data row13 col0\" >2,20</td>\n",
       "      <td id=\"T_8c14f_row13_col1\" class=\"data row13 col1\" >2,25</td>\n",
       "      <td id=\"T_8c14f_row13_col2\" class=\"data row13 col2\" >0,00</td>\n",
       "      <td id=\"T_8c14f_row13_col3\" class=\"data row13 col3\" >0,71</td>\n",
       "      <td id=\"T_8c14f_row13_col4\" class=\"data row13 col4\" >1,59</td>\n",
       "      <td id=\"T_8c14f_row13_col5\" class=\"data row13 col5\" >2,95</td>\n",
       "      <td id=\"T_8c14f_row13_col6\" class=\"data row13 col6\" >19,95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x74ccdb0205e0>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "start_data_9"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['mean', 'std', 'min', '25%', '50%', '75%', 'max', 'objet']\n",
    "predictions = []\n",
    "for i, n in enumerate(mc.index):\n",
    "    xi = samples[i][\"Grand lac\"].describe()\n",
    "    xi.loc[\"objet\"] = n\n",
    "    predictions.append(pd.DataFrame(xi).T)\n",
    "hl_predictions = pd.concat(predictions)\n",
    "hl_predictions = hl_predictions[columns]\n",
    "hl_predictions.set_index('objet', inplace=True, drop=True)\n",
    "hl_predictions.index.name = None\n",
    "grand_lac = rc.translated_and_style_for_display(hl_predictions, display_language_map, display_language, gradient=False)\n",
    "caption =  f\"<b>{label}9 :</b> Grand lac, La distribution attendue des objets les plus courants 2024.\" \n",
    "glue(\"start_data_9\", grand_lac.set_caption(caption), display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2bb2f-8477-43d3-a53d-baf0fd619144",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Petit lac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bff86da-028d-4345-ac15-244b2b69beed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_caa27 tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_caa27 tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_caa27 tr {\n",
       "  font-size: 10px;\n",
       "}\n",
       "#T_caa27 th {\n",
       "  background-color: #FFF;\n",
       "  font-size: 12px;\n",
       "  text-align: left;\n",
       "  width: auto;\n",
       "  word-break: keep-all;\n",
       "}\n",
       "#T_caa27 td {\n",
       "  padding: 4px;\n",
       "  font-size: 12px;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_caa27 caption {\n",
       "  caption-side: bottom;\n",
       "  font-size: 1em;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_caa27\">\n",
       "  <caption><b>Table A5-10 :</b> Petit lac, la distribution attendue des résultats des échantillons pour 2024.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_caa27_level0_col0\" class=\"col_heading level0 col0\" >moyenne</th>\n",
       "      <th id=\"T_caa27_level0_col1\" class=\"col_heading level0 col1\" >écart-type</th>\n",
       "      <th id=\"T_caa27_level0_col2\" class=\"col_heading level0 col2\" >min</th>\n",
       "      <th id=\"T_caa27_level0_col3\" class=\"col_heading level0 col3\" >25%</th>\n",
       "      <th id=\"T_caa27_level0_col4\" class=\"col_heading level0 col4\" >50%</th>\n",
       "      <th id=\"T_caa27_level0_col5\" class=\"col_heading level0 col5\" >75%</th>\n",
       "      <th id=\"T_caa27_level0_col6\" class=\"col_heading level0 col6\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_caa27_level0_row0\" class=\"row_heading level0 row0\" >Petit lac</th>\n",
       "      <td id=\"T_caa27_row0_col0\" class=\"data row0 col0\" >1,02</td>\n",
       "      <td id=\"T_caa27_row0_col1\" class=\"data row0 col1\" >1,27</td>\n",
       "      <td id=\"T_caa27_row0_col2\" class=\"data row0 col2\" >0,00</td>\n",
       "      <td id=\"T_caa27_row0_col3\" class=\"data row0 col3\" >0,26</td>\n",
       "      <td id=\"T_caa27_row0_col4\" class=\"data row0 col4\" >0,66</td>\n",
       "      <td id=\"T_caa27_row0_col5\" class=\"data row0 col5\" >1,27</td>\n",
       "      <td id=\"T_caa27_row0_col6\" class=\"data row0 col6\" >12,74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x74ccdc23bb20>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "start_data_10"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "pl_stot = pd.DataFrame(samplest[0][\"Petit lac\"].describe()).T\n",
    "pl_stot  = pl_stot[columns]\n",
    "\n",
    "pl_stot.index = [\"Petit lac\"]\n",
    "pl_stot = rc.translated_and_style_for_display(pl_stot, display_language_map, display_language, gradient=False)\n",
    "caption =  f\"<b>{label}10 :</b> Petit lac, la distribution attendue des résultats des échantillons pour 2024.\" \n",
    "glue(\"start_data_10\", pl_stot.set_caption(caption), display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61a71bd7-af9e-44a5-bb8f-55cfce7d177e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_97006 tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_97006 tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_97006 tr {\n",
       "  font-size: 10px;\n",
       "}\n",
       "#T_97006 th {\n",
       "  background-color: #FFF;\n",
       "  font-size: 12px;\n",
       "  text-align: left;\n",
       "  width: auto;\n",
       "  word-break: keep-all;\n",
       "}\n",
       "#T_97006 td {\n",
       "  padding: 4px;\n",
       "  font-size: 12px;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_97006 caption {\n",
       "  caption-side: bottom;\n",
       "  font-size: 1em;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_97006\">\n",
       "  <caption><b>Table A5-11 :</b> Petit lac, La distribution attendue des objets les plus courants 2024.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_97006_level0_col0\" class=\"col_heading level0 col0\" >moyenne</th>\n",
       "      <th id=\"T_97006_level0_col1\" class=\"col_heading level0 col1\" >écart-type</th>\n",
       "      <th id=\"T_97006_level0_col2\" class=\"col_heading level0 col2\" >min</th>\n",
       "      <th id=\"T_97006_level0_col3\" class=\"col_heading level0 col3\" >25%</th>\n",
       "      <th id=\"T_97006_level0_col4\" class=\"col_heading level0 col4\" >50%</th>\n",
       "      <th id=\"T_97006_level0_col5\" class=\"col_heading level0 col5\" >75%</th>\n",
       "      <th id=\"T_97006_level0_col6\" class=\"col_heading level0 col6\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row0\" class=\"row_heading level0 row0\" >Fragments de plastique: g80, g79, g78, g77, g76, g75</th>\n",
       "      <td id=\"T_97006_row0_col0\" class=\"data row0 col0\" >0,36</td>\n",
       "      <td id=\"T_97006_row0_col1\" class=\"data row0 col1\" >0,41</td>\n",
       "      <td id=\"T_97006_row0_col2\" class=\"data row0 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row0_col3\" class=\"data row0 col3\" >0,09</td>\n",
       "      <td id=\"T_97006_row0_col4\" class=\"data row0 col4\" >0,23</td>\n",
       "      <td id=\"T_97006_row0_col5\" class=\"data row0 col5\" >0,49</td>\n",
       "      <td id=\"T_97006_row0_col6\" class=\"data row0 col6\" >2,80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row1\" class=\"row_heading level0 row1\" >Mégots et filtres à cigarettes</th>\n",
       "      <td id=\"T_97006_row1_col0\" class=\"data row1 col0\" >0,32</td>\n",
       "      <td id=\"T_97006_row1_col1\" class=\"data row1 col1\" >0,53</td>\n",
       "      <td id=\"T_97006_row1_col2\" class=\"data row1 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row1_col3\" class=\"data row1 col3\" >0,06</td>\n",
       "      <td id=\"T_97006_row1_col4\" class=\"data row1 col4\" >0,17</td>\n",
       "      <td id=\"T_97006_row1_col5\" class=\"data row1 col5\" >0,35</td>\n",
       "      <td id=\"T_97006_row1_col6\" class=\"data row1 col6\" >5,93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row2\" class=\"row_heading level0 row2\" >Fragments de polystyrène expansé: g81, g82, g83</th>\n",
       "      <td id=\"T_97006_row2_col0\" class=\"data row2 col0\" >0,25</td>\n",
       "      <td id=\"T_97006_row2_col1\" class=\"data row2 col1\" >1,55</td>\n",
       "      <td id=\"T_97006_row2_col2\" class=\"data row2 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row2_col3\" class=\"data row2 col3\" >0,01</td>\n",
       "      <td id=\"T_97006_row2_col4\" class=\"data row2 col4\" >0,02</td>\n",
       "      <td id=\"T_97006_row2_col5\" class=\"data row2 col5\" >0,05</td>\n",
       "      <td id=\"T_97006_row2_col6\" class=\"data row2 col6\" >18,63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row3\" class=\"row_heading level0 row3\" >Emballages de bonbons, de snacks</th>\n",
       "      <td id=\"T_97006_row3_col0\" class=\"data row3 col0\" >0,11</td>\n",
       "      <td id=\"T_97006_row3_col1\" class=\"data row3 col1\" >0,14</td>\n",
       "      <td id=\"T_97006_row3_col2\" class=\"data row3 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row3_col3\" class=\"data row3 col3\" >0,04</td>\n",
       "      <td id=\"T_97006_row3_col4\" class=\"data row3 col4\" >0,06</td>\n",
       "      <td id=\"T_97006_row3_col5\" class=\"data row3 col5\" >0,13</td>\n",
       "      <td id=\"T_97006_row3_col6\" class=\"data row3 col6\" >0,90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row4\" class=\"row_heading level0 row4\" >Coton-tige</th>\n",
       "      <td id=\"T_97006_row4_col0\" class=\"data row4 col0\" >0,23</td>\n",
       "      <td id=\"T_97006_row4_col1\" class=\"data row4 col1\" >1,44</td>\n",
       "      <td id=\"T_97006_row4_col2\" class=\"data row4 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row4_col3\" class=\"data row4 col3\" >0,02</td>\n",
       "      <td id=\"T_97006_row4_col4\" class=\"data row4 col4\" >0,05</td>\n",
       "      <td id=\"T_97006_row4_col5\" class=\"data row4 col5\" >0,13</td>\n",
       "      <td id=\"T_97006_row4_col6\" class=\"data row4 col6\" >19,51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row5\" class=\"row_heading level0 row5\" >Couvercles en plastique bouteille:  g21, g22, g23, g24</th>\n",
       "      <td id=\"T_97006_row5_col0\" class=\"data row5 col0\" >0,22</td>\n",
       "      <td id=\"T_97006_row5_col1\" class=\"data row5 col1\" >1,32</td>\n",
       "      <td id=\"T_97006_row5_col2\" class=\"data row5 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row5_col3\" class=\"data row5 col3\" >0,01</td>\n",
       "      <td id=\"T_97006_row5_col4\" class=\"data row5 col4\" >0,04</td>\n",
       "      <td id=\"T_97006_row5_col5\" class=\"data row5 col5\" >0,08</td>\n",
       "      <td id=\"T_97006_row5_col6\" class=\"data row5 col6\" >19,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row6\" class=\"row_heading level0 row6\" >Bâche, feuille plastique industrielle</th>\n",
       "      <td id=\"T_97006_row6_col0\" class=\"data row6 col0\" >3,68</td>\n",
       "      <td id=\"T_97006_row6_col1\" class=\"data row6 col1\" >5,59</td>\n",
       "      <td id=\"T_97006_row6_col2\" class=\"data row6 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row6_col3\" class=\"data row6 col3\" >0,22</td>\n",
       "      <td id=\"T_97006_row6_col4\" class=\"data row6 col4\" >0,72</td>\n",
       "      <td id=\"T_97006_row6_col5\" class=\"data row6 col5\" >5,56</td>\n",
       "      <td id=\"T_97006_row6_col6\" class=\"data row6 col6\" >19,75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row7\" class=\"row_heading level0 row7\" >Pellets industriels (gpi)</th>\n",
       "      <td id=\"T_97006_row7_col0\" class=\"data row7 col0\" >0,41</td>\n",
       "      <td id=\"T_97006_row7_col1\" class=\"data row7 col1\" >1,25</td>\n",
       "      <td id=\"T_97006_row7_col2\" class=\"data row7 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row7_col3\" class=\"data row7 col3\" >0,04</td>\n",
       "      <td id=\"T_97006_row7_col4\" class=\"data row7 col4\" >0,12</td>\n",
       "      <td id=\"T_97006_row7_col5\" class=\"data row7 col5\" >0,37</td>\n",
       "      <td id=\"T_97006_row7_col6\" class=\"data row7 col6\" >18,30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row8\" class=\"row_heading level0 row8\" >Fragments de plastique angulaires <5mm</th>\n",
       "      <td id=\"T_97006_row8_col0\" class=\"data row8 col0\" >0,58</td>\n",
       "      <td id=\"T_97006_row8_col1\" class=\"data row8 col1\" >1,46</td>\n",
       "      <td id=\"T_97006_row8_col2\" class=\"data row8 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row8_col3\" class=\"data row8 col3\" >0,08</td>\n",
       "      <td id=\"T_97006_row8_col4\" class=\"data row8 col4\" >0,23</td>\n",
       "      <td id=\"T_97006_row8_col5\" class=\"data row8 col5\" >0,73</td>\n",
       "      <td id=\"T_97006_row8_col6\" class=\"data row8 col6\" >19,31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row9\" class=\"row_heading level0 row9\" >Déchets de construction en plastique</th>\n",
       "      <td id=\"T_97006_row9_col0\" class=\"data row9 col0\" >0,77</td>\n",
       "      <td id=\"T_97006_row9_col1\" class=\"data row9 col1\" >2,99</td>\n",
       "      <td id=\"T_97006_row9_col2\" class=\"data row9 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row9_col3\" class=\"data row9 col3\" >0,01</td>\n",
       "      <td id=\"T_97006_row9_col4\" class=\"data row9 col4\" >0,02</td>\n",
       "      <td id=\"T_97006_row9_col5\" class=\"data row9 col5\" >0,04</td>\n",
       "      <td id=\"T_97006_row9_col6\" class=\"data row9 col6\" >19,95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row10\" class=\"row_heading level0 row10\" >Mousse de plastique pour l'isolation thermique</th>\n",
       "      <td id=\"T_97006_row10_col0\" class=\"data row10 col0\" >0,21</td>\n",
       "      <td id=\"T_97006_row10_col1\" class=\"data row10 col1\" >1,47</td>\n",
       "      <td id=\"T_97006_row10_col2\" class=\"data row10 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row10_col3\" class=\"data row10 col3\" >0,01</td>\n",
       "      <td id=\"T_97006_row10_col4\" class=\"data row10 col4\" >0,03</td>\n",
       "      <td id=\"T_97006_row10_col5\" class=\"data row10 col5\" >0,06</td>\n",
       "      <td id=\"T_97006_row10_col6\" class=\"data row10 col6\" >17,86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row11\" class=\"row_heading level0 row11\" >Cartouches de fusil de chasse</th>\n",
       "      <td id=\"T_97006_row11_col0\" class=\"data row11 col0\" >1,01</td>\n",
       "      <td id=\"T_97006_row11_col1\" class=\"data row11 col1\" >3,52</td>\n",
       "      <td id=\"T_97006_row11_col2\" class=\"data row11 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row11_col3\" class=\"data row11 col3\" >0,01</td>\n",
       "      <td id=\"T_97006_row11_col4\" class=\"data row11 col4\" >0,02</td>\n",
       "      <td id=\"T_97006_row11_col5\" class=\"data row11 col5\" >0,04</td>\n",
       "      <td id=\"T_97006_row11_col6\" class=\"data row11 col6\" >19,63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row12\" class=\"row_heading level0 row12\" >Bâtonnets de sucette</th>\n",
       "      <td id=\"T_97006_row12_col0\" class=\"data row12 col0\" >0,38</td>\n",
       "      <td id=\"T_97006_row12_col1\" class=\"data row12 col1\" >2,08</td>\n",
       "      <td id=\"T_97006_row12_col2\" class=\"data row12 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row12_col3\" class=\"data row12 col3\" >0,01</td>\n",
       "      <td id=\"T_97006_row12_col4\" class=\"data row12 col4\" >0,02</td>\n",
       "      <td id=\"T_97006_row12_col5\" class=\"data row12 col5\" >0,04</td>\n",
       "      <td id=\"T_97006_row12_col6\" class=\"data row12 col6\" >18,33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97006_level0_row13\" class=\"row_heading level0 row13\" >Pailles et agitateurs</th>\n",
       "      <td id=\"T_97006_row13_col0\" class=\"data row13 col0\" >1,02</td>\n",
       "      <td id=\"T_97006_row13_col1\" class=\"data row13 col1\" >1,27</td>\n",
       "      <td id=\"T_97006_row13_col2\" class=\"data row13 col2\" >0,00</td>\n",
       "      <td id=\"T_97006_row13_col3\" class=\"data row13 col3\" >0,26</td>\n",
       "      <td id=\"T_97006_row13_col4\" class=\"data row13 col4\" >0,66</td>\n",
       "      <td id=\"T_97006_row13_col5\" class=\"data row13 col5\" >1,27</td>\n",
       "      <td id=\"T_97006_row13_col6\" class=\"data row13 col6\" >12,74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x74ccdbf8d100>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "start_data_11"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['mean', 'std', 'min', '25%', '50%', '75%', 'max', 'objet']\n",
    "predictions = []\n",
    "for i, n in enumerate(mc.index):\n",
    "    xi = samples[i][\"Petit lac\"].describe()\n",
    "    xi.loc[\"objet\"] = n\n",
    "    predictions.append(pd.DataFrame(xi).T)\n",
    "hl_predictions = pd.concat(predictions)\n",
    "hl_predictions = hl_predictions[columns]\n",
    "hl_predictions.set_index('objet', inplace=True, drop=True)\n",
    "hl_predictions.index.name = None\n",
    "petit_lac = rc.translated_and_style_for_display(hl_predictions, display_language_map, display_language, gradient=False)\n",
    "caption =  f\"<b>{label}11 :</b> Petit lac, La distribution attendue des objets les plus courants 2024.\" \n",
    "glue(\"start_data_11\", petit_lac.set_caption(caption), display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae464695-6651-49c9-b0ec-03d8577f1149",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git repo: https://github.com/hammerdirt-analyst/plastock.git\n",
      "\n",
      "Git branch: main\n",
      "\n",
      "seaborn   : 0.13.1\n",
      "matplotlib: 3.8.2\n",
      "numpy     : 1.26.3\n",
      "pandas    : 2.0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions -b -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62784e-3db5-4d60-994f-e45e2e3ef286",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d3862e-f440-4768-98dd-864407e37721",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "<!-- ### Analyse factorielle de données mixtes\n",
    "\n",
    "L'ACP n'est pas recommandée si l'on utilise des types de données mixtes. Nous suivrons ici la méthode recommandée. Nous poursuivrons ensuite avec une ACP traditionnelle. Dans ce cas particulier, l'augmentation de la dimensionnalité causée par les variables nominales peut ne pas être un problème.\n",
    "\n",
    "_\"L’introduction simultanée de variables quantitatives et qualitatives (donnéesdites mixtes) en tant qu’éléments actifs d’une même analyse factorielle est une problématique fréquente. La méthodologie usuelle consiste à transformer les variables quantitatives en qualitatives en découpant en classes leur intervalle de variation et à soumettre le tableau homogène ainsi obtenu à une analyse des correspondances multiples (ACM)\"._ (_citation: Revue de statistique appliquée, tome 52, no 4 (2004), p. 93-111_)\n",
    "\n",
    "Cette section est rédigée en R. Les données sont les mêmes que celles utilisées dans les sections précédentes. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893e5ac-6122-47d6-8c1a-287345701c90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "<!-- ### AFDM 5 dimensions\n",
    "\n",
    "#### Valeurs Eigen et pourcentage cumulé de la variance -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
