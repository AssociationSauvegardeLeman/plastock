{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32bcdb7d-96d5-47f5-a77a-139bafcc6a7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from myst_nb import glue\n",
    "from IPython.display import Markdown as md\n",
    "from slugify import slugify\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import plastockconf as psc\n",
    "from plastockconf import name_zones, name_particles, name_frequentation, name_situation\n",
    "from plastockconf import particle_groups, name_substrate, name_distance, table_css_styles, table_css_styles_top\n",
    "\n",
    "from plastock import attribute_summary, attribute_summary_test, attribute_summary_grid, add_table_to_page\n",
    "import plastock as pstk\n",
    "import reportclass as rc\n",
    "\n",
    "def translate_describe(x, value_column, transpose: bool = False):\n",
    "    described = x.to_dict()\n",
    "    described.pop(\"count\")\n",
    "    described[\"moyenne\"] = described.pop(\"mean\")\n",
    "    described[\"écart-type\"] = described.pop(\"std\")\n",
    "    df = pd.DataFrame(described.items())\n",
    "    df.set_index(0, inplace=True)\n",
    "    df.rename(columns={1:value_column}, inplace=True)\n",
    "    df.index.name = None\n",
    "    \n",
    "    if transpose:\n",
    "        df = df.T\n",
    "        \n",
    "    return df\n",
    "import reportclass as rc\n",
    "import plastock as pst\n",
    "language_maps = rc.language_maps()\n",
    "\n",
    "glue('blank_caption', \" \", display=False)\n",
    "\n",
    "section = 'MP'\n",
    "page = \"\"\n",
    "\n",
    "work_data = pd.read_csv(\"data/end_pipe/long_form_micro.csv\")# thes samples were not completed\n",
    "drop_these = ['VD_Cul_2', 'VD_Vid_13', 'VD_Vid_8', 'VS_Bou_12']\n",
    "\n",
    "\n",
    "work_data = pd.read_csv(\"data/inprocess/micros_new_integrated.csv\")\n",
    "work_data.rename(columns={\"échantillon\":\"echantillon\"}, inplace=True)\n",
    "work_data = work_data[~work_data[\"echantillon\"].isin(drop_these)].copy()\n",
    "work_data.rename(columns={'echantillon':'échantillon', 'frequentation':'fréquentation'}, inplace=True)\n",
    "beach_data = pd.read_csv(\"data/end_pipe/asl_beaches.csv\")\n",
    "\n",
    "\n",
    "# the regional labels for each survey location\n",
    "regions = pd.read_csv(\"data/end_pipe/lac_leman_regions.csv\")\n",
    "regions.set_index('slug', drop=True, inplace=True)\n",
    "\n",
    "# the city name of the survey locations\n",
    "city_map = pd.read_csv('data/end_pipe/city_map.csv')\n",
    "city_map.set_index('slug', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006b1cf8-46b5-4359-ab2e-d5c0233efead",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! combine souples et dur !\n",
    "fibers = work_data.loc[work_data.objet == 'fibres'].copy()\n",
    "not_fibers = work_data.loc[work_data.objet != 'fibres'].copy()\n",
    "\n",
    "not_fibers['objet'] = 'fragments'\n",
    "\n",
    "work_datai = pd.concat([fibers, not_fibers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e618b570-baa3-4688-8cc6-857866c14610",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def name_the_new_distance(x, less='<= 500 m', more = '> 500 m'):\n",
    "    if x == 1:\n",
    "        return less\n",
    "    else:\n",
    "        return more\n",
    "\n",
    "def name_the_new_freq(x, new):\n",
    "    if x <= 2:\n",
    "        return new\n",
    "    else:\n",
    "        return 'Elévée'\n",
    "\n",
    "\n",
    "# the feature variables are added to the work_data\n",
    "ti = work_datai.copy()\n",
    "features = ['frequentation', 'situation', 'orientation', 'distance']\n",
    "\n",
    "work_datai['slug'] = work_datai.Plage.apply(lambda x: slugify(x))\n",
    "work_datai['region'] = work_datai.slug.apply(lambda x: regions.loc[x, 'alabel'])\n",
    "work_datai['city'] =  work_datai.slug.apply(lambda x: city_map.loc[x, 'city'])\n",
    "\n",
    "work_data['particules'] = work_data.compte\n",
    "work_datai[\"particules\"] = work_datai.compte\n",
    "\n",
    "work_data['slug'] = work_data.Plage.apply(lambda x: slugify(x))\n",
    "work_data['region'] = work_data.slug.apply(lambda x: regions.loc[x, 'alabel'])\n",
    "work_data['city'] =  work_data.slug.apply(lambda x: city_map.loc[x, 'city'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31df0293-bb2f-4aa2-9c3e-09d2b2fbdb41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# combining variables\n",
    "env_plastock = work_datai.copy()\n",
    "\n",
    "\n",
    "# the substrat and distance features are being combined\n",
    "# the two lowest and the two highest of each group are being combined\n",
    "# substrat is a matter of combining different granularities. They are being grouped as\n",
    "# sand and gravel.\n",
    "# distance is now grouped by locations either less than or equal to 500 meters\n",
    "env_plastock.loc[env_plastock.substrat <= 2, 'substrat'] = 1\n",
    "env_plastock.loc[env_plastock.substrat > 2, 'substrat'] = 2\n",
    "env_plastock.loc[env_plastock.distance <= 2, 'distance'] = 1\n",
    "env_plastock.loc[env_plastock.distance > 2, 'distance'] = 2\n",
    "env_plastock.loc[env_plastock[\"fréquentation\"] <= 2, 'fréquentation'] = 2\n",
    "work_data_combined = env_plastock.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2b4625-65e8-4ddc-9aa0-4e3f3d1fbdea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "wk_dt =work_datai.groupby('échantillon', as_index=False).compte.sum()\n",
    "limit = np.quantile(wk_dt.compte.values, .99)\n",
    "\n",
    "test = wk_dt[wk_dt.compte == 0][\"échantillon\"].unique()\n",
    "not_these = wk_dt[wk_dt.compte > limit +1][\"échantillon\"].unique()\n",
    "not_these = [*not_these, *test]\n",
    "\n",
    "\n",
    "wd_10 = work_datai[~work_datai[\"échantillon\"].isin(not_these)].copy()\n",
    "wd_10dt = wd_10.groupby('échantillon', as_index=False).compte.sum()\n",
    "\n",
    "test = wk_dt[wk_dt.compte == 0][\"échantillon\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e55d98-6c25-463f-85a1-279a94a6ed64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "wk_dt =wd_10.groupby('échantillon', as_index=False).compte.sum()\n",
    "# fragments versus fibres\n",
    "# eliminate anything beyond the 99th percentile\n",
    "\n",
    "sit_disp = pd.DataFrame(translate_describe(wk_dt.compte.describe(), \"résultats\"))\n",
    "sit_disp.loc[\"échantillon\", \"résultats\"] = wd_10[\"échantillon\"].nunique()\n",
    "sit_disp.loc[\"total\", \"résultats\"] = wd_10.compte.sum()\n",
    "sit_disp[\"résultats\"] = sit_disp[\"résultats\"].astype(int)\n",
    "sit_disp = sit_disp.style.set_table_styles(table_css_styles).format(**psc.format_kwargs)\n",
    "sit_disp = add_table_to_page(sit_disp, 1, \"\", section, page, \"\")\n",
    "glue('sit_disp_micro', sit_disp, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c1ba13-ab5e-4c73-be3a-2dbc09c1b305",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "cgp_c = beach_data[[\"Plage\", \"x\", \"y\"]]\n",
    "cgp_c.set_index(\"Plage\", inplace=True, drop=True)\n",
    "\n",
    "map_data = wk_dt.copy()\n",
    "plage_map = work_data[[\"Plage\", \"échantillon\"]].copy()\n",
    "plage_map = plage_map.drop_duplicates([\"Plage\", \"échantillon\"])\n",
    "plage_map.set_index(\"échantillon\", drop=True, inplace=True)\n",
    "map_data[\"Plage\"] = map_data[\"échantillon\"].apply(lambda x: plage_map.loc[x, \"Plage\"])\n",
    "\n",
    "map_data = map_data.groupby(\"Plage\", as_index=False).compte.mean()\n",
    "map_data[\"compte\"] = map_data.compte.astype(int)\n",
    "map_data[\"lat\"] = map_data.Plage.apply(lambda x: cgp_c.loc[x, \"x\"])\n",
    "map_data[\"lon\"] = map_data.Plage.apply(lambda x: cgp_c.loc[x, \"y\"])\n",
    "\n",
    "map_data.to_csv(\"resources/maps/micro_count_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d2dfa7-7eef-4a04-98d7-a22e3ae1bd60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8,8))\n",
    "wk_dt = wd_10.groupby('échantillon', as_index=False).particules.sum()\n",
    "vals = 'particules'\n",
    "object_column = vals\n",
    "ylim = np.quantile(wk_dt.particules.values, .99)\n",
    "xlim = np.quantile(wk_dt.particules.values, .99)\n",
    "sns.scatterplot(wk_dt, x=\"échantillon\", y=vals, label='Pla\\'stock micros particules', ax=axs[0, 0])\n",
    "sns.boxplot(wk_dt, y=vals,  showfliers=True, ax=axs[0, 1], dodge=False)\n",
    "sns.histplot(wk_dt, x=vals,  ax=axs[1, 0], stat='probability', kde=True)\n",
    "sns.ecdfplot(wk_dt, x=vals,  ax=axs[1, 1])\n",
    "\n",
    "# axs[0,0].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "# axs[0,0].xaxis.set_major_formatter(mdates.DateFormatter('%m-%y'))\n",
    "\n",
    "axs[0, 0].set_ylim(-1, ylim)\n",
    "axs[0, 1].set_ylim(-1, ylim)\n",
    "axs[1, 1].set_xlim(-1, xlim)\n",
    "axs[1, 0].set_xlim(-1, xlim)\n",
    "# Hide X and Y axes tick marks\n",
    "axs[0,0].set_xticks([])\n",
    "\n",
    "\n",
    "axs[0, 0].set_xlabel(\"échantillon\")\n",
    "axs[0, 0].set_ylabel(\"Particules\")\n",
    "\n",
    "axs[1, 0].set_xlabel(\"Particules\")\n",
    "axs[1, 0].set_ylabel(\"Probabilité\")\n",
    "axs[0, 1].set_xlabel(\"\")\n",
    "axs[0, 1].set_ylabel(\"Particules\")\n",
    "axs[0, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "axs[1, 1].set_xlabel(\"Particules\")\n",
    "axs[0,0].set_title(\"Total par échantillon\", loc=\"left\")\n",
    "axs[0,1].set_title(\"Boîte de Tukey\", loc=\"left\")\n",
    "axs[1,0].set_title(\"Histogramme\", loc=\"left\")\n",
    "axs[1,1].set_title(\"Fonction de répartition\", loc=\"left\")\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "glue('micro-situataion-sa', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4480a701-2e29-455b-86a3-0abb9b84f20b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# composition of total\n",
    "# work_data has the excluded samples\n",
    "parts = work_data.groupby([\"objet\"], as_index=False).compte.sum()\n",
    "parts[\"% du total\"] = parts.compte/parts.compte.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b051a994-a36c-4f39-85a5-06c3f208bbc3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].groupby(['échantillon', 'objet'], as_index=False).particules.sum()\n",
    "table2 = data.groupby('objet').particules.describe()\n",
    "table2 = table2.reindex(['fibres', 'fdure', 'souple'])\n",
    "table2 = table2.astype('int')\n",
    "language_maps = rc.language_maps()\n",
    "g = language_maps['fr']\n",
    "new_names = {x:g.loc[x, 'fr'] for x in table2.columns if x in g.index}\n",
    "\n",
    "\n",
    "table2['Particule'] = table2.index.map(lambda x: psc.particle_groups[x])\n",
    "table2.rename(columns=new_names, inplace=True)\n",
    "caption = \"Résultats par forme d'objet.\"\n",
    "\n",
    "table2 = table2[[table2.columns[-1], *table2.columns[:-1]]].style.set_table_styles(table_css_styles).hide(axis=0)\n",
    "table2 = pst.add_table_to_page(table2, 2, caption, section, page, \"\", format_index=\"both\")\n",
    "glue('table2', table2, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "976be5d9-f3f3-4bcb-96ab-db8b7d0bb351",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data = wd_10.groupby(['échantillon', 'objet'], as_index=False).particules.sum()\n",
    "table3 = data.groupby('objet').particules.describe()\n",
    "table3 = table3.astype('int')\n",
    "table3['Particule'] = [x.capitalize() for x in table3.index]\n",
    "table3.rename(columns=new_names, inplace=True)\n",
    "table3 = table3[[table3.columns[-1], *table3.columns[:-1]]].style.set_table_styles(table_css_styles)\n",
    "\n",
    "caption = \"Résultats par forme d'objet, fragments durs et souples agrégée.\"\n",
    "table3 = pst.add_table_to_page(table3, 3, caption, section, page, \"\", format_index='both')\n",
    "table3 = table3.hide(axis='index')\n",
    "glue('table3', table3, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08e7937-1f56-4823-832d-b1311fddc2ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fibres'\n",
    "feature = 'substrat'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_substrate[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fibres, résultats par subbstrat.\"\n",
    "\n",
    "\n",
    "table4 = add_table_to_page(table4, 4, caption, section, page, \"\", format_index='both')\n",
    "glue('table4', table4, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68dce72-396f-4242-9a6d-125fd32f3616",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fibres'\n",
    "feature = 'fréquentation'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_frequentation[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fibres, résultats par fréquentation\"\n",
    "\n",
    "\n",
    "table5 = add_table_to_page(table4, 5, caption, section, page, \"\", format_index='both')\n",
    "glue('table5', table5, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6be96dd1-3958-4b0a-9a2f-7ae4d7b14ce6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fibres'\n",
    "feature = 'situation'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_situation[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fibres, résultats par situation\"\n",
    "\n",
    "\n",
    "table6 = add_table_to_page(table4, 6, caption, section, page, \"\", format_index='both')\n",
    "glue('table6', table6, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0e7074d-b775-4ab6-9392-fe812e35ce39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fibres'\n",
    "feature = 'distance'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_distance[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fibres, résultats par distance du parking\"\n",
    "\n",
    "\n",
    "table7 = add_table_to_page(table4, 7, caption, section, page, \"\", format_index='both')\n",
    "glue('table7', table7, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68de8477-77b1-49d8-a9a8-84f080907057",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fdure'\n",
    "feature = 'substrat'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_substrate[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fragments durs, résultats par substrat\"\n",
    "\n",
    "\n",
    "table4 = add_table_to_page(table4, 8, caption, section, page, \"\", format_index='both')\n",
    "glue('table8', table4, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9786ceb0-cd7b-48fa-82ad-9e86f456e79b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fdure'\n",
    "feature = 'fréquentation'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_frequentation[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption =  \"Fragments durs, résultats par fréquentation\"\n",
    "\n",
    "\n",
    "table5 = add_table_to_page(table4, 9, caption, section, page, \"\", format_index='both')\n",
    "glue('table9', table5, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "901f1aeb-f2e3-49cd-8edc-50c9b5bd9688",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fdure'\n",
    "feature = 'situation'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_situation[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption =  \"Fragments durs, résultats par situtation\"\n",
    "\n",
    "\n",
    "table6 = add_table_to_page(table4, 10, caption, section, page, \"\", format_index='both')\n",
    "glue('table10', table6, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc981225-9b6d-4dde-8ffe-06336f4be017",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'fdure'\n",
    "feature = 'distance'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_distance[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption =  \"Fragments durs, résultats par distance du parking\"\n",
    "\n",
    "\n",
    "table7 = add_table_to_page(table4, 11, caption, section, page, \"\", format_index='both')\n",
    "glue('table11', table7, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea4fba1-bfd3-4382-888f-8e44fc23a47d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'souple'\n",
    "feature = 'substrat'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_substrate[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fragments souples, résultats par substrat\"\n",
    "\n",
    "\n",
    "table4 = add_table_to_page(table4, 12, caption, section, page, \"\", format_index='both')\n",
    "glue('table12', table4, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfc01c54-9124-4ae8-8fcf-c67f164dca58",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'souple'\n",
    "feature = 'fréquentation'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_frequentation[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fragments souples, résultats par fréquentation\"\n",
    "\n",
    "\n",
    "table5 = add_table_to_page(table4, 13, caption, section, page, \"\", format_index='both')\n",
    "glue('table13', table5, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfccafd9-3db4-4268-aa0c-0792fdf917ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'souple'\n",
    "feature = 'situation'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_situation[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fragments souples, résultats par situation\"\n",
    "\n",
    "\n",
    "table6 = add_table_to_page(table4, 14, caption, section, page, \"\", format_index='both')\n",
    "glue('table14', table6, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7ffe399-c9a2-4440-b477-19e619d26d65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "obj = 'souple'\n",
    "feature = 'distance'\n",
    "\n",
    "cols = ['échantillon', feature,  'objet']\n",
    "\n",
    "data = work_data[~work_data[\"échantillon\"].isin(not_these)].copy()\n",
    "data = data[data.objet == obj].groupby(cols, as_index=False).particules.sum()\n",
    "table4 = data.groupby(feature).particules.describe()\n",
    "table4 = table4.astype('int')\n",
    "table4[feature] = table4.index.map(lambda x: name_distance[x])\n",
    "table4.set_index(feature, inplace=True, drop=True)\n",
    "table4.index.name = None\n",
    "table4.rename(columns=new_names, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "table4 = table4.style.set_table_styles(table_css_styles)\n",
    "caption = \"Fragments souples, résultats par distance du parking\"\n",
    "\n",
    "\n",
    "table7 = add_table_to_page(table4, 15, caption, section, page, \"\", format_index='both')\n",
    "glue('table15', table7, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "832040b5-44c4-435e-9af1-b134c5b10acc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "bn = work_data.groupby([\"region\", \"objet\"], as_index=False).particules.mean()\n",
    "bn = bn.pivot(columns=\"region\", index=\"objet\")\n",
    "bn.index.name = None\n",
    "bn.columns.name =None\n",
    "bn = bn.droplevel(0, axis=1)\n",
    "bn.columns.name = None\n",
    "bn[\"object\"] = bn.index.map(lambda x: particle_groups[x])\n",
    "bn.set_index('object', inplace=True, drop=True)\n",
    "bn.index.name = None\n",
    "bn = bn.astype('int')\n",
    "bn = bn.reindex([\"Fibre\", \"Particule rigide\", \"Particule souple\"])\n",
    "bn.loc[\"Total\"] = bn.sum()\n",
    "\n",
    "bn = bn.style.set_table_styles(table_css_styles)\n",
    "caption = \"Résultats moyens de l'échantillon par région et par forme\"\n",
    "\n",
    "\n",
    "tablei = add_table_to_page(bn, 16, caption, section, page, \"\", format_index='both')\n",
    "glue('table16', tablei, display=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4af3e202-a714-479a-9805-2318d838bc8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "bn = work_data.groupby([\"region\", \"objet\"], as_index=False).particules.sum()\n",
    "bn = bn.pivot(columns=\"region\", index=\"objet\")\n",
    "bn.index.name = None\n",
    "bn.columns.name =None\n",
    "bn = bn.droplevel(0, axis=1)\n",
    "bn.columns.name = None\n",
    "bn[\"object\"] = bn.index.map(lambda x: particle_groups[x])\n",
    "bn.set_index('object', inplace=True, drop=True)\n",
    "bn.index.name = None\n",
    "bn = bn.astype('int')\n",
    "bn = bn.reindex([\"Fibre\", \"Particule rigide\", \"Particule souple\"])\n",
    "bn.loc[\"Total\"] = bn.sum()\n",
    "\n",
    "bn = bn.style.set_table_styles(table_css_styles)\n",
    "caption = \"Nombre total de particules collectées par région et par forme\"\n",
    "\n",
    "\n",
    "tablei = add_table_to_page(bn, 17, caption, section, page, \"\", format_index='both')\n",
    "glue('table17', tablei, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cef9308c-a779-4059-bb62-fb6473abf9f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "nsamples = work_data.groupby([\"region\"], as_index=False)[\"échantillon\"].nunique()\n",
    "nsamples.set_index(\"region\", inplace=True, drop=True)\n",
    "nsamples.rename(columns={\"échantillon\": \"Echantillons\"}, inplace=True)\n",
    "nsamples.index.name = None\n",
    "nsamples = nsamples.style.set_table_styles(table_css_styles)\n",
    "caption = \"Nombre d'échantillons\"\n",
    "\n",
    "\n",
    "tablei = add_table_to_page(nsamples, 18, caption, section, page, \"\", format_index='both')\n",
    "glue('table18', tablei, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d58b4eb1-2bcd-4749-8a6c-f0926bfc14c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "position_totals = wd_10.groupby([\"Plage\",\"échantillon\", \"position\"], as_index=False).particules.sum()\n",
    "position_totals[\"position\"] = position_totals.position.apply(lambda x: name_zones[x])\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(9,5))\n",
    "\n",
    "sns.boxplot(data=position_totals, x=\"Plage\", y=\"particules\", hue=\"position\", ax=ax, showfliers=False)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Particules\")\n",
    "ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "# capitalize_x_and_y_axis_labels(ax)\n",
    "# capitalize_legend_components(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "glue('fig-mp3', fig, display=False)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92188c-a5b0-43ca-860a-c29086319fbe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Micros particules \n",
    "\n",
    "__Format__ \n",
    "\n",
    "Le format suit celui de l'annexe pour les [microplastiques](micro_atts) . Nous incluons également l'analyse utilisant des variables combinées selon la méthode décrite dans la section [Résultats précédents](previous_results).\n",
    "\n",
    ":::{card}\n",
    ":margin: 3\n",
    "\n",
    "```{image} resources/maps/chapter_one_map.jpeg\n",
    ":alt: chapter one map\n",
    ":align: center\n",
    ":name: chapter_one_map\n",
    "```\n",
    "+++\n",
    "<b>Fig 1.1 :</b> Carte des résultats de l'étude. Nombre moyenne de particules. Le diamètre du marqueur est relatif à la compte moyenne de particules,\n",
    ":::\n",
    "\n",
    "__Le système de mesure.__\n",
    "\n",
    "Dans cette section, les unités sont le nombre de particules par conteneur. Le récipient a des côtés de 10 cm X 10 cm X 5 cm ou 0,0005 m³.\n",
    "\n",
    "## Résultats\n",
    "\n",
    "::::{grid} 1 1 2 2\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`sit_disp_micro`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "D'après le tableau [A1-4](micro-table-A1-4), le nombre maximum de particules était de 2 991. Ce chiffre a été enregistré à la Pichette, où 2 593 fibres ont été comptées dans un échantillon. Le 99e percentile de tous les totaux d'échantillons est de 1 060 particules par échantillon. Ce chiffre a été dépassé trois fois, deux fois à Port Choiseul et une fois à la Pichette.\n",
    "\n",
    "Nous considérons ici les données limitées au 99e percentile, c'est-à-dire que nous éliminons les trois échantillons qui ont dépassé 1 061 particules.\n",
    "\n",
    "<b>Table MP-1 :</b> Distribution des résultats de l’ensemble de l’échantillons Pla'stock. Toutes les valeurs inférieures à 1 061 (99e percentile).\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    ":::{card} \n",
    "\n",
    "{glue}`micro-situataion-sa`\n",
    "\n",
    "+++\n",
    "<b> Figure 1.2 :</b> Pla'stock 2022: distribution des résultats de l’ensemble de l’échantillons Pla'stock. L'élimination de ces trois échantillons a entraîné une baisse de 24 points de la moyenne et de 115 points de l'écart-type ([A1-4](micro-table-A1-4)).\n",
    ":::\n",
    "\n",
    ":::{card} \n",
    "\n",
    "{glue}`fig-mp3` \n",
    "\n",
    "+++\n",
    "<b> Figure 1.3 :</b> Pla'stock 2022: distribution des résultats par lieu d'échantillonage.\n",
    ":::\n",
    "\n",
    "\n",
    "(conditions_mp)=\n",
    "### Conditions d'échantillonage\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Resumé\n",
    ":selected:\n",
    "\n",
    "{glue}`table2`\n",
    "\n",
    "{glue}`table3`\n",
    "\n",
    "\n",
    "::: \n",
    "\n",
    ":::{tab-item} Fibres\n",
    "\n",
    "{glue}`table4`\n",
    "\n",
    "{glue}`table5`\n",
    "\n",
    "{glue}`table6`\n",
    "\n",
    "{glue}`table7`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Fragments\n",
    "\n",
    "{glue}`table8`\n",
    "\n",
    "{glue}`table9`\n",
    "\n",
    "{glue}`table10`\n",
    "\n",
    "{glue}`table11`\n",
    "::: \n",
    "\n",
    ":::{tab-item} Souples\n",
    "\n",
    "{glue}`table12`\n",
    "\n",
    "{glue}`table13`\n",
    "\n",
    "{glue}`table14`\n",
    "\n",
    "{glue}`table15`\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "### Régionalité\n",
    "\n",
    "::::{grid} 1 1 2 2\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`table16`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`table17`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`table18`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a9c6a06-1afc-4bfa-862f-e2b1da4ec0fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def analyze_scenario(scenario_data, func, n_iterations=100, bin_width=0.2):\n",
    "    \"\"\"\n",
    "    Analyze a specific scenario using Random Forest regression with bootstrapping,\n",
    "    and calculate feature importances.\n",
    "\n",
    "    :param data: DataFrame containing the dataset.\n",
    "    :param feature_1: The name of the first feature for filtering.\n",
    "    :param feature_1_value: The value of the first feature to filter by.\n",
    "    :param feature_2: The name of the second feature for filtering.\n",
    "    :param feature_2_value: The value of the second feature to filter by.\n",
    "    :param n_iterations: Number of bootstrap iterations. Default is 100.\n",
    "    :param bin_width: Width of each bin for histogram. Default is 0.2.\n",
    "    :return: A tuple containing bins, bin probabilities, flattened predictions, and feature importances.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare data for regression\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaled = y_scaler.fit_transform(scenario_data['pcs_m'].values.reshape(-1,1)).flatten()\n",
    "    \n",
    "    # Initialize the OneHotEncoder\n",
    "    # here we encode the ordinal data\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    \n",
    "    X = scenario_data.drop('pcs_m', axis=1)\n",
    "    \n",
    "    # Apply the encoder to the categorical columns\n",
    "    encoded_data = encoder.fit_transform(scenario_data[['fréquentation', 'situation', 'distance', 'substrat']])\n",
    "    # Create a DataFrame with the encoded data\n",
    "    X_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['fréquentation', 'situation', 'distance', 'substrat']))\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_scaled, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Bootstrap predictions and accumulate feature importances\n",
    "    bootstrap_predictions = []\n",
    "        \n",
    "    # Collect diagnostic at each repetition\n",
    "    cum_mse = []\n",
    "    cum_r2 = []\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        X_train_sample, y_train_sample = resample(X_train, y_train, n_samples= len(y_train) -1)\n",
    "        rf_model_sample = func\n",
    "        rf_model_sample.fit(X_train_sample, y_train_sample)\n",
    "        \n",
    "        pred = rf_model_sample.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, pred)\n",
    "        pred = y_scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "        bootstrap_predictions.append(pred)\n",
    "        mse = mean_squared_error(y_test , pred)\n",
    "        \n",
    "        cum_mse.append(mse)\n",
    "        cum_r2.append(r2)           \n",
    "\n",
    "    # Flatten the predictions array\n",
    "    predictions_flat = np.array(bootstrap_predictions).flatten()\n",
    "    \n",
    "    return predictions_flat, cum_mse, cum_r2\n",
    "\n",
    "def plot_histogram(predictions, observed, title=\"\", reference='camp-dist-1', display=False, order='predictions', xmax=800, n_bins=20, x_label='pcs/m³'):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    if order == 'predictions':\n",
    "        sns.histplot(predictions, binwidth=n_bins, stat=\"probability\", ax=ax, label='prédictions', zorder=0)\n",
    "        sns.histplot(observed, binwidth=n_bins, stat=\"probability\", label='observée', zorder=1, ax=ax)\n",
    "    else:\n",
    "        sns.histplot(predictions, binwidth=n_bins, stat=\"probability\", ax=ax, label='prédictions', zorder=1)\n",
    "        sns.histplot(observed, binwidth=n_bins, stat=\"probability\", label='observée', zorder=0, ax=ax)\n",
    "    ax.set_xlim(-.1, xmax)\n",
    "    plt.title(title, loc='left')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('Densité de Probabilité')\n",
    "    plt.legend()\n",
    "    glue(reference, fig, display=display)\n",
    "    plt.close()\n",
    "\n",
    "def evalutate_model(r2s, mses, label, model='random-forest'):\n",
    "    r2 = np.round(np.mean(r2s), 2)\n",
    "    mse = np.round(np.mean(mses), 2)\n",
    "    results = {\"cross validated error\":r2, \"mean² error\":mse, 'model':model}\n",
    "    return pd.DataFrame(results, index=[label])\n",
    "\n",
    "# Calculating quantiles for Scenario 2\n",
    "format_kwargs = dict(precision=0, thousands=\"'\")\n",
    "q_uants = [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "index = ['1%', '25%', '50%', '75%', '99%', 'Moyenne']\n",
    "def makeqdf(observed, predicted, index=index, quants=q_uants, caption=\"\"):\n",
    "    \n",
    "    o_q = np.quantile(observed, quants)\n",
    "    m_o = np.mean(observed)\n",
    "    o_p = np.quantile(predicted, quants)\n",
    "    m_p = np.mean(predicted)\n",
    "    \n",
    "    results = {'observée':[*o_q, m_o], 'prédiction': [*o_p, m_p]}\n",
    "   \n",
    "    return pd.DataFrame(results, index=index).style.set_table_styles(table_css_styles_top).format(**format_kwargs).set_caption(caption)\n",
    "\n",
    "cols = ['échantillon', 'position', 'fréquentation','situation', 'distance', 'substrat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c91f3523-e232-4c59-b7fe-a328b70640af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "estimators = 10\n",
    "iterations = 100\n",
    "\n",
    "test_xt = work_data_combined[~work_data_combined[\"échantillon\"].isin(not_these)].copy()\n",
    "# the volume of the container used to sample in cm³\n",
    "# sample_volume_cm = 10*10*5\n",
    "# sample_volume_m = sample_volume_cm/10**6\n",
    "test_xt['pcs_m'] = test_xt['compte']\n",
    "\n",
    "\n",
    "# Filter for Scenario \n",
    "test_xi = test_xt[(test_xt['position'] == 1)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat',  'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.85)\n",
    "predictions_flat, feature_importances,  mse, r2 = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "caption = 'Ligne d\\'eau'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions_flat, caption=caption)\n",
    "glue('q-lignedeau-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules, Le Léman\\nDistribution des Prédictions - Ligne d\\'eau'\n",
    "pstk.plot_histogram(predictions_flat, test_x.pcs_m.values, title=title, reference='lignedeau-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94ff68ec-50b3-4cad-9ff0-e7c81e9617c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "\n",
    "test_xt = work_data_combined[~work_data_combined[\"échantillon\"].isin(not_these)].copy()\n",
    "# the volume of the container used to sample in cm³\n",
    "# sample_volume_cm = 10*10*5\n",
    "# sample_volume_m = sample_volume_cm/10**6\n",
    "test_xt['pcs_m'] = test_xt['compte']\n",
    "\n",
    "\n",
    "# Filter for Scenario \n",
    "test_xi = test_xt.copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat',  'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.85)\n",
    "predictions, feature_importances,  mse, r2 = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "\n",
    "caption = 'Tous les positions'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-tous-md-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules, Le Léman\\nDistribution des Prédictions'\n",
    "pstk.plot_histogram(predictions_flat, test_x.pcs_m.values, title=title, reference='tous-md-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94bb0f64-eaab-4b39-a648-938aa42a16e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = test_xt[(test_xt['position'] == 2)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.9, min_samples_leaf=2)\n",
    "predictions, feature_importances,  mse, r2 = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "caption = 'Plage seche'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-plageseche-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022 , Le Léman micro particules\\nDistribution des Prédictions - Plage seche'\n",
    "pstk.plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='plageseche-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e78b009-f725-40d2-a9d5-5906eeb572cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "cols = ['échantillon', 'position', 'fréquentation','situation', 'distance', 'substrat']\n",
    "test_xi = test_xt[(test_xt['position'] == 2)&(test_xt.objet == 'fibres')].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.85)\n",
    "predictions, feature_importances,  mse, r2 = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "caption = 'Plage seche et fibres'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-plagesechefibres-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions - Plage seche et fibres'\n",
    "pstk.plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='plagesechefibres-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a91d8da-3067-4c5a-986e-9daa8bdc4ba4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = test_xt[(test_xt['substrat'] == 1)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.9, min_samples_leaf=3)\n",
    "predictions, feature_importances,  mse, r2 = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "caption = 'Sable'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-sablesfins-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022, Le Léman\\nDistribution des Prédictions - Sables fins'\n",
    "pstk.plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='sablesfins-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d98ec6b-0f31-4d80-8b94-ac5c73792dfd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = test_xt[(test_xt['substrat'] == 2)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.85)\n",
    "predictions, feature_importances,  mse, r2 = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "caption = 'Graviers'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-cailloux-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions - Gravier'\n",
    "pstk.plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='cailloux-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "625968dd-abe1-4da3-88d6-7df8e376d3ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = test_xt[(test_xt['fréquentation'] == 3)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.3)\n",
    "predictions, feature_importances,  mse, r2 = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "caption = 'Fréquentation élevée'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-freq3-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions - Fréquentation élevée'\n",
    "pstk.plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='freq3-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "790d9487-2da8-4330-b7b6-6488edb5c367",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = test_xt[(test_xt['fréquentation'] == 2)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42, max_samples=.85)\n",
    "predictions, feature_importances,  mse, r2  = pstk.analyze_scenario(test_x, func,  n_iterations=iterations)\n",
    "\n",
    "caption = 'Fréquentation moyenne'\n",
    "q_sit_2_freq_3 = pstk.makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-freq2-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions - Fréquentation moyenne'\n",
    "pstk.plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='freq2-sa', display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfdd4b-eaa3-408b-99a7-5ef417a215ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(random_forest_sa_md)=\n",
    "### Random Forest \n",
    "\n",
    "Source : [scikit-learn random forest](https://scikit-learn.org/0.16/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "criterion : `absolute error`\n",
    "\n",
    "La régression avec forêt aléatoire est une technique d'apprentissage automatique (machine learning) utilisée pour prédire des résultats continus (par opposition aux catégories dans la classification). C'est une méthode d'apprentissage ensembliste, ce qui signifie qu'elle combine les prédictions de plusieurs algorithmes d'apprentissage automatique pour produire des prédictions plus précises.\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Toutes les conditions\n",
    "{glue}`tous-md-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Fréquentation moyenne\n",
    "{glue}`freq2-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Haute fréquentation\n",
    "{glue}`freq3-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Graviers\n",
    "{glue}`cailloux-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Sable\n",
    "{glue}`sablesfins-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Plage seche et sable fins\n",
    "{glue}`plagesechefibres-sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Plage seche\n",
    "{glue}`plageseche-sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Ligne d'eau\n",
    "{glue}`lignedeau-sa`\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{tab-item} Résultats\n",
    ":selected:\n",
    "\n",
    "````{grid} 1 2 2 2\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-tous-md-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-lignedeau-sa`\n",
    "\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-freq2-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-freq3-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-cailloux-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-sablesfins-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-plagesechefibres-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-plageseche-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "\n",
    "```\n",
    "\n",
    "````\n",
    ":::\n",
    "\n",
    "::::    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79aecd81-eadc-4468-9321-734e64d062d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'top'\n",
    "pcs_col = 'particules'\n",
    "cols = ['échantillon', 'fréquentation', 'situation', 'distance', 'substrat']\n",
    "grid_range = np.arange(0, 1001)\n",
    "\n",
    "# The data to analyze and a beta prior\n",
    "test_xt = work_data_combined[~work_data_combined[\"échantillon\"].isin(not_these)].copy()\n",
    "beta_prior = pstk.calculate_beta_prior(grid_range=grid_range, bin_density_numbers=[1])\n",
    "\n",
    "bins = [1]\n",
    "\n",
    "test_x = test_xt.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "test_x['top'] = 1\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock1 = pstk.define_posterior(grid_pstock.copy(), beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock1)\n",
    "\n",
    "caption = 'Toutes les conditions'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-tous', test_grid_quants, display=False)\n",
    "\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules,\\nDistribution des Prédictions: toutes les conditions,  approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-toutes-ga', display=False, xlabel=pcs_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3000d5c6-64f0-4a31-8e8d-8c6e8eb58848",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'fréquentation'\n",
    "pcs_col = 'particules'\n",
    "cols = ['échantillon', 'fréquentation', 'situation', 'distance', 'substrat']\n",
    "bins = [3]\n",
    "\n",
    "# beta_prior = pstk.calculate_beta_prior(grid_range=grid_range, bin_density_numbers=[1])\n",
    "\n",
    "test_x = test_xt[(test_xt['fréquentation'] == 3)].copy()\n",
    "test_x = test_x.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock2 = pstk.define_posterior(grid_pstock.copy(), beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock2)\n",
    "\n",
    "caption = 'Fréquentation élevée'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-freqelevee', test_grid_quants, display=False)\n",
    "\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions: Fréquentation élevée,  approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-freqelevee-ga', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c160f4e-4c5e-47ca-8847-dabe78016885",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'fréquentation'\n",
    "pcs_col = 'particules'\n",
    "cols = ['échantillon', 'fréquentation', 'situation', 'distance', 'substrat']\n",
    "bins = [2]\n",
    "\n",
    "# beta_prior = pstk.calculate_beta_prior(grid_range=grid_range, bin_density_numbers=[1])\n",
    "\n",
    "test_x = test_xt[(test_xt['fréquentation'] == 2)].copy()\n",
    "test_x = test_x.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock2 = pstk.define_posterior(grid_pstock.copy(), beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock2)\n",
    "\n",
    "caption = 'Fréquentation moyenne'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-freqmoyenne', test_grid_quants, display=False)\n",
    "\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions: Fréquentation moyenne,  approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-freqmoyenne-ga', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e326aef-da72-4343-8021-7462d68ef053",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'substrat'\n",
    "pcs_col = 'particules'\n",
    "# grid_range = grid_val_index\n",
    "# category value\n",
    "cat = 1\n",
    "bins = [cat]\n",
    "# test_xt = work_data_combined[~work_data_combined[\"échantillon\"].isin(not_these)].copy()\n",
    "# test_xt['pcs_m'] = test_xt['compte']\n",
    "\n",
    "mask = (test_xt[col] == cat)&(test_xt.substrat == cat)\n",
    "test_x = test_xt[mask].copy()\n",
    "\n",
    "test_x = test_x.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock3 = pstk.define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock3.copy())\n",
    "\n",
    "caption = 'Sable'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-sable', test_grid_quants, display=False)\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions: Sable, approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-sable-ga', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a18a8-652b-4279-acef-ef564471bde1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1db3bdc8-7cbf-4eb6-95d0-2d86eca1f20f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'substrat'\n",
    "pcs_col = 'particules'\n",
    "# grid_range = grid_val_index\n",
    "# category value\n",
    "cat = 2\n",
    "bins = [cat]\n",
    "# test_xt = work_data_combined[~work_data_combined[\"échantillon\"].isin(not_these)].copy()\n",
    "# test_xt['pcs_m'] = test_xt['compte']\n",
    "\n",
    "mask = (test_xt[col] == cat)\n",
    "test_x = test_xt[mask].copy()\n",
    "\n",
    "\n",
    "\n",
    "test_x = test_x.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock3 = pstk.define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock3.copy())\n",
    "\n",
    "caption = 'Graviers'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-graviers', test_grid_quants, display=False)\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions: Graviers,  approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-graviers-ga', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bd63ce3-cc10-4840-9b45-d802bb788ba0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "mask = (test_xt.position == 2)&(test_xt.objet == 'fibres')\n",
    "test_x = test_xt[mask].copy()\n",
    "\n",
    "test_x = test_x.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock3 = pstk.define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock3.copy())\n",
    "\n",
    "caption = 'Plage seche et fibres'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-sechefibres', test_grid_quants, display=False)\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions: Plage seche et fibres, approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-sechefibres-ga', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e421993-36d7-417f-b69f-4e6e90bbf018",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "mask = (test_xt.position == 2)\n",
    "test_x = test_xt[mask].copy()\n",
    "\n",
    "\n",
    "\n",
    "test_x = test_x.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock3 = pstk.define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock3.copy())\n",
    "\n",
    "caption = 'Plage seche'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-seche', test_grid_quants, display=False)\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions: Plage seche,  approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-seche-ga', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9905868-60a4-4fdd-b785-7cd0192c4bcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "mask = (test_xt.position == 1)\n",
    "test_x = test_xt[mask].copy()\n",
    "\n",
    "\n",
    "\n",
    "test_x = test_x.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "grid_pstock = pstk.calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock3 = pstk.define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = pstk.posterior_predictions(post_grid_pstock3.copy())\n",
    "\n",
    "caption = 'Ligne d\\'eau'\n",
    "\n",
    "test_grid_quants = pstk.makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-micro-lignedeau-ga', test_grid_quants, display=False)\n",
    "title = 'Pla\\'stock 2022, Le Léman micro particules\\nDistribution des Prédictions: Ligne d\\'eau, approximation Bayésienne, prior = beta(1,1)'\n",
    "\n",
    "pstk.plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='micro-lignedeau-ga', display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa065804-842c-4ff6-818c-dfead308b919",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(grid_approx_micro)=\n",
    "### Approximation Bayésienne par Grille\n",
    "\n",
    "Source : [solid-waste-team](https://hammerdirt-analyst.github.io/solid-waste-team/grid_approximation.html)\n",
    "\n",
    "prior : beta(1,1)\n",
    "\n",
    "Cas d'utilisation : Cette méthode est une approche manuelle de l'inférence Bayésienne. Elle est particulièrement utile lorsque vous souhaitez incorporer des croyances antérieures et mettre à jour ces croyances avec des données observées.\n",
    "\n",
    "Mise en œuvre : Implique la définition d'une grille de valeurs de paramètres et le calcul de la vraisemblance des données observées à chaque point de cette grille. En multipliant par la probabilité a priori et en normalisant, on obtient la distribution a posteriori. Cela peut être fait pour chaque condition séparément ou pour toutes les conditions ensemble, bien que cela soit plus intensif en termes de calcul.\n",
    "\n",
    "\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Toutes les conditions\n",
    "{glue}`micro-toutes-ga`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Fréquentation moyenne\n",
    "{glue}`micro-freqmoyenne-ga`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Haute fréquentation\n",
    "{glue}`micro-freqelevee-ga`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Graviers\n",
    "{glue}`micro-graviers-ga`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Sable\n",
    "{glue}`micro-sable-ga`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Plage seche et sable fins\n",
    "{glue}`micro-sechefibres-ga`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Plage seche\n",
    "{glue}`micro-seche-ga`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Ligne d'eau\n",
    "{glue}`micro-lignedeau-ga`\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{tab-item} Résultats\n",
    ":selected:\n",
    "\n",
    "````{grid} 1 2 2 2\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-micro-tous`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "\n",
    "{glue}`q-micro-lignedeau-ga`\n",
    "\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-micro-freqmoyenne`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-micro-freqelevee`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-micro-graviers`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-micro-sable`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-micro-sechefibres`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-micro-seche`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "\n",
    "```\n",
    "\n",
    "````\n",
    ":::\n",
    "\n",
    "::::    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e50a7c8a-1316-4170-88c2-d70d1f64c3ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git repo: https://github.com/hammerdirt-analyst/plastock.git\n",
      "\n",
      "Git branch: feb5\n",
      "\n",
      "pandas    : 2.0.3\n",
      "seaborn   : 0.13.1\n",
      "numpy     : 1.26.3\n",
      "matplotlib: 3.8.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions -b -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba80e4d-6655-47b7-91fd-6276e80722b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}