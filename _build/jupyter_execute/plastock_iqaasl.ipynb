{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117b743e-ebf6-411b-a322-bdb052247f93",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, time\n",
    "from babel.dates import format_date, format_datetime, format_time, get_month_names\n",
    "import locale\n",
    "import slugify\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import scipy.stats as stats\n",
    "\n",
    "# charting:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "# images and display\n",
    "from IPython.display import Markdown as md\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "header_row = {'selector': 'th:nth-child(1)', 'props': f'background-color: #FFF;'}\n",
    "even_rows = {\"selector\": 'tr:nth-child(even)', 'props': f'background-color: rgba(139, 69, 19, 0.08);'}\n",
    "odd_rows = {'selector': 'tr:nth-child(odd)', 'props': 'background: #FFF;'}\n",
    "table_font = {'selector': 'tr', 'props': 'font-size: 12px;'}\n",
    "table_css_styles = [even_rows, odd_rows, table_font, header_row]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e62e42-fd31-42c6-8a1d-97ef1ad4adde",
   "metadata": {},
   "source": [
    "# Plastock - Iqaasl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7f497-9eee-4ba0-b006-fd6119704b1b",
   "metadata": {},
   "source": [
    "### Comparaison de la taille des lieux d'échantillonnage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47889a93-19f6-45fd-bf9f-7de954e82224",
   "metadata": {},
   "source": [
    "### Mètres carrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2039971-e326-4e55-bac2-b5b2d2571442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plage</th>\n",
       "      <th>echantillon</th>\n",
       "      <th>orientation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>position</th>\n",
       "      <th>substrat</th>\n",
       "      <th>area</th>\n",
       "      <th>time</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>74_Amp_1</td>\n",
       "      <td>NE</td>\n",
       "      <td>46.398117</td>\n",
       "      <td>6.534083</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>74_Amp_10</td>\n",
       "      <td>NNE</td>\n",
       "      <td>46.397900</td>\n",
       "      <td>6.534450</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>74_Amp_2</td>\n",
       "      <td>NNE</td>\n",
       "      <td>46.398017</td>\n",
       "      <td>6.534250</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>74_Amp_3</td>\n",
       "      <td>NE</td>\n",
       "      <td>46.398000</td>\n",
       "      <td>6.534350</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>74_Amp_4</td>\n",
       "      <td>NNE</td>\n",
       "      <td>46.397917</td>\n",
       "      <td>6.534583</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Bouveret</td>\n",
       "      <td>VS_Bou_5</td>\n",
       "      <td>O</td>\n",
       "      <td>46.389317</td>\n",
       "      <td>6.859867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Bouveret</td>\n",
       "      <td>VS_Bou_6</td>\n",
       "      <td>OSO</td>\n",
       "      <td>46.389400</td>\n",
       "      <td>6.859867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Bouveret</td>\n",
       "      <td>VS_Bou_7</td>\n",
       "      <td>OSO</td>\n",
       "      <td>46.389517</td>\n",
       "      <td>6.859817</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Bouveret</td>\n",
       "      <td>VS_Bou_8</td>\n",
       "      <td>ONO</td>\n",
       "      <td>46.389017</td>\n",
       "      <td>6.859833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "      <td>220</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Bouveret</td>\n",
       "      <td>VS_Bou_9</td>\n",
       "      <td>ONO</td>\n",
       "      <td>46.389100</td>\n",
       "      <td>6.859883</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "      <td>220</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Plage echantillon orientation   latitude  longitude  position   \n",
       "0     Amphion    74_Amp_1          NE  46.398117   6.534083         1  \\\n",
       "1     Amphion   74_Amp_10         NNE  46.397900   6.534450         2   \n",
       "2     Amphion    74_Amp_2         NNE  46.398017   6.534250         1   \n",
       "3     Amphion    74_Amp_3          NE  46.398000   6.534350         1   \n",
       "4     Amphion    74_Amp_4         NNE  46.397917   6.534583         1   \n",
       "..        ...         ...         ...        ...        ...       ...   \n",
       "230  Bouveret    VS_Bou_5           O  46.389317   6.859867         1   \n",
       "231  Bouveret    VS_Bou_6         OSO  46.389400   6.859867         1   \n",
       "232  Bouveret    VS_Bou_7         OSO  46.389517   6.859817         1   \n",
       "233  Bouveret    VS_Bou_8         ONO  46.389017   6.859833         2   \n",
       "234  Bouveret    VS_Bou_9         ONO  46.389100   6.859883         2   \n",
       "\n",
       "     substrat  area  time  length  \n",
       "0           4    98    50      91  \n",
       "1           4    98    50      91  \n",
       "2           4    98    50      91  \n",
       "3           4    98    50      91  \n",
       "4           4    98    50      91  \n",
       "..        ...   ...   ...     ...  \n",
       "230         1    99    50     116  \n",
       "231         1    99    50     116  \n",
       "232         1    99    50     116  \n",
       "233         1   438   220     116  \n",
       "234         1   438   220     116  \n",
       "\n",
       "[235 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(\"data/macro_current.csv\")\n",
    "beach_data = pd.read_csv(\"data/pstock_beaches_current.csv\")\n",
    "beach_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d3c1f2-9235-416b-adde-925b84d581a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plage</th>\n",
       "      <th>position</th>\n",
       "      <th>substrat</th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>quantity</th>\n",
       "      <th>area</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>01.02.2022</td>\n",
       "      <td>G24</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>01.02.2022</td>\n",
       "      <td>G24</td>\n",
       "      <td>42</td>\n",
       "      <td>342</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>03.05.2022</td>\n",
       "      <td>G24</td>\n",
       "      <td>5</td>\n",
       "      <td>342</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.07.2022</td>\n",
       "      <td>G24</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amphion</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.07.2022</td>\n",
       "      <td>G24</td>\n",
       "      <td>11</td>\n",
       "      <td>342</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>Aubonne</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.09.2022</td>\n",
       "      <td>G165</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>Aubonne</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.09.2022</td>\n",
       "      <td>G165</td>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>Baby Plage</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.04.2022</td>\n",
       "      <td>G165</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>Baby Plage</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.10.2022</td>\n",
       "      <td>G165</td>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>Tougues</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.01.2022</td>\n",
       "      <td>G165</td>\n",
       "      <td>2</td>\n",
       "      <td>450</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Plage  position  substrat        date  code  quantity  area  length\n",
       "0        Amphion         1       4.0  01.02.2022   G24         2    98      91\n",
       "1        Amphion         2       4.0  01.02.2022   G24        42   342      91\n",
       "2        Amphion         2       4.0  03.05.2022   G24         5   342      91\n",
       "3        Amphion         1       4.0  19.07.2022   G24         5    98      91\n",
       "4        Amphion         2       4.0  19.07.2022   G24        11   342      91\n",
       "...          ...       ...       ...         ...   ...       ...   ...     ...\n",
       "2285     Aubonne         1       4.0  10.09.2022  G165         1    72      50\n",
       "2286     Aubonne         2       4.0  10.09.2022  G165         4   268      50\n",
       "2287  Baby Plage         1       1.0  23.04.2022  G165         1   112      81\n",
       "2288  Baby Plage         2       1.0  15.10.2022  G165         1   384      81\n",
       "2289     Tougues         2       2.0  29.01.2022  G165         2   450     114\n",
       "\n",
       "[2290 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column_names = {\n",
    "    \"Position\":\"position\",\n",
    "    \"Substrat\":\"substrat\",\n",
    "    \"Date\":\"date\",\n",
    "    \"Code\":\"code\",\n",
    "    \"Quantité\":\"quantity\",\n",
    "    \"Aire\":\"area\"\n",
    "}\n",
    "\n",
    "length_key = beach_data[[\"Plage\",\"length\"]].drop_duplicates(\"Plage\").set_index(\"Plage\")\n",
    "work_data = new_data[[\"Plage\", *new_column_names.keys()]].copy()\n",
    "work_data.rename(columns=new_column_names, inplace=True)\n",
    "work_data[\"length\"] = work_data.Plage.apply(lambda x: length_key.loc[x, \"length\"])\n",
    "work_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c8c1b-2129-4579-98f6-49713c56ec1d",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plastock data\n",
    "plastock = pd.read_csv(\"data/20230314macro.csv\", sep=\";\", encoding=\"ISO-8859-3\")\n",
    "p_beaches = pd.read_csv(\"data/asl_beaches2.csv\")\n",
    "# iqaasl data\n",
    "iq_dims = pd.read_csv(\"data/corrected_dims.csv\")\n",
    "iqaasl = pd.read_csv(\"data/lac_leman_iqaasl.csv\")\n",
    "\n",
    "# plastock survey data of interest\n",
    "pstck_cols = ['Lieu', 'Aire','Position', 'Date', 'Code', 'Quantité']\n",
    "pstck_rename = {\"Lieu\":\"location\", \"Aire\":\"area\", \"Date\":\"date\", \"Code\":\"code\", \"Quantité\":\"quantity\", \"Position\":\"position\"}\n",
    "pstck =  plastock[pstck_cols]\n",
    "pstck = pstck.rename(columns=pstck_rename)\n",
    "\n",
    "# the surveys were separated into two zones for plastock\n",
    "# we want to compare the total of the surveys, so the zones at each\n",
    "# location and survey need to be combined\n",
    "pstck_q = pstck.groupby([\"location\", \"date\", \"code\"], as_index=False).quantity.sum()\n",
    "\n",
    "# the length of the survey is not included in the plastock survey data\n",
    "# it needs to be attached to the survey reults, this information is available\n",
    "# in the beaches file\n",
    "pbl = p_beaches[[\"location\", \"length\"]].drop_duplicates([\"location\", \"length\"]).set_index(\"location\")\n",
    "\n",
    "# the dimensional data was taken once per survey\n",
    "# remove the duplicate values by date and location\n",
    "pstck_ndup = pstck.drop_duplicates([\"location\", \"date\",\"area\"])\n",
    "# combine the areas by date and location\n",
    "pstck_ta = pstck_ndup.groupby([\"location\", \"date\"]).area.sum()\n",
    "pstck = pstck_q.merge(pstck_ta, on=[\"location\", \"date\"])\n",
    "\n",
    "# the location names in asl_beaches does not match the names in 20230314macro.csv\n",
    "# the names in the asl_beaches file were changed previously\n",
    "# they need to be changed back to match the new survey data\n",
    "p_names = sorted(p_beaches.location.unique())\n",
    "pstock_names = sorted(plastock.Lieu.unique())\n",
    "\n",
    "# the differences are capitalizations and hyphenations\n",
    "renames = {x: p_names[i] for i, x in enumerate(pstock_names)}\n",
    "pstck[\"location\"] = pstck.location.apply(lambda x: renames[x])\n",
    "\n",
    "# add the length\n",
    "pstck[\"length\"] = pstck.location.apply(lambda x: pbl.loc[x].length)\n",
    "pstck[\"project\"] = \"plastock\"\n",
    "pstck[\"date\"] = pd.to_datetime(pstck[\"date\"], format=\"%d.%m.%Y\")\n",
    "\n",
    "pstck[\"doy\"] = pstck[\"date\"].dt.dayofyear\n",
    "pstck[\"date\"] = pstck[\"date\"].dt.date\n",
    "\n",
    "# the columns of interest\n",
    "survey_columns = [\n",
    "    \"location\",\n",
    "    \"date\",\n",
    "    \"code\",\n",
    "    \"length\",\n",
    "    \"area\",\n",
    "    \"quantity\",\n",
    "    \"project\",\n",
    "    \"doy\"\n",
    "]\n",
    "\n",
    "pstck = pstck[survey_columns]\n",
    "# there are aggregations that need to be made to the plastock data. The fragemented foams\n",
    "# and fragmented plastics are consolidated into one group of codes. The plastic caps are consolidated\n",
    "# as per the intend of the ASL and the recomendation from the IQAASL report.    \n",
    "gfoam = [\"G81\", \"G82\", \"G83\"]\n",
    "plasticpcs = [ \"G78\", \"G79\", \"G80\", \"G75\", \"G76\", \"G77\"]\n",
    "Gcaps = [ \"G21\", \"G23\", \"G24\" ]\n",
    "\n",
    "# the columns that are being kept and the operations per column          \n",
    "columns = ['location', 'date',  'area', 'length','project', \"doy\"]\n",
    "operations = {\"quantity\":\"sum\"}\n",
    "\n",
    "# separate the codes of interest by group from the data frame and add the replacement value\n",
    "pstck_gfrags = pstck[pstck.code.isin(plasticpcs)].groupby(columns, as_index=False).agg(operations)\n",
    "pstck_gfoam = pstck[pstck.code.isin(gfoam)].groupby(columns, as_index=False).agg(operations)\n",
    "pstck_gcaps = pstck[pstck.code.isin(Gcaps)].groupby(columns, as_index=False).agg(operations)\n",
    "\n",
    "pstck_gcaps[\"code\"] = \"Gcaps\"\n",
    "pstck_gfoam[\"code\"] = \"Gfoam\"\n",
    "pstck_gfrags[\"code\"] = \"Gfrags\"\n",
    "\n",
    "# remove the same instances from the work data                                                               \n",
    "pstck_no_frags = pstck[~pstck.code.isin([*plasticpcs, *gfoam, *Gcaps])].copy()\n",
    "\n",
    "# formatted plastock data\n",
    "pstck = pd.concat([pstck_no_frags, pstck_gfrags, pstck_gfoam, pstck_gcaps])\n",
    "\n",
    "# zero is not accounted for in the plastock data\n",
    "# this is essential for computing the median and average\n",
    "# values. The fail rate can not be calculated with out it\n",
    "# 1. collect all the codes that were identified in plastock\n",
    "codes = pstck.code.unique()\n",
    "\n",
    "# 2 make a dataframe of all possible codes and give them a\n",
    "# quantity of zero\n",
    "code_zero = pd.DataFrame({\"code\":codes})\n",
    "code_zero[\"quantity\"] = 0\n",
    "\n",
    "# 3. collect all the unique date and location pairs\n",
    "dates = pstck[['date', 'location']].drop_duplicates()\n",
    "\n",
    "def add_zeroes(data, dates, code_zero):\n",
    "    \n",
    "    some_zeroes = []\n",
    "    for apair in dates.values:\n",
    "        # collect the results from one survey\n",
    "        d = data[(data.location == apair[1])&(data[\"date\"] == apair[0])]\n",
    "        # collect the codes that were identified in the current survey\n",
    "        codes_with_vals = d.code.unique()\n",
    "        # identify the codes that were not identified\n",
    "        codes_with_no_vals = [x for x in code_zero.code.unique() if x not in codes_with_vals]\n",
    "        # collect the area and length for the current survey\n",
    "        area_length = d[[\"area\", \"length\"]].drop_duplicates([\"area\", \"length\"]).reset_index()\n",
    "        # add the area, length, location, date and project to\n",
    "        # to the dataframe of codes and zeroes\n",
    "        code_zero[\"area\"] = area_length.loc[0, \"area\"]\n",
    "        code_zero[\"length\"] = area_length.loc[0, \"length\"]\n",
    "        code_zero[\"date\"] = apair[0]\n",
    "        code_zero[\"location\"] = apair[1]\n",
    "        code_zero[\"project\"] = \"plastock\"\n",
    "        # keep only the codes that were not indentified in the survey\n",
    "        test_no_vals = code_zero[code_zero.code.isin(codes_with_no_vals)]\n",
    "        # add the resulting df to the list\n",
    "        some_zeroes.append(test_no_vals)\n",
    "    return some_zeroes\n",
    "\n",
    "# collect the zero values\n",
    "zeroes =  add_zeroes(pstck, dates, code_zero)\n",
    "# add them to the existing survey results\n",
    "pstk = pd.concat([pstck, *zeroes], axis=0)\n",
    "\n",
    "# IQAASL data\n",
    "# only locations on lac leman\n",
    "iq_locations = iqaasl.location.unique()\n",
    "iq_d = iq_dims[iq_dims.location.isin(iq_locations)]\n",
    "\n",
    "# there are three surveys that do not have length or area data:\n",
    "# two at quai-maria-belgia and one at baby-plage-geneva\n",
    "# the average value of the preceeding surveys will be used\n",
    "qmb = iq_d[(iq_d.location == \"quai-maria-belgia\") & (iq_d.area > 0)].agg({\"length\":\"mean\", \"area\":\"mean\"})\n",
    "bp = iq_d[(iq_d.location == \"baby-plage-geneva\") & (iq_d.area > 0)].agg({\"length\":\"mean\", \"area\":\"mean\"})\n",
    "\n",
    "# separate the surveys with no dimensional data\n",
    "qmb_0 = iq_d[(iq_d.location == \"quai-maria-belgia\") & (iq_d.area == 0)]\n",
    "bp_0 = iq_d[(iq_d.location == \"baby-plage-geneva\") & (iq_d.area == 0)]\n",
    "\n",
    "# add the derived values\n",
    "qmb_0.loc[:, \"area\"] = qmb.area\n",
    "qmb_0.loc[:, \"length\"] = qmb.length\n",
    "bp_0.loc[:, \"area\"] = bp.area\n",
    "bp_0.loc[:, \"length\"] = bp.length\n",
    "\n",
    "# merge the corrections with the original data\n",
    "# minus the records with no diemensional data\n",
    "iqd = iq_d[(iq_d.area > 0)]\n",
    "iqd = pd.concat([iqd, qmb_0, bp_0], axis=0)\n",
    "iqd_la = iqd[[\"loc_date\", \"area\"]].set_index(\"loc_date\")\n",
    "\n",
    "iqaasl[\"project\"] = \"iqaasl\"\n",
    "iqaasl[\"area\"] = iqaasl.loc_date.apply(lambda x: iqd_la.loc[x].area)\n",
    "iqa = iqaasl.copy()\n",
    "iqa[\"date\"] = pd.to_datetime(iqa[\"date\"])\n",
    "iqa[\"doy\"] = iqa[\"date\"].dt.dayofyear\n",
    "iqa[\"date\"] = iqa[\"date\"].dt.date\n",
    "iqa = iqa[survey_columns].copy()\n",
    "iqa = iqa[iqa.code.isin(codes)]\n",
    "\n",
    "# make gcaps, gfrags and foams are ready made\n",
    "iqaasl_not_caps = iqa[~iqa.code.isin(Gcaps)].copy()\n",
    "iqaasl_caps = iqa[iqa.code.isin(Gcaps)].groupby(columns, as_index=False).quantity.sum()\n",
    "iqaasl_caps[\"code\"] = \"Gcaps\"\n",
    "\n",
    "# formatted iqaasl data\n",
    "iqa = pd.concat([iqaasl_caps, iqaasl_not_caps])\n",
    "combined = pd.concat([iqa,pstk], axis=0).reset_index(drop=True)\n",
    "combined[\"loc_date\"] = list(zip(combined.location, combined[\"date\"]))\n",
    "combined[\"pcs/m\"] = combined[\"quantity\"]/combined[\"length\"]\n",
    "combined[\"pcs/m²\"] = combined[\"quantity\"]/combined[\"area\"]\n",
    "\n",
    "combined_dt = combined.groupby([\"loc_date\", \"location\", \"date\", \"doy\", \"project\", \"area\", \"length\"], as_index=False).agg({\"pcs/m\":\"sum\", \"pcs/m²\":\"sum\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234071fd-3f0a-4886-b974-e8b9a38431a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "table_one = combined_dt.groupby(\"project\")[\"area\"].describe()\n",
    "table_one.index.name = None\n",
    "table_one.style.format(precision=2).set_table_styles(table_css_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755aac40-4b8b-43a3-9a5c-d19c9fac1f92",
   "metadata": {},
   "source": [
    "### Mètres linéaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb162701-f198-443f-8c3c-50e14e5a50e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "table_two = combined_dt.groupby(\"project\")[\"length\"].describe()\n",
    "table_two.index.name = None\n",
    "table_two.style.format(precision=2).set_table_styles(table_css_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a49256-0775-4d34-8605-be15ed1e90d2",
   "metadata": {},
   "source": [
    "## Comparaison des résultats:\n",
    "\n",
    "Comparaison des résultats des deux projets : distribution des résultats de l'échantillon en pièces par mètre et en pièces par mètre au carré.\n",
    "\n",
    "Seuls les objets identifiés dans PLASTOCK ont été pris en compte\n",
    "\n",
    "\n",
    "### Pièces par mètre carré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e76b0bb-e193-462d-a89b-29768f90565f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "table_three = combined_dt.groupby(\"project\")[\"pcs/m²\"].describe()\n",
    "table_three.index.name = None\n",
    "table_three.style.format(precision=2).set_table_styles(table_css_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa86b76-fe7d-453d-911c-5c7203ccfd02",
   "metadata": {},
   "source": [
    "### Pièces par mètre linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ba983-b6ad-4fc0-ba5a-7eea424e96f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "table_four = combined_dt.groupby(\"project\")[\"pcs/m\"].describe()\n",
    "table_four.index.name = None\n",
    "table_four.style.format(precision=2).set_table_styles(table_css_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3fddb-afc7-46a2-8aad-52844fcceb0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(8, 7))\n",
    "palette= {\"iqaasl\":\"dodgerblue\", \"plastock\":\"magenta\"}\n",
    "\n",
    "sns.scatterplot(data=combined_dt, x=\"doy\", y=\"pcs/m\", ax=ax[0,0], hue=\"project\", palette=palette)\n",
    "sns.scatterplot(data=combined_dt, x=\"doy\", y=\"pcs/m²\", ax=ax[0,1], hue=\"project\", palette=palette)\n",
    "sns.boxplot(data=combined_dt, x='project', y=\"pcs/m\", ax=ax[1,0], hue=\"project\", palette=palette, showfliers=False, dodge=False)\n",
    "sns.boxplot(data=combined_dt, x='project', y=\"pcs/m²\", ax=ax[1,1], hue=\"project\", palette=palette, showfliers=False, dodge=False)\n",
    "\n",
    "ax[0,0].set_title(\"Mètre linéaire\", fontsize=12, loc=\"left\")\n",
    "ax[0,1].set_title(\"Mètre carré\", fontsize=12, loc=\"left\")\n",
    "ax[0,0].set_xlabel(\"Jour de l'année\", fontsize=12)\n",
    "ax[0,1].set_xlabel(\"Jour de l'année\", fontsize=12)\n",
    "ax[1,0].set_xlabel(\"\")\n",
    "ax[1,1].set_xlabel(\"\")\n",
    "for anax in [ax[0,0], ax[1,0], ax[1,1]]:\n",
    "    anax.get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd251c-baa1-4667-a102-58c87aa17478",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 7), sharex=False, sharey=False)\n",
    "\n",
    "ax[0,0] = sns.ecdfplot(data=combined_dt, x=\"pcs/m\", hue=\"project\", palette=palette, ax=ax[0,0])\n",
    "ax[1,0] = sns.histplot(data=combined_dt, x=\"pcs/m\", hue=\"project\", palette=palette, stat=\"probability\", multiple=\"stack\", ax=ax[1,0])\n",
    "ax[0,1] = sns.ecdfplot(data=combined_dt, x=\"pcs/m²\", hue=\"project\", palette=palette, ax=ax[0,1])\n",
    "ax[1,1] = sns.histplot(data=combined_dt, x=\"pcs/m²\", hue=\"project\", palette=palette, stat=\"probability\", multiple=\"stack\", ax=ax[1,1])\n",
    "\n",
    "ax[0,0].set_title(\"fonction de répartition, pcs/m\", loc=\"left\")\n",
    "ax[1,0].set_title(\"histogramme, pcs/m\", loc=\"left\")\n",
    "\n",
    "ax[0,1].set_title(\"fonction de répartition, pcs/m²\", loc=\"left\")\n",
    "ax[1,1].set_title(\"histogramme, pcs/m²\", loc=\"left\")\n",
    "\n",
    "ax[1,0].get_legend().remove()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f0e7b-aa33-4e65-8f9a-ef37f26bc1b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "mask = (combined_dt.doy >=  0) & (combined_dt.doy <= 50)\n",
    "q1 = combined_dt[mask]\n",
    "\n",
    "mask_notin_pstock = (combined_dt.doy >50) & (combined_dt.doy < 100)\n",
    "not_inpstck = combined_dt[mask_notin_pstock]\n",
    "\n",
    "mask2 = (combined_dt.doy >= 100) & (combined_dt.doy <= 150)\n",
    "q2 = combined_dt[mask2]\n",
    "\n",
    "mask3 = (combined_dt.doy >= 183) & (combined_dt.doy <= 257)\n",
    "q3 = combined_dt[mask3]\n",
    "\n",
    "mask4 = (combined_dt.doy > 257) & (combined_dt.doy <= 351)\n",
    "q4 = combined_dt[mask3]\n",
    "\n",
    "merged_qs = pd.concat([q1, q2, q3, q4, not_inpstck], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(8, 7), sharex=True)\n",
    "palette= {\"iqaasl\":\"dodgerblue\", \"plastock\":\"magenta\"}\n",
    "\n",
    "sns.boxplot(data=q1, x=\"project\", y=\"pcs/m\", ax=ax[0,0], hue=\"project\", palette=palette, showfliers=False, dodge=False)\n",
    "sns.boxplot(data=q2, x=\"project\", y=\"pcs/m\", ax=ax[0,1], hue=\"project\", palette=palette, showfliers=False, dodge=False)\n",
    "sns.boxplot(data=q3, x='project', y=\"pcs/m\", ax=ax[1,0], hue=\"project\", palette=palette, showfliers=False, dodge=False)\n",
    "sns.boxplot(data=q4, x='project', y=\"pcs/m\", ax=ax[1,1], hue=\"project\", palette=palette, showfliers=False, dodge=False)\n",
    "\n",
    "ax[0,0].set_title(\"Jours 0 - 50\", fontsize=12, loc=\"left\")\n",
    "ax[0,1].set_title(\"Jours 100 - 150\", fontsize=12, loc=\"left\")\n",
    "ax[1,0].set_title(\"Jours 183 - 257\", fontsize=12, loc=\"left\")\n",
    "ax[1,1].set_title(\"Jours 258 - 351\", fontsize=12, loc=\"left\")\n",
    "for anax in [ax[0,1], ax[1,0], ax[1,1], ax[0,0]]:\n",
    "    anax.get_legend().remove()\n",
    "    anax.set_xlabel(\"\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd4bdd-c12b-4f36-b979-b8b2647f2e9e",
   "metadata": {},
   "source": [
    "### Jours d'échantillonnage par période de 12 mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0a105-bf29-4ab5-b8bc-a6d99ad3cef5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "cov_pstock = combined_dt[combined_dt.project == \"plastock\"].date.nunique()\n",
    "cov_iqaasl = combined_dt[combined_dt.project == \"iqaasl\"].date.nunique()\n",
    "\n",
    "print(f'Plastock = {round(cov_pstock/365, 2)}, iqaasl =  {round(cov_iqaasl/365, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88467e15-934e-48cc-8b9f-0472f8253117",
   "metadata": {},
   "source": [
    "### Difference entre les deux distributions d'échantillonnage: pcs/m\n",
    "\n",
    "Les deux distributions sont des mesures de la densité minimale probable de déchets pour chaque mètre de littoral. \n",
    "\n",
    "Notre intérêt est de comprendre dans quelle mesure les observations de PLASTOCK étaient probables compte tenu des résultats d'IQAASSL et vice versa. Le JRC, dans [Eu threshold for macro litter on coastlines](https://mcc.jrc.ec.europa.eu/main/dev.py?N=41&O=454), a suggéré d'utiliser une distribution binomiale négative pour modéliser les résultats des échantillons. Cette méthode a été illustrée dans le chapitre ([Beach litter baselines](https://hammerdirt-analyst.github.io/IQAASL-End-0f-Sampling-2021/baselines.html)) du rapport fédérale.\n",
    "\n",
    "The difference between the two sampling periods is the shaded area between the probability mass functions of the two negative binomial distributions defined by the mean and variance from the respective sampling periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80657825-ab41-42d6-b680-e6057a3528cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import nbinom\n",
    "from statsmodels.distributions.empirical_distribution import ECDF as ecdf\n",
    "\n",
    "e_pstock = combined_dt[combined_dt.project == \"plastock\"]\n",
    "x_p = e_pstock[\"pcs/m\"].sort_values()\n",
    "ecdf_pstock = ecdf(x_p)\n",
    "\n",
    "e_iqaasl = combined_dt[combined_dt.project == \"iqaasl\"]\n",
    "x_i = e_iqaasl[\"pcs/m\"].sort_values()\n",
    "ecdf_iqaasl = ecdf(x_i)\n",
    "\n",
    "def make_n(mean, variance):\n",
    "    return mean**2/(variance-mean)\n",
    "def make_p(mean, variance):\n",
    "    return mean/variance\n",
    "\n",
    "n_i = make_n(np.mean(x_i), np.var(x_i))\n",
    "p_i = make_p(np.mean(x_i), np.var(x_i))\n",
    "\n",
    "n_p = make_n(np.mean(x_p), np.var(x_p))\n",
    "p_p = make_p(np.mean(x_p), np.var(x_p))\n",
    "\n",
    "x_ii = np.arange(0, x_i.max())\n",
    "x_pi = np.arange(0,  x_i.max())\n",
    "\n",
    "i_nb = nbinom(n_i, p_i)\n",
    "p_nb = nbinom(n_p, p_p)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(x_ii, i_nb.pmf(x_ii), label='iqaasl', c='dodgerblue')\n",
    "ax[0].plot(x_pi, p_nb.pmf(x_pi), label='plastock', c='magenta')\n",
    "ax[0].fill_between(x_pi,p_nb.pmf(x_pi), i_nb.pmf(x_ii), alpha=0.2, color=\"black\", label=\"difference\")\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Probability mass function\", loc=\"left\")\n",
    "ax[1].fill_between(x_pi,p_nb.cdf(x_pi), i_nb.cdf(x_pi), alpha=0.2, color=\"black\", label=\"difference\")\n",
    "ax[1].plot(x_i, i_nb.cdf(x_i), color=\"dodgerblue\", linewidth=2)\n",
    "ax[1].plot(x_p, p_nb.cdf(x_p), color=\"magenta\", linewidth=2)\n",
    "ax[1].set_title(\"Cumulative distribution\", loc=\"left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00fcaa6-f8be-4c62-ada1-c2aed18ab428",
   "metadata": {},
   "source": [
    "### Quantifying the difference\n",
    "\n",
    "To quantify the difference between the two sampling periods we will consider the following:\n",
    "\n",
    "1. The probability that samples from one period could have been drawn from the other\n",
    "2. Comparing the 90% confidence interval of the two distributions\n",
    "3. Visully comparing the results in a box-plot\n",
    "\n",
    "#### The confidence intervals and boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05270ec6-3c1f-4984-871f-9afd48ebdc29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "i_nbci = i_nb.interval(.9)\n",
    "p_nbci = p_nb.interval(.9)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(9,6))\n",
    "ax[0].plot(x_ii, i_nb.pmf(x_ii), label='iqaasl', c='dodgerblue')\n",
    "ax[0].plot(x_pi, p_nb.pmf(x_pi), label='plastock', c='magenta')\n",
    "ax[0].axvspan(xmin=i_nbci[0], xmax=i_nbci[1], color=\"dodgerblue\", alpha=0.2, label=\"iqaasl 90% interval\")\n",
    "ax[0].axvspan(xmin=p_nbci[0], xmax=p_nbci[1], color=\"magenta\", alpha=0.2, label=\"plastock 90% interval\")\n",
    "# ax[0].fill_between(x_pi,p_nb.pmf(x_pi), i_nb.pmf(x_ii), alpha=0.2, color=\"black\", label=\"difference\")\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Probability mass function\", loc=\"left\")\n",
    "\n",
    "sns.boxplot(data=combined_dt[combined_dt.project == \"iqaasl\"], y=\"pcs/m\", x=\"project\", ax=ax[1], hue=\"project\", palette=palette, showfliers=False, dodge=False)\n",
    "sns.stripplot(data=combined_dt[combined_dt.project == \"plastock\"],  x=\"project\", y=\"pcs/m\", ax=ax[1], color=\"magenta\", size=6, dodge=True, label=\"plastock\")\n",
    "ax[1].set_xlabel(\"\")\n",
    "sns.boxplot(data=combined_dt[combined_dt.project == \"plastock\"], y=\"pcs/m\", x=\"project\", ax=ax[2], hue=\"project\", palette=palette, showfliers=True, dodge=False)\n",
    "sns.stripplot(data=combined_dt[combined_dt.project == \"iqaasl\"],  x=\"project\", y=\"pcs/m\", ax=ax[2], color=\"dodgerblue\", size=6, dodge=True, label=\"iqaasl\")\n",
    "ax[2].set_xlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba494bb0-7e22-46ff-aa5d-ea659e990372",
   "metadata": {},
   "source": [
    "__Interpretation:__\n",
    "\n",
    "1. The 90% interval from the plastock samples fall within the 90% interval of IQAASL\n",
    "2. 99% of all samples from plastock fall within the 90% interval of iqaasl\n",
    "3. 80% of all samples from iqaasl fall within the 90% interval of plastock\n",
    "\n",
    "__Remarks:__ The standard deviation of iqaasl is $\\approx$ 3 times that of plastock. There are more sampling days in iqaasl v/s plastock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e3399-4e25-4bd4-a432-60691cdab5cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pnames = combined[combined.project == \"plastock\"].copy()\n",
    "iqnames = combined[combined.project == \"iqaasl\"].copy()\n",
    "\n",
    "\n",
    "\n",
    "pnames[\"city\"] = pnames.location\n",
    "\n",
    "city_names = {\n",
    "    \"Grangettes\":\"Villeneuve\",\n",
    "    \"Port Choilseul\": \"Versoix\",\n",
    "    \"Pichette\": \"Vevey\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def change_names(x, names=city_names.keys(), city_names=city_names):\n",
    "    \n",
    "    if x in names:\n",
    "        x = city_names[x]\n",
    "    \n",
    "    return x\n",
    "\n",
    "pnames[\"city\"] = pnames.location.apply(lambda x: change_names(x))\n",
    "\n",
    "\n",
    "iqcities = iqaasl[['location', 'city']].drop_duplicates(['location', 'city']).set_index('location')\n",
    "iqnames[\"city\"] = iqnames.location.apply(lambda x: iqcities[\"city\"].loc[x])\n",
    "\n",
    "\n",
    "city_combined = pd.concat([iqnames, pnames])\n",
    "pnames_s = p_beaches.location.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae6795-cd18-46e5-b8ca-1586eb95c0e5",
   "metadata": {},
   "source": [
    "### Fail rate : taux d'écheque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd5eb8-841d-485f-9f71-c0f99f2c0fbf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# fail rate\n",
    "def n_fails(data, code, threshhold=0):\n",
    "    \n",
    "    return ((data.code == code) & (data.quantity > threshhold)).sum()    \n",
    "\n",
    "def fail_rate(data, code, threshhold=0, project=\"iqaasl\"):\n",
    "    d = data[data.project == project]\n",
    "    fails = n_fails(d, code, threshhold=threshhold)\n",
    "    tries = d.loc_date.nunique()\n",
    "    \n",
    "    return fails/tries\n",
    "\n",
    "def make_fail_rate_df(data, codes, project=\"iqaasl\", threshold=0):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for code in codes:\n",
    "        results.append({\"code\":code, \"project\":project, \"fail rate\":fail_rate(data, code, project=project)})\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "iqa_fail_rate = make_fail_rate_df(combined, codes)\n",
    "pstk_fail_rate = make_fail_rate_df(combined, codes, project='plastock')\n",
    "\n",
    "fail_rates = pd.concat([iqa_fail_rate, pstk_fail_rate], axis=0)\n",
    "\n",
    "fail_rates = fail_rates.pivot(index=\"code\", columns=\"project\")\n",
    "fail_rates.sort_values(by=(\"fail rate\",\"iqaasl\"), ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4566d7a-be31-48e5-bb09-2c85529b511b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}