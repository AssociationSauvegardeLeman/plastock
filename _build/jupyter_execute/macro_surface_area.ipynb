{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32bcdb7d-96d5-47f5-a77a-139bafcc6a7d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from myst_nb import glue\n",
    "from slugify import slugify\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "from plastockconf import name_zones, name_frequentation, name_situation\n",
    "from plastockconf import name_substrate, name_distance, table_css_styles, table_css_styles_top\n",
    "\n",
    "from plastock import add_table_to_page, capitalize_x_tick_labels, capitalize_x_and_y_axis_labels, capitalize_legend_components, attribute_summary\n",
    "\n",
    "import reportclass as rc\n",
    "import setvariables as conf_\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "def translate_describe(x, value_column):\n",
    "    described = x.to_dict()\n",
    "    described.pop(\"count\")\n",
    "    described[\"moyenne\"] = described.pop(\"mean\")\n",
    "    described[\"écart-type\"] = described.pop(\"std\")\n",
    "    df = pd.DataFrame(described.items())\n",
    "    df.set_index(0, inplace=True)\n",
    "    df.rename(columns={1:value_column}, inplace=True)\n",
    "    df.index.name = None\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "format_kwargs = dict(precision=2, thousands=\"'\", decimal=\",\")\n",
    "def make_exportable(data, file_name, cmap='YlOrBr'):\n",
    "    data.fillna(0, inplace=True)\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    sns.heatmap(data=data, vmin=0, vmax=1, cmap=cmap, annot=True, fmt='.2', annot_kws={'size':10}, ax=ax, cbar=False)\n",
    "    plt.tight_layout()\n",
    "    ax.tick_params(which='both', axis='both', bottom=False, left=False)\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "glue('blank_caption', \" \", display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4bb245-4398-4ed2-89a8-7ad4748578d5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"data/end_pipe/macro_current.csv\")\n",
    "beach_data = pd.read_csv(\"data/pstock_beaches_current.csv\")\n",
    "codes = pd.read_csv('data/end_pipe/codes.csv').set_index('code')\n",
    "language_maps = rc.language_maps()\n",
    "\n",
    "new_column_names = {\n",
    "    \"Position\":\"position\",\n",
    "    \"Substrat\":\"substrat\",\n",
    "    \"Date\":\"date\",\n",
    "    \"Code\":\"code\",\n",
    "    \"Quantité\":\"quantité\",\n",
    "    \"Aire\":\"area\"\n",
    "}\n",
    "\n",
    "# import data and assign new column names and sample_id\n",
    "# the sample_id is the tuple (location, date). Each row\n",
    "# is a unique combinantion of sample_id and code\n",
    "work_data = new_data[[\"Plage\", *new_column_names.keys()]].copy()\n",
    "work_data.rename(columns=new_column_names, inplace=True)\n",
    "work_data[\"slug\"] = work_data.Plage.apply(lambda x: slugify(x))\n",
    "work_data[\"échantillon\"] = list(zip(work_data.slug, work_data['date']))\n",
    "work_data['date'] = pd.to_datetime(work_data[\"date\"], format=\"mixed\", dayfirst=True)\n",
    "work_data.dropna(inplace=True)\n",
    "\n",
    "# type the columns\n",
    "work_data[[\"position\", \"substrat\"]] = work_data[[\"position\", \"substrat\"]].astype(\"int\")\n",
    "work_data['échantillon'] = work_data['échantillon'].astype(str)\n",
    "\n",
    "# ! combine the surface areas of the position vectors !\n",
    "# locate all the duplicate values by sample id and area\n",
    "# this gives a data frame that has the position and area for\n",
    "# each sample_id\n",
    "total_area_dup = work_data.drop_duplicates(['échantillon', 'area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0016edfd-855c-484f-bae7-76fabdb2ff72",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# sum of the areas for each position at each sample\n",
    "# use the sample_id as index and sum the areas for each postition at each sample\n",
    "total_area = total_area_dup.groupby('échantillon').area.sum()\n",
    "\n",
    "# apply the total area to the work_data, index on sample_id\n",
    "work_data['area_c'] = work_data['échantillon'].apply(lambda x: total_area.loc[x])\n",
    "work_data['area'] = work_data.area_c\n",
    "work_data.drop('area_c', axis=1, inplace=True)\n",
    "# the code total per sample with the combined area\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'quantité', 'code'], as_index=False)['quantité'].sum()\n",
    "work_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# get the pcs/m²  for each object at each sample\n",
    "work_data['pcs/m²'] = work_data['quantité']/work_data.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73519a05-eccd-40b9-8c72-92df5e191786",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# the code total per sample with the combined area\n",
    "work_data = work_data.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area','slug', 'quantité', 'code'], as_index=False)['quantité'].sum()\n",
    "work_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# get the pcs/m²  for each object at each sample\n",
    "work_data['pcs/m²'] = work_data['quantité']/work_data.area\n",
    "\n",
    "# grouping on substrate should produce the same values as table A4-1 \n",
    "test = work_data.groupby(['échantillon', 'substrat'], as_index=False)['pcs/m²'].sum()\n",
    "dtest = test.groupby('substrat')['pcs/m²'].describe()\n",
    "dtest.index.name = None\n",
    "dtest.rename(columns={'count':'compte', 'mean':'moyenne', 'std':'écart type'}, inplace=True)\n",
    "dtest['compte'] = dtest.compte.astype(int)\n",
    "\n",
    "caption = \"Les valeurs doivent correspondre au table A4-1 dans l'annexe 'Macro déchets plage et attribut'\"\n",
    "\n",
    "dtest = dtest.style.set_table_styles(table_css_styles).format(precision=2).set_caption(caption).format(**format_kwargs)\n",
    "\n",
    "glue('dtest-sa', dtest, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801382a8-e6a0-4011-9334-e1b6ab3492f0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ! there are samples that have different substrates on the same sample_id.!\n",
    "# there should be one substrate per sample_id. Identify the locations that have duplicate values\n",
    "voi = 'substrat'\n",
    "vals = \"pcs/m²\"\n",
    "some_data = work_data.copy()\n",
    "groupby = ['échantillon', voi]\n",
    "data = some_data.groupby(groupby, as_index=False)[vals].sum()\n",
    "\n",
    "# the samples with more than one substrate\n",
    "dd = data[data['échantillon'].duplicated()].copy()\n",
    "\n",
    "# select all the duplicated sample_ids from the work_data\n",
    "duplicated = work_data[work_data['échantillon'].isin(dd['échantillon'].unique())].copy()\n",
    "# change the substrat to [2]\n",
    "duplicated['substrat'] = 2 \n",
    "\n",
    "# select all the values that are not duplicated\n",
    "not_duplicated = work_data[~(work_data['échantillon'].isin(dd['échantillon'].unique()))].copy()\n",
    "\n",
    "# put it back together again\n",
    "work_data = pd.concat([duplicated, not_duplicated])\n",
    "\n",
    "# ! valid codes and definitions !\n",
    "# plastock did not use the same inventory as iqaasl\n",
    "# here we select only the codes in the plastock inventory\n",
    "pcodes = work_data.code.unique()\n",
    "\n",
    "# identify and remove codes for which there is no defintion\n",
    "# if the code is not defined then it can not be used\n",
    "t = [x for x in pcodes if x not in codes.index]\n",
    "wd_ni = work_data[~work_data.code.isin(t)].copy()\n",
    "\n",
    "# ! aggregating to Gfrags, Gcaps and Gfoams !\n",
    "# these items are not well divided into the composite subgroups\n",
    "# for example people often know what a cap is, but whether it \n",
    "# comes from a drink bottle or other type is not well considered\n",
    "# we combine the subcategories into more comprehensive groups.\n",
    "ti = rc.use_gfrags_gfoams_gcaps(wd_ni, codes)\n",
    "\n",
    "# ! groupby the sample id otherwise there are duplicate codes\n",
    "# after aggregating to Gfrags etc..\n",
    "work_data = ti.groupby(['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug', 'code'], as_index=False).agg({'quantité':'sum'})\n",
    "work_data['pcs/m²'] = work_data['quantité']/work_data['area']\n",
    "\n",
    "# accounting for objects not found at a sample:\n",
    "# the codes that were indentified are the unique codes\n",
    "# in the set of data\n",
    "codes_ip = work_data.code.unique()\n",
    "# the unique samples by id\n",
    "loc_dates = work_data['échantillon'].unique()\n",
    "\n",
    "# a copy for itterating\n",
    "wd = work_data.copy()\n",
    "\n",
    "# for each sample (échantillon) indentify the codes that were not\n",
    "# found by indentifying all the codes that were found and removing \n",
    "# them from the list of all unique codes.\n",
    "# for each unidentified code per sample, add a row with the sample\n",
    "# id and the code. give the row a quantity of zero.\n",
    "rows = []\n",
    "for a_loc in loc_dates:\n",
    "    r = wd.loc[wd['échantillon'] == a_loc].copy()\n",
    "    r.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    t = r.loc[0][['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug']].values\n",
    "    asamp = [x for x in t]\n",
    "    used_codes = r.code.unique()\n",
    "    unused = [x for x in codes_ip if x not in used_codes]\n",
    "    for element in unused:\n",
    "        arow = [*asamp, element, 0, 0]\n",
    "        rows.append(arow)\n",
    "        \n",
    "\n",
    "# now all the data has the same number of records per sample\n",
    "# for each sample we can now say what was found and what was\n",
    "# not found with respect to all the results\n",
    "work_x = pd.DataFrame(rows, columns=['échantillon', 'Plage', 'substrat', 'date', 'area', 'slug', 'code', 'quantité', 'pcs/m²'])\n",
    "work_data = pd.concat([work_x, work_data])\n",
    "\n",
    "\n",
    "# add the regional component\n",
    "regions = pd.read_csv(\"data/end_pipe/lac_leman_regions.csv\")\n",
    "regions.loc[regions.slug == 'savoniere', 'slug'] = 'savonniere'\n",
    "regions.drop_duplicates('slug', inplace=True)\n",
    "regions.set_index('slug', drop=True, inplace=True)\n",
    "work_data['region'] = work_data.slug.apply(lambda x: regions.loc[x, 'alabel'])\n",
    "# the city names are not included with the plastock data\n",
    "# they have been incorporated into the IQAASL data\n",
    "# we need to change the names from plastock that are duplicates\n",
    "# in the IQAASL data.\n",
    "change_names = ['preverenges', 'tolochenaz', 'versoix', 'vidy', 'cully']\n",
    "\n",
    "changeus = work_data[work_data.slug.isin(change_names)].copy()\n",
    "donotchange = work_data[~work_data.slug.isin(change_names)].copy()\n",
    "\n",
    "new_slug = {\n",
    "    'cully': 'cully-p',\n",
    "    'preverenges': 'preverenges-p',\n",
    "    'tolochenaz': 'tolochenaz-p',\n",
    "    'versoix':'versoix-p',\n",
    "    'vidy': 'vidy-p'}\n",
    "\n",
    "# they have the same name as locations in iqaasl\n",
    "changeus['new_slug'] = changeus.slug.apply(lambda x: new_slug[x])\n",
    "changeus['slug'] = changeus.new_slug\n",
    "changeus.drop('new_slug', inplace=True, axis=1)\n",
    "\n",
    "# the plastock data with the converted names\n",
    "report_data = pd.concat([changeus, donotchange])\n",
    "\n",
    "f = pd.read_csv('data/u_pstk.csv')\n",
    "city_map = f[[\"slug\", \"city\"]].drop_duplicates()\n",
    "city_map.loc[city_map.slug == 'savoniere', 'slug'] = 'savonniere'\n",
    "city_map.set_index('slug', inplace=True)\n",
    "\n",
    "# adding and renaming columns according to reportclass requirements\n",
    "# these values can be indexed on the IQAASL data\n",
    "report_data['city'] = report_data.slug.apply(lambda x: city_map.loc[x])\n",
    "report_data['groupname'] = report_data.code.apply(lambda x: codes.groupname.loc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d79ab4b-cca1-4443-9f5f-a3b17804bdaa",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def name_the_new_distance(x, less='<= 500 m', more = '> 500 m'):\n",
    "    if x == 1:\n",
    "        return less\n",
    "    else:\n",
    "        return more\n",
    "\n",
    "def name_the_new_freq(x, new):\n",
    "    if x <= 2:\n",
    "        return new\n",
    "    else:\n",
    "        return 'Elévée'\n",
    "\n",
    "\n",
    "# the feature variables are added to the work_data\n",
    "ti = work_data.copy()\n",
    "features = ['frequentation', 'situation', 'orientation', 'distance',]\n",
    "\n",
    "beach_datax = pd.read_csv(\"data/end_pipe/asl_beaches.csv\").set_index('Plage')\n",
    "\n",
    "# they can be merged on the Plage column and the index\n",
    "env_plastock = ti.merge(beach_datax[features], left_on='Plage', right_index=True)\n",
    "\n",
    "# ! creation of composite variables !\n",
    "t_and_f = env_plastock.loc[:, ['échantillon', 'slug','date','code', 'pcs/m²', 'quantité', 'frequentation', 'situation', 'distance', 'substrat', 'region']].copy()\n",
    "\n",
    "# the substrat and distance features are being combined\n",
    "# the two lowest and the two highest of each group are being combined\n",
    "# substrat is a matter of combining different granularities. They are being grouped as\n",
    "# sand and gravel.\n",
    "# distance is now grouped by locations either less than or equal to 500 meters\n",
    "t_and_f.loc[t_and_f.substrat <= 2, 'substrat'] = 1\n",
    "t_and_f.loc[t_and_f.substrat > 2, 'substrat'] = 2\n",
    "t_and_f.loc[t_and_f.distance <= 2, 'distance'] = 1\n",
    "t_and_f.loc[t_and_f.distance > 2, 'distance'] = 2\n",
    "t_and_f.loc[t_and_f.frequentation <= 2, 'frequentation'] = 2\n",
    "\n",
    "# ! the data used in the models !\n",
    "f_combi = t_and_f.copy()\n",
    "\n",
    "f_combi.rename(columns={'frequentation':'fréquentation', 'loc_date': 'échantillon'}, inplace=True)\n",
    "\n",
    "# the feature variables are combined along the ordinal axis. Going from four catgories\n",
    "# to two in the case of distance and substrate. city and country are already binary\n",
    "# the values of low and moderate frequentation are combined also.\n",
    "f_comb = f_combi.copy()\n",
    "f_comb['distance'] = f_comb['distance'].apply(lambda x: name_the_new_distance(x))\n",
    "f_comb['fréquentation'] = f_comb['fréquentation'].apply(lambda x: name_the_new_freq(x, 'faible-moyenne'))\n",
    "f_comb['situation'] = f_comb['situation'].apply(lambda x: name_situation[x])\n",
    "f_comb['substrat'] = f_comb['substrat'].apply(lambda x: name_the_new_distance(x, less='Sable', more='Graviers'))\n",
    "\n",
    "# ! no composite variables !\n",
    "no_combined = env_plastock.loc[:, ['échantillon', 'slug','date','code', 'pcs/m²', 'frequentation', 'situation', 'distance', 'substrat', 'region']].copy()\n",
    "no_combined.rename(columns={'frequentation':'fréquentation', 'loc_date': 'échantillon'}, inplace=True)\n",
    "\n",
    "no_combined['distance'] = no_combined['distance'].apply(lambda x: name_distance[x])\n",
    "no_combined['fréquentation'] = no_combined['fréquentation'].apply(lambda x: name_frequentation[x])\n",
    "no_combined['situation'] = no_combined['situation'].apply(lambda x: name_situation[x])\n",
    "no_combined['substrat'] = no_combined['substrat'].apply(lambda x: name_substrate[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d2dfa7-7eef-4a04-98d7-a22e3ae1bd60",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8,8))\n",
    "wk_dt = report_data.groupby(['échantillon', 'date'], as_index=False)['pcs/m²'].sum()\n",
    "vals = 'pcs/m²'\n",
    "object_column = vals\n",
    "ylim = 4\n",
    "xlim = 4\n",
    "sns.scatterplot(wk_dt, x=\"date\", y=vals, label='Plastock 2022 m²', ax=axs[0, 0])\n",
    "sns.boxplot(wk_dt, y=vals,  showfliers=True, ax=axs[0, 1], dodge=False)\n",
    "sns.histplot(wk_dt, x=vals,  ax=axs[1, 0], stat='probability', kde=True)\n",
    "sns.ecdfplot(wk_dt, x=vals,  ax=axs[1, 1])\n",
    "\n",
    "axs[0,0].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "axs[0,0].xaxis.set_major_formatter(mdates.DateFormatter('%m-%y'))\n",
    "\n",
    "axs[0, 0].set_ylim(-.01, ylim)\n",
    "axs[0, 1].set_ylim(-.01, ylim)\n",
    "axs[1, 1].set_xlim(-.01, xlim)\n",
    "axs[1, 0].set_xlim(-.01, xlim)\n",
    "\n",
    "axs[0, 0].set_xlabel(\"date\")\n",
    "axs[0, 0].set_ylabel(object_column)\n",
    "\n",
    "axs[1, 0].set_xlabel(object_column)\n",
    "axs[1, 0].set_ylabel(\"Probabilité\")\n",
    "axs[0, 1].set_xlabel(\"\")\n",
    "axs[0, 1].set_ylabel(object_column)\n",
    "axs[0, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "axs[1, 1].set_xlabel(object_column)\n",
    "axs[0,0].set_title(\"Total par échantillon\", loc=\"left\")\n",
    "axs[0,1].set_title(\"Boîte de Tukey\", loc=\"left\")\n",
    "axs[1,0].set_title(\"Histogramme\", loc=\"left\")\n",
    "axs[1,1].set_title(\"Fonction de répartition\", loc=\"left\")\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "glue('situataion-sa', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b09958-060c-459b-bcac-f039861d0246",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "situation_summary = rc.a_summary_of_one_vector(report_data, ['échantillon', 'date'], {'pcs/m²':'sum', 'quantité':'sum'}, describe  ='pcs/m²', total_column='quantité')\n",
    "situation_summary.rename(columns={'pcs/m²':'résultats'}, inplace=True)\n",
    "sit_disp = rc.translated_and_style_for_display(situation_summary, language_maps['fr'], 'fr', gradient=False)\n",
    "glue('sit_display', sit_disp, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be232674-3553-4503-ad95-c89419a9a0a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e232c01-ce55-4008-bd0c-4cfbb813dab6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# most common\n",
    "\n",
    "quantity_code = work_data.groupby('code')['quantité'].sum()\n",
    "pcsm_code = work_data.groupby('code')['pcs/m²'].mean()\n",
    "percent_total = quantity_code/quantity_code.sum()\n",
    "\n",
    "# fail_rate\n",
    "work_data['gzero'] = work_data['quantité'] > 0\n",
    "fail_rate = work_data.groupby('code').gzero.sum()\n",
    "fail_rate = fail_rate/work_data['échantillon'].nunique()\n",
    "inventory = pd.DataFrame({'Quantité':quantity_code, '% du total':percent_total, 'pcs/m²':pcsm_code, 'Taux d\\'échec':fail_rate})\n",
    "abundant_codes = inventory.sort_values(by='Quantité', ascending=False)[:10].index\n",
    "frequent_codes = inventory[inventory['Taux d\\'échec'] >= 0.5].index\n",
    "most_common_codes = list(set([*frequent_codes, *abundant_codes]))\n",
    "\n",
    "most_common_codes_df = inventory.loc[most_common_codes].sort_values(by='Quantité', ascending=False)\n",
    "most_common_codes_df['index'] = most_common_codes_df.index.map(lambda x: codes.fr.loc[x])\n",
    "\n",
    "mcm = most_common_codes_df.set_index('index', drop=True)\n",
    "mcm.index.name = None\n",
    "mc = mcm.style.set_table_styles(table_css_styles).format(**format_kwargs)\n",
    "\n",
    "glue('mcm-sa', mc, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fcd663c-ef20-4083-9c93-cd7fccac77ec",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "w_df = report_data.copy()\n",
    "cities = w_df.city.unique()\n",
    "cities = w_df.city.unique()\n",
    "cities.sort()\n",
    "cone = cities[:12]\n",
    "ctwo = cities[12:]\n",
    "\n",
    "\n",
    "\n",
    "sample_id = \"échantillon\"\n",
    "group_agg = {\"quantité\":\"sum\", \"pcs/m²\":\"mean\"}\n",
    "unit_agg = {\"quantité\":\"sum\", \"pcs/m²\":\"sum\"}\n",
    "pivot_values = vals\n",
    "\n",
    "args = dict(\n",
    "    feature_name='city', \n",
    "    object_column='code',\n",
    "    sample_id=sample_id, \n",
    "    group_agg=group_agg, \n",
    "    unit_agg=unit_agg, \n",
    "    pivot_values=vals, \n",
    "    table_split=cone\n",
    ")\n",
    "\n",
    "t = rc.a_cumulative_report(w_df[(w_df.code.isin(most_common_codes))], **args)\n",
    "\n",
    "caption_tone = \"Les résultats des objets les plus courants en pcs/m² pour chaque ville du projet: Amphion à Hermance\"\n",
    "\n",
    "mc_c1 = rc.translated_and_style_for_display(t, language_maps['fr'], 'fr',  gradient=True).set_caption(caption_tone)\n",
    "glue('most_common_c1', mc_c1, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fedc49de-90e6-4724-be32-99a6703ee497",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "file_name = 'resources/images/most_common_one-sa.jpg'\n",
    "make_exportable(t, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99f6a33-c654-4854-9a45-6185e51138e2",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "args.update({'table_split':ctwo})\n",
    "t = rc.a_cumulative_report(w_df[(w_df.code.isin(most_common_codes))], **args)\n",
    "\n",
    "caption_ttwo = \"Les résultats des objets les plus courants en pcs/m² pour chaque ville du projet: Lugrin à Vidy\"\n",
    "\n",
    "mc_c2 = rc.translated_and_style_for_display(t, language_maps['fr'], 'fr',  gradient=True).set_caption(caption_ttwo)\n",
    "glue('most_common_c2', mc_c2, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15539d12-1a77-4862-9d6c-326d39eaf49e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "file_name = 'resources/images/most_common_two-sa.jpg'\n",
    "make_exportable(t, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f5228e-fab0-4ba6-b621-060b75ebb8e9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "w_df = report_data.copy()\n",
    "cities = w_df.city.unique()\n",
    "cities.sort()\n",
    "cone = cities[:12]\n",
    "ctwo = cities[12:]\n",
    "\n",
    "args = dict(\n",
    "    feature_name='city', \n",
    "    object_column='groupname', \n",
    "    sample_id=sample_id, \n",
    "    group_agg=group_agg, \n",
    "    unit_agg=unit_agg, \n",
    "    pivot_values=vals, \n",
    "    table_split=cone\n",
    ")\n",
    "\n",
    "caption_gn1 = \"Les résultats des objets par utilisation pour chaque ville du projet: Amphion à Hemance\"\n",
    "\n",
    "groups_df = report_data.copy()\n",
    "group_name_map = codes['groupname']\n",
    "groups_df['groupname'] = groups_df.code.apply(lambda x: group_name_map.loc[x])\n",
    "tg1 = rc.a_cumulative_report(groups_df, feature_name='city', object_column='groupname', sample_id=sample_id, group_agg=group_agg, unit_agg=unit_agg, pivot_values=vals, table_split=cone)\n",
    "\n",
    "gn_c1 = rc.translated_and_style_for_display(tg1, language_maps['fr'], 'fr', gradient=True).set_caption(caption_gn1)\n",
    "glue('gn_c1', gn_c1, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b0ad8ea-4e55-404c-98fc-30c9ef7e1a6b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "file_name = 'resources/images/group_names_one-sa.jpg'\n",
    "make_exportable(tg1, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf8da2ee-5122-4569-9a1e-3c839a80eb92",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "args.update({'table_split':ctwo})\n",
    "\n",
    "caption_gn2 = \"Les résultats des objets par utilisation pour chaque ville du projet: Lugrin à Vevey\"\n",
    "tg2 = rc.a_cumulative_report(groups_df, **args)\n",
    "gn_c2 = rc.translated_and_style_for_display(tg2, language_maps['fr'], 'fr', gradient=True).set_caption(caption_gn2)\n",
    "\n",
    "glue('gn_c2', gn_c2, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63db6e14-be77-43fc-88bc-f74afee80964",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "file_name = 'resources/images/group_names_two-sa.jpg'\n",
    "make_exportable(tg2, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "059b6ce9-c551-47cc-9f1f-38ef9b35a046",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "unit_columns = ['region', 'échantillon']\n",
    "rg = []\n",
    "label='Haut lac'\n",
    "summary_index = ['min', '25%', '50%', '75%', 'max', 'mean', 'std', 'count', 'total']\n",
    "for label in report_data.region.unique():\n",
    "    g = rc.a_summary_of_one_vector(report_data[report_data.region == label].copy(), unit_columns=unit_columns, unit_agg=unit_agg, describe='pcs/m²', label=label, total_column='quantité')\n",
    "    rg.append(g)\n",
    "regional_summary = pd.concat(rg)\n",
    "rg = regional_summary.pivot(columns='label', values='pcs/m²')\n",
    "rg = rg.reindex(summary_index)\n",
    "\n",
    "rcg = rc.translated_and_style_for_display(rg, language_maps['fr'], 'fr', gradient=False)\n",
    "\n",
    "caption = \"Distribution des résultats par échantillon et par région : Plastock 2022\"\n",
    "\n",
    "rcg_hist = rcg.highlight_max(axis=1, props= 'color: rgba(255, 0, 0, 1);').set_caption(caption)\n",
    "glue('regional_summary_sa', rcg_hist, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b5a732b-7792-4ea0-8fa4-8b8d7b91d9bc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "mc_reg = report_data.groupby(['region', 'échantillon', 'code'], as_index=False)['pcs/m²'].sum()\n",
    "mcg = mc_reg[mc_reg.code.isin(most_common_codes)].groupby([\"region\", \"code\"], as_index=False)[\"pcs/m²\"].mean()\n",
    "mcg = mcg[['region', 'code', 'pcs/m²']].pivot(index='code', values='pcs/m²', columns='region')\n",
    "\n",
    "# language_maps = rc.language_maps()\n",
    "mcg = rc.translated_and_style_for_display(mcg, language_maps['fr'], 'fr', gradient=False) \n",
    "\n",
    "caption = \"La moyenne des objets les plus courants par région. Plastock 2022\"\n",
    "mcg_hist = mcg.highlight_max(axis=1, props= 'color: rgba(255, 0, 0, 1);').set_caption(caption)\n",
    "glue('regional_most_common', mcg_hist, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c50591ab-2576-48d9-ad70-afbe53964deb",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "distance_index = ['<= 500 m', '> 500 m']\n",
    "freq_index = ['Elévée', 'faible-moyenne']\n",
    "sub_index =  ['Graviers', 'Sable']\n",
    "def reindex_df(category, df, index):\n",
    "    df = df.reindex(index=index)\n",
    "    return df\n",
    "\n",
    "def calculate_combined_stats(category, data=f_comb.copy(), index=None):\n",
    "    # Descriptive statistics of the sample density and quantity of pieces found\n",
    "    # Aggregates the data on category and sample_id    \n",
    "    grouped = data.groupby([category, 'échantillon'], as_index=False)['pcs/m²'].sum()\n",
    "\n",
    "    group_summary = grouped.groupby(category, as_index=True).agg({'échantillon':'nunique', 'pcs/m²':['mean', 'median']})\n",
    "    group_summary.columns = group_summary.columns.droplevel(0)\n",
    "    \n",
    "    # Calculating percentage of total samples\n",
    "    group_summary['percentage'] = (group_summary['nunique'] / data['échantillon'].nunique()) * 100\n",
    "    group_summary.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    # Renaming columns for clarity\n",
    "    group_summary.rename(columns={'nunique': 'échantillons','mean': 'Moyenne', 'median': 'Médiane', 'percentage': '%'}, inplace=True)\n",
    "    group_summary.set_index(category, inplace=True, drop=True)\n",
    "    \n",
    "    # Make the index labels if required\n",
    "    if index is not None:\n",
    "        group_summary = reindex_df(category, group_summary, index=index)\n",
    "    \n",
    "    \n",
    "    return group_summary.style.set_table_styles(table_css_styles).format(precision=2).hide(axis=0, names=True)\n",
    "\n",
    "# Calculate stats for each category with combined rows\n",
    "frequentation_stats = calculate_combined_stats('fréquentation', index=freq_index)\n",
    "situation_stats = calculate_combined_stats('situation')\n",
    "distance_stats = calculate_combined_stats('distance', index=distance_index)\n",
    "substrat_stats = calculate_combined_stats('substrat', index=sub_index)\n",
    "section = 'MD'\n",
    "page = '1'\n",
    "\n",
    "freq_stats = add_table_to_page(frequentation_stats, 2, \": Densité de déchets par fréquentation\", section, page, \"\", format_index=None)\n",
    "sit_stats = add_table_to_page(situation_stats, 3, \": Densité de déchets par urbanization\", section, page, \"\", format_index=None)\n",
    "dist_stats = add_table_to_page(distance_stats, 4, \": Densité de déchets par distance de parking\", section, page, \" \", format_index=None)\n",
    "sub_stats = add_table_to_page(substrat_stats, 5, \": Densité de déchets selon substrat\", section, page, \"\", format_index=None)\n",
    "\n",
    "glue('freq_stats_sa', freq_stats, display=False)\n",
    "glue('sit_stats_sa', sit_stats, display=False)\n",
    "glue('dist_stats_sa', dist_stats, display=False)\n",
    "glue('sub_stats_sa', sub_stats, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dca663-eda6-4f86-8924-005dbb226320",
   "metadata": {},
   "source": [
    "# Plastock Macros déchets \n",
    "\n",
    "Les déchets de plage ont été échantillonnés tous les trimestres du 1er janvier 2022 au 31 décembre 2022 sur les plages du lac Léman. Les participants ont mesuré la longueur le long de la ligne d'eau et la largeur, la distance de la ligne d'eau, de chaque site d'étude. Au cours de cette période de 12 mois, les volontaires ont collecté et identifié 27 493 objets sur 25 sites, représentant 24 villes du bassin du Léman, ([résultats](sa_results)).\n",
    "\n",
    "Le résultat moyen était de 0,66 déchets par mètre² (pcs/m²). L'objet le plus courant est le plastique fragmenté, qui représente 41 % du total des objets (0,26 pièce/m²), suivi des mégots de cigarettes, qui représentent 11 % du total (0,07 pièce/m²).  Les objets les plus courants, ([plus courants](mc_sa)), en 2022 avaient tous été identifiés lors de campagnes antérieures sur le lac. Il convient de noter que six des objets les plus courants identifiés dans les études Plastock sont également les plus courants dans la région OSPAR ([OSPAR correspondance](cor_ospar)). \n",
    "\n",
    "Les échantillons ont été prélevés des deux côtés du lac et dans les trois régions. Le plus grand nombre d'échantillons a été collecté dans le Grand lac (47), suivi du Petit lac (27) et enfin du Haut lac (24). Le résultat moyen était le plus élevé dans le Haut lac (0,95 pcs/m²), suivi par le Grand lac (0,65 pcs/m²) et enfin le Petit lac (0,4 pcs/m²). Tous les objets les plus courants, à l'exception des capsules de bouteilles, ont également enregistré des valeurs moyennes plus élevées dans le Haut Lac. Cependant, la valeur médiane est la plus élevée dans le Grand lac et la différence entre la médiane et la moyenne est la plus élevée dans le Haut lac ([régionalité](mc_regional)).\n",
    "\n",
    "Les résultats de l'enquête sur les objets tels que les mégots de cigarettes et les emballages de snacks devraient être plus élevés dans les endroits où le substrat est sablonneux et où il y a un accès à un parking. Les sites éloignés ou constitués d'un substrat de gravier présentent des niveaux plus élevés de plastiques fragmentés. Différents modèles ont été envisagés à l'aide d'une régression par forêt aléatoire et d'une approximation par grille([random forest](random_forest_sa)) and a grid approximation ([grid approximation](grid_approx_p)).\n",
    "\n",
    "__Autres campganes :__\n",
    "\n",
    "Le Swiss Litter Report ([Swiss Litter Report](http://www.stoppp.org/)) fait état d'une moyenne de 0,67 déchet par m². La moyenne déclarée pour les lacs était de 1,23 pcs/m², avec des chiffres élevés dans les zones urbaines de 1,03 pcs/m². Nous notons que ces valeurs se situent dans la fourchette que l'on pourrait attendre de la mer ionienne (0,67 pcs/m²) ou de la mer méditerranée (0,61 pcs/m²).\n",
    "\n",
    "__Perspectives 2024 :__\n",
    "\n",
    "Si nous utilisons la même logique que celle appliquée dans ([résulats précédents](previous_results)), le résultat médian estimé pour 2024 se situe entre 0,43 pcs/m² et 0,62 pcs/m². Les sites avec un substrat de gravier ou plus éloignés auront des valeurs de comptage plus faibles pour les mégots de cigarettes et les emballages de snacks, mais des proportions plus élevées de plastiques fragmentés.\n",
    "\n",
    "(sa_results)=\n",
    "## Résultats\n",
    "::::{grid} 1 1 2 2\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`sit_display`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "L’échantillonnage était planifié trimestriellement, commençant en janvier 2022. À quelques exceptions près, chaque emplacement était échantillonné quatre fois au cours de la période de 12 mois.\n",
    "\n",
    "Au total, 98 échantillons ont été enregistrés sur 25 sites représentant 24 villes sur les rives du Léman.\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    ":columns: 12\n",
    "{glue}`situataion-sa`\n",
    ":::\n",
    "::::\n",
    "\n",
    "\n",
    "(mc_sa)=\n",
    "### Les objets les plus courants \n",
    "\n",
    "#### Définition des _objets les plus courants_\n",
    "\n",
    "Les _objets les plus courants_ peuvent être sélectionnés de plusieurs manières. On peut également les appeler les _objets d'intérêt_. Dans le cadre de ce rapport, nous nous concentrons sur les objets qui représentent une proportion plus importante des résultats que les autres. Nous avons utilisé deux critères de sélection : i. la quantité, ii. le taux d'échec.\n",
    "\n",
    "1. Quanité: Si un objet a une quantité totale qui le place dans les dix premiers, il est considéré comme 'courant'.\n",
    "2. Taux d'échec: Si un objet a été trouvé dans au moins la moitié des échantillons, il est ÉGALEMENT considéré comme 'courant'.\n",
    "\n",
    "Par conséquent, pour cette étude, les 'objets les plus courants' sont ceux qui se trouvent soit dans les dix premiers en termes de nombre total de pièces de déchets ET/OU qui ont été trouvés dans au moins 50% des enquêtes. Pour Plastock, les objets les plus courants représentent 89% du montant total ou 24'156/27'493 [Les plus courants](most_common_p).\n",
    "\n",
    "{glue}`mcm-sa`\n",
    "\n",
    "(mc_regional)=\n",
    "#### Les plus courants par région\n",
    "\n",
    "\n",
    "::::{grid} 1 1 2 2\n",
    ":::{grid-item}\n",
    "{glue}`regional_summary_sa`\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    ":padding: 4 1 1 1\n",
    "Comme nous l'avons vu précédemment, le Haut Lac a en moyenne des valeurs plus élevées que les deux autres régions. Cependant, nous remarquons que les valeurs minimales et de 25 % sont plus faibles dans le Haut Lac et que la médiane est presque la même que dans le Grand Lac. Cela suggère que les événements extrêmes sont plus probables dans le Haut Lac que dans le Grand Lac.\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    ":columns: 12\n",
    "\n",
    "{glue}`regional_most_common`\n",
    "\n",
    ":::\n",
    "::::\n",
    "\n",
    "\n",
    "#### Les plus courants par ville\n",
    "\n",
    "__Amphion à Hermance__\n",
    "\n",
    "```{glue} most_common_c1\n",
    "```\n",
    "<br>\n",
    "\n",
    "__Lugrin à Vevey__\n",
    "\n",
    "```{glue} most_common_c2\n",
    "``` \n",
    "\n",
    "### Les objets trouvés en fonction de leur utilisation\n",
    "\n",
    "Le type d'utilité est basé sur l'utilisation de l'objet avant qu'il ne soit jeté ou sur la description de l'objet si l'utilisation initiale est indéterminée. Les objets identifiés sont classés dans l'une des 260 catégories prédéfinies. Les catégories sont regroupées en fonction de leur utilisation ou de leur description.\n",
    "\n",
    "- Eaux usées : objets rejetés par les stations d'épuration, y compris les objets susceptibles d'être jetés dans les toilettes.\n",
    "- Microplastiques (< 5 mm) : plastiques fragmentés et résines plastiques de préproduction.\n",
    "- Infrastructure : objets liés à la construction et à l'entretien des bâtiments, des routes et des réseaux d'eau et d'électricité.\n",
    "- Alimentation et boisson : tous les matériaux liés à la consommation de nourriture et de boissons.\n",
    "- Agriculture : principalement des feuilles industrielles, par exemple, paillis et bâches de culture, serres, fumigation du sol, films d'emballage de balles. Comprend les plastiques durs pour les clôtures agricoles, les pots de fleurs, etc.\n",
    "- Tabac : principalement des filtres de cigarettes, y compris tous les matériaux liés au tabagisme.\n",
    "- Loisirs : objets liés au sport et aux loisirs, par exemple, pêche, chasse, randonnée, etc.\n",
    "- Emballages non alimentaires et non liés au tabac : matériaux d'emballage non identifiés comme étant liés à la nourriture, aux boissons ou au tabac.\n",
    "- Fragments de plastique : morceaux de plastique d'origine ou d'utilisation indéterminée.\n",
    "- Objets personnels : accessoires, articles d'hygiène et vêtements.\n",
    "\n",
    "Pour des informations détaillées sur la composition des groupes, consultez [IQAASL - DE](https://hammerdirt-analyst.github.io/IQAASL-End-0f-Sampling-2021/code_groups.html) ou [IQAASL - EN](https://www.plagespropres.ch/code_groups.html).\n",
    "<br>\n",
    "\n",
    "__Amphion à Hermance__\n",
    "\n",
    "```{glue} gn_c1\n",
    "```\n",
    "<br>\n",
    "\n",
    "__Lugrin à Vevey__\n",
    "\n",
    "```{glue} gn_c2\n",
    "``` \n",
    "<br>\n",
    "\n",
    "### Différences entre les types de plage\n",
    "\n",
    "Les conditions d’échantillonnage\n",
    "\n",
    "Les enquêteurs ont classé les conditions à chaque emplacement d’échantillonnage selon quatre catégories, fréquentation, substrat, distance au parking et situation (ville/campagne). Les plages ayant un taux d’utilisation élevé représentaient 56% (55/98) de tous les échantillons. Les plages situés à moins de 500 mètres d’un parking représentent 84% (83/98). Le résumé en détail est disponible ([attributes](macro-attributes)).\n",
    "\n",
    "Les catégories ont été combinées afin de réduire la covariance et d'améliorer l'interprétabilité. Les catégories ont été réduites de 4 à 2 dans le cas du substrat et de la distance au parking. La fréquence a été réduite à deux groupes en combinant les deux rangs les plus bas. Vous pouvez consulter les détails de la raison et de la manière dont nous procédons ici.: ([correlations](correlations)). Les résultats sont présentés ci-dessous :\n",
    "\n",
    "::::{grid} 1 1 2 2 \n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`freq_stats_sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`dist_stats_sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`sub_stats_sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    "\n",
    "{glue}`sit_stats_sa` \n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "Les lieux avec une plage de sable avaient la valeur médiane la plus élevée, soit .52 pcs/m² v/s graviers 0.24 pcs/m². Les lieux classés comme urbains avaient une valeur médiane de 0,52 pcs/m² pour 31 échantillons, contre 0,38 pcs/m² a la campagne pour 67 échantillons. Mais, l’échantillon moyenne attendu est plus élevé dans les localités désignées comme étant à la campagne (0.71 contre 0.57). Á la campagne, on s’attend à trouver plus de Gfrags et de pellets industriels (GPI) en % du total. Dans les villes, nous nous attendons à trouver plus de bouts de cigarettes et d’emballages de snacks par échantillon. Des prédictions ont été faites en utilisant différentes combinaisons de catégories à l’aide du régresseur de la forêt aléatoire ([Random forest](random_forest_sa)) et d’une approximation de la grille bayésienne ([Grid approximations](grid_approx_p)).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- ### Exigences particulières données plastock\n",
    "\n",
    "La quantité de déchets sauvages par mètre² de plage correspond au nombre total d'objets identifiés divisé par la surface d'étude. Pour les données Plastock, cela signifie que nous devons considérer la position un (ligne d'eau) et la position deux (plage sèche) ensemble. \n",
    "\n",
    "\n",
    "::::{grid}\n",
    "\n",
    ":::{grid-item}\n",
    "{glue}`dtest-sa`\n",
    ":::\n",
    "\n",
    ":::{grid-item}\n",
    ":padding: 4 2 2 2\n",
    "Les déchets par mètre carré sont considérés comme la somme de la surface de la position 1 et de la surface de la position 2 pour chaque échantillon [Macro déchets plage et attribut](macro-attributes).\n",
    ":::\n",
    "::::\n",
    "\n",
    "De plus, il y a __douze échantillons où le substrat était différent entre la position un et la position deux__. Par conséquent, ces 12 échantillons ont tous été classés dans la catégorie Sables grossiers. La distribution de la variable de substrat après la réattribution des 12 échantillons en question : 1. Sables fins : 27%, 2. Sables Grossiers : 32%, 3. Graviers : 16%, 4. Cailloux : 25%. -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5780bef-538b-4fd9-9df5-95f9ad75baff",
   "metadata": {},
   "source": [
    "## Estimation des paramètres et prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74d7fcd-500d-44d4-9aa3-aca0f037f53d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def analyze_scenario(scenario_data, func, n_iterations=100, bin_width=0.2):\n",
    "    \"\"\"\n",
    "    Analyze a specific scenario using Random Forest regression with bootstrapping,\n",
    "    and calculate feature importances.\n",
    "\n",
    "    :param data: DataFrame containing the dataset.\n",
    "    :param feature_1: The name of the first feature for filtering.\n",
    "    :param feature_1_value: The value of the first feature to filter by.\n",
    "    :param feature_2: The name of the second feature for filtering.\n",
    "    :param feature_2_value: The value of the second feature to filter by.\n",
    "    :param n_iterations: Number of bootstrap iterations. Default is 100.\n",
    "    :param bin_width: Width of each bin for histogram. Default is 0.2.\n",
    "    :return: A tuple containing bins, bin probabilities, flattened predictions, and feature importances.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare data for regression\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaled = y_scaler.fit_transform(scenario_data['pcs_m'].values.reshape(-1,1)).flatten()\n",
    "    \n",
    "    # Initialize the OneHotEncoder\n",
    "    # here we encode the ordinal data\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    \n",
    "    X = scenario_data.drop('pcs_m', axis=1)\n",
    "    \n",
    "    # Apply the encoder to the categorical columns\n",
    "    encoded_data = encoder.fit_transform(scenario_data[['fréquentation', 'situation', 'distance', 'substrat']])\n",
    "    # Create a DataFrame with the encoded data\n",
    "    X_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['fréquentation', 'situation', 'distance', 'substrat']))\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Bootstrap predictions and accumulate feature importances\n",
    "    bootstrap_predictions = []\n",
    "    feature_importances_accumulated = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    # Collect diagnostic at each repetition\n",
    "    cum_mse = []\n",
    "    cum_r2 = []\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        X_train_sample, y_train_sample = resample(X_train, y_train)\n",
    "        rf_model_sample = func\n",
    "        rf_model_sample.fit(X_train_sample, y_train_sample)\n",
    "        \n",
    "        pred = rf_model_sample.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, pred)\n",
    "        pred = y_scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "        bootstrap_predictions.append(pred)\n",
    "        mse = mean_squared_error(y_test , pred)\n",
    "        \n",
    "        \n",
    "        feature_importances_accumulated += rf_model_sample.feature_importances_\n",
    "        \n",
    "        cum_mse.append(mse)\n",
    "        cum_r2.append(r2)\n",
    "\n",
    "        # Average feature importances\n",
    "    feature_importances = feature_importances_accumulated / n_iterations\n",
    "\n",
    "    # Flatten the predictions array\n",
    "    predictions_flat = np.array(bootstrap_predictions).flatten()\n",
    "\n",
    "    return predictions_flat, feature_importances, cum_mse, cum_r2\n",
    "\n",
    "def plot_histogram(predictions, observed, title=\"\", reference='camp-dist-1', display=False):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.histplot(predictions, bins=20, stat=\"probability\", ax=ax, label='prédictions', zorder=0)\n",
    "    sns.histplot(observed, bins=20, stat=\"probability\", label='observée', zorder=1, ax=ax)\n",
    "    plt.title(title, loc='left')\n",
    "    plt.xlabel('pcs/m')\n",
    "    plt.ylabel('Densité de Probabilité')\n",
    "    plt.legend()\n",
    "    glue(reference, fig, display=display)\n",
    "    plt.close()\n",
    "\n",
    "def evalutate_model(r2s, mses, label, model='random-forest'):\n",
    "    r2 = np.round(np.mean(r2s), 2)\n",
    "    mse = np.round(np.mean(mses), 2)\n",
    "    results = {\"cross validated error\":r2, \"mean² error\":mse, 'model':model}\n",
    "    return pd.DataFrame(results, index=[label])\n",
    "\n",
    "# Calculating quantiles for Scenario 2\n",
    "q_uants = [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "index = ['1%', '25%', '50%', '75%', '99%', 'Moyenne']\n",
    "def makeqdf(observed, predicted, index=index, quants=q_uants, caption=\"\"):\n",
    "    \n",
    "    o_q = np.quantile(observed, quants)\n",
    "    m_o = np.mean(observed)\n",
    "    o_p = np.quantile(predicted, quants)\n",
    "    m_p = np.mean(predicted)\n",
    "    \n",
    "    results = {'observée':[*o_q, m_o], 'prédiction': [*o_p, m_p]}\n",
    "    return pd.DataFrame(results, index=index).style.set_table_styles(table_css_styles_top).format(precision=2).set_caption(caption)\n",
    "\n",
    "cols = ['échantillon', 'fréquentation','situation', 'distance', 'substrat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fbc57ee-2582-4c77-b97c-10ffda08ad91",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = f_combi[(f_combi['situation'] == 2) & (f_combi['fréquentation'] == 3)].copy()\n",
    "test_xi.rename(columns={'pcs/m²':'pcs_m'}, inplace=True)\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "# model parameters\n",
    "estimators = 10\n",
    "iterations = 1000\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42)\n",
    "predictions, feature_importance, mse, r2 = analyze_scenario(test_x, func,  n_iterations=iterations, bin_width=0.2)\n",
    "\n",
    "caption = 'Urban, Fréquentation Elévée'\n",
    "q_sit_2_freq_3 = makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-hf-ville-sa', q_sit_2_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions - Situation Ville, Haute Fréquentation'\n",
    "plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='ville-hf-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1ab426a-c84d-4229-a6b6-7f75df697e17",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = f_combi[(f_combi['situation'] == 1) & (f_combi['fréquentation'] == 3)].copy()\n",
    "test_xi.rename(columns={'pcs/m²':'pcs_m'}, inplace=True)\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42)\n",
    "predictions, feature_importance, mse, r2 = analyze_scenario(test_x, func,  n_iterations=iterations, bin_width=0.2)\n",
    "\n",
    "# the quantiles for this scenario\n",
    "caption=\"Campagne, Fréquentation Eléveé\"\n",
    "q_sit_1_freq_3 = makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-hf-camp-sa', q_sit_1_freq_3, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions - Situation Campagne, Haute Fréquentation\\n'\n",
    "plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='camp-hf-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "968529b2-2f1e-4c1e-a6df-79016b4e6599",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = f_combi[(f_combi['situation'] == 1) & (f_combi['distance'] == 1)].copy()\n",
    "test_xi.rename(columns={'pcs/m²':'pcs_m'}, inplace=True)\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42)\n",
    "predictions, feature_importance, mse, r2 = analyze_scenario(test_x, func,  n_iterations=iterations, bin_width=0.2)\n",
    "\n",
    "# the quantiles for this scenario\n",
    "caption = 'Campagne, <= 500 m du parking'\n",
    "q_sit_1_d_1 = makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-camp-dist_1-sa', q_sit_1_d_1, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions - Situation Campagne, distance < 500 m'\n",
    "plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='camp-dist-1-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92997188-9e47-4cca-bf6a-0908324ee81c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = f_combi[(f_combi['situation'] == 2) & (f_combi['distance'] == 1)].copy()\n",
    "test_xi.rename(columns={'pcs/m²':'pcs_m'}, inplace=True)\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42)\n",
    "predictions, feature_importance, mse, r2 = analyze_scenario(test_x, func,  n_iterations=iterations, bin_width=0.2)\n",
    "\n",
    "# the quantiles for this scenario\n",
    "caption = 'Urban, <= 500 m du parking'\n",
    "q_sit_2_d_1 = makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-ville-dist_1-sa', q_sit_2_d_1, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions - Situation Ville, distance < 500 m'\n",
    "plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='ville-dist-1-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "167922ac-8249-4a11-b75b-dd7ba59ac3e0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = f_combi[(f_combi['substrat'] == 1)].copy()\n",
    "test_xi.rename(columns={'pcs/m²':'pcs_m'}, inplace=True)\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42)\n",
    "predictions, feature_importance, mse, r2 = analyze_scenario(test_x, func,  n_iterations=iterations, bin_width=0.2)\n",
    "\n",
    "# the quantiles for this scenario\n",
    "caption = 'Sables'\n",
    "q_sub_1 = makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q_subs_1-sa', q_sub_1, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions - Sables'\n",
    "plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='subs_1_hist-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10bb04cc-4d9e-440f-a827-d9cd7b456f3e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "test_xi = f_combi[(f_combi['substrat'] == 2)].copy()\n",
    "test_xi.rename(columns={'pcs/m²':'pcs_m'}, inplace=True)\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "test_x = test_x[['fréquentation', 'situation', 'distance', 'substrat', 'pcs_m']]\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42)\n",
    "predictions, feature_importance, mse, r2 = analyze_scenario(test_x, func,  n_iterations=iterations, bin_width=0.2)\n",
    "\n",
    "# the quantiles for this scenario\n",
    "caption='Graviers'\n",
    "q_sub_2 = makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q_subs_2-sa', q_sub_2, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions - Graviers'\n",
    "plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='subs_2_hist-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45312e72-c814-46f5-b56a-2a2bcccedb4b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter for Scenario \n",
    "# This is all the values => no filter\n",
    "# just aggregating to the sample_id \n",
    "test_xi = f_combi.copy()\n",
    "test_xi.rename(columns={'pcs/m²':'pcs_m'}, inplace=True)\n",
    "test_x = test_xi.groupby(cols, as_index=False).pcs_m.sum()\n",
    "\n",
    "func = RandomForestRegressor(n_estimators=estimators, criterion=\"absolute_error\", random_state=42)\n",
    "predictions, feature_importance, mse, r2 = analyze_scenario(test_x, func,  n_iterations=iterations, bin_width=0.2)\n",
    "\n",
    "# the quantiles for this scenario\n",
    "caption = 'Toutes les conditions'\n",
    "q_tous = makeqdf(test_x.pcs_m.values, predictions, caption=caption)\n",
    "glue('q-tous-sa', q_tous, display=False)\n",
    "\n",
    "# the histogram for this scenario:\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions'\n",
    "plot_histogram(predictions, test_x.pcs_m.values, title=title, reference='tous-sa', display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdf825c-9a58-46cb-b0eb-df125784a038",
   "metadata": {},
   "source": [
    "(random_forest_sa)=\n",
    "### Random Forest \n",
    "\n",
    "Source : [scikit-learn random forest](https://scikit-learn.org/0.16/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "criterion : `absolute error`\n",
    "\n",
    "La régression avec forêt aléatoire est une technique d'apprentissage automatique (machine learning) utilisée pour prédire des résultats continus (par opposition aux catégories dans la classification). C'est une méthode d'apprentissage ensembliste, ce qui signifie qu'elle combine les prédictions de plusieurs algorithmes d'apprentissage automatique pour produire des prédictions plus précises.\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Toutes les conditions\n",
    "{glue}`tous-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Graviers\n",
    "{glue}`subs_2_hist-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Sables\n",
    "{glue}`subs_1_hist-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Ville et haute Fréquentation\n",
    "{glue}`ville-hf-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Campagne et haute fréquentation\n",
    "{glue}`camp-hf-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Campagne et parking <= 500 m\n",
    "{glue}`camp-dist-1-sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Ville et parking <= 500 m\n",
    "{glue}`ville-dist-1-sa`\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    ":::{tab-item} Résultats\n",
    ":selected:\n",
    "\n",
    "````{grid} 1 2 2 2\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-tous-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "\n",
    "Les modèles ont fait l'objet d'un bootstrap, 100 itérations pour chaque scénario. Les résultats estimés sont la collection de toutes les prédictions de chaque itération.\n",
    "\n",
    "Par exemple, le tableau intitulé \"Gravier\" présente les résultats observés et prévus pour les plages ayant un substrat de 3 ou 4.\n",
    "\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q_subs_2-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q_subs_1-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-hf-ville-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-hf-camp-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-camp-dist_1-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-ville-dist_1-sa`\n",
    "```\n",
    "\n",
    "````\n",
    ":::\n",
    "\n",
    "::::\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ff8b3c5-1033-4e4e-9c89-faf276ebb18f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from typing import Type, Optional, Callable\n",
    "from typing import List, Dict, Union, Tuple\n",
    "\n",
    "def sum_a_b(zipped):\n",
    "    for element in zipped:\n",
    "        # the new beta distribution would be\n",
    "        # total success, (total tries - total success)\n",
    "        new_element_0 = np.array([np.array([x[0], x[1] - x[0]]) for x in element[0]])\n",
    "        new_element_1 = np.array([x for x in element[1]])\n",
    "        t3 = new_element_0 + new_element_1\n",
    "        \n",
    "        yield t3\n",
    "\n",
    "# Grid approximation\n",
    "grid_val_index = np.linspace(0, 5.99, 600)\n",
    "groupby_columns = ['sample_id', 'location', 'date', 'city', 'orchards', 'vineyards', 'buildings', 'forest',\n",
    "                   'undefined', 'public_services', 'streets']\n",
    "def draw_a_beta_value(generator):\n",
    "    d = next(generator)\n",
    "    # drawing a random number from the beta distribution\n",
    "    # this is the the chance p, that a binomial distribution will\n",
    "    # result in True.\n",
    "    my_beta = [beta(x[0], x[1]).rvs(1) for x in d]\n",
    "    yield my_beta\n",
    "\n",
    "def binomial_probability_of_failure(generator):\n",
    "    # in this case failure means exceeding the value\n",
    "    # for trash a success is never exceeding the value\n",
    "    d = next(generator)\n",
    "    di = [x[0] for x in d]\n",
    "    yield di\n",
    "\n",
    "def bin_land_use_values(*, data: pd.DataFrame, column: str, num_bins: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Bins the specified column's values into a given number of bins and adds a new column to the DataFrame with these bin labels.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame to modify.\n",
    "        column (str): The name of the column to bin.\n",
    "        num_bins (int, optional): The number of bins to use. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with an additional column for binned values.\n",
    "    \"\"\"\n",
    "    data[f'{column}_bin'] = pd.cut(data[column], bins=num_bins, labels=[1, 2, 3, 4 ], include_lowest=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_likelihood(*, aggregated_data: pd.DataFrame, bin_density_column: str, pcs_column: str = 'pcs/m',\n",
    "                         grid_range: np.ndarray = None, bins: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the likelihood of observing the aggregated pcs/m data for each grid point and bin density value.\n",
    "\n",
    "    Args:\n",
    "        aggregated_data (pd.DataFrame): The aggregated data to be used for likelihood calculation.\n",
    "        bin_density_column (str): The column representing bin density numbers.\n",
    "        pcs_column (str, optional): The pcs/m column to use for calculation. Defaults to 'pcs/m'.\n",
    "        grid_range (np.ndarray, optional): The range of grid values. Defaults to np.linspace(0, 9.99, 1000).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with likelihood values for each grid value and bin density number.\n",
    "    \"\"\"\n",
    "    likelihood_df = pd.DataFrame(index=grid_range)\n",
    "    \n",
    "    for bin_value in bins:\n",
    "        bin_data = aggregated_data[aggregated_data[bin_density_column] == bin_value]\n",
    "        if bin_data.empty:\n",
    "            likelihoods = [np.array([1, 1]) for grid_point in grid_range]\n",
    "        else:\n",
    "            likelihoods = [np.array([(bin_data[pcs_column] > grid_point).sum(), len(bin_data)]) for grid_point in\n",
    "                           grid_range]\n",
    "        likelihood_df[f'Likelihood_{bin_value}'] = likelihoods\n",
    "    return likelihood_df\n",
    "\n",
    "def calculate_beta_prior(*, grid_range: np.ndarray = grid_val_index, bin_density_numbers: List[int] = list(range(1,\n",
    "                                                                                                    21))) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates a Beta(1, 1) prior for each value in the specified grid range for each bin density number.\n",
    "\n",
    "    Args:\n",
    "        grid_range (np.ndarray, optional): The range of grid values. Defaults to np.linspace(0, 9.99, 1000).\n",
    "        bin_density_numbers (List[int], optional): List of bin density numbers. Defaults to range(1, 21).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with Beta(1, 1) prior values for each grid value and bin density number.\n",
    "    \"\"\"\n",
    "    prior_df = pd.DataFrame(index=grid_range)\n",
    "    prior_values = np.array([1, 1])  # Constant value since Beta(1, 1) is uniform\n",
    "    \n",
    "    for bin_number in bin_density_numbers:\n",
    "        prior_df[f'Bin_{bin_number}'] = [prior_values for grid_point in grid_range]\n",
    "    return prior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "493630d7-064e-4dac-a9d2-bf4ee8522116",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "from scipy.stats import multinomial\n",
    "\n",
    "def define_posterior(likelihood, prior, grid_val_index: np.array = None):\n",
    "    \n",
    "    # the alpha, beta parameters of the likelihood and prior are assembled\n",
    "    alpha_beta = list(zip(likelihood.values, prior.values))\n",
    "    a_b_sum = sum_a_b(alpha_beta)\n",
    "    \n",
    "    posteriors = []\n",
    "    for i in grid_val_index:\n",
    "        # the sum of successes and failures for the scenario at the given\n",
    "        # grid value are used as the alpha, beta parameters of the beta distribtion\n",
    "        # for the binomial/bernouli probability that a sample will exceed the grid\n",
    "        # value i.\n",
    "        st = binomial_probability_of_failure(draw_a_beta_value(a_b_sum))\n",
    "        val = next(st)\n",
    "        posteriors.append(val)\n",
    "    \n",
    "    # return posterior probabilities with gird index and column labels\n",
    "    post_grid_pstock = pd.DataFrame(posteriors, index=grid_val_index, columns=prior.columns)\n",
    "    \n",
    "    # identify the x scale of the grid\n",
    "    post_grid_pstock['X'] = post_grid_pstock.index\n",
    "    \n",
    "    # this column is the normalized probabilities that a sample\n",
    "    # will exceed a value on the grid.\n",
    "    post_grid_pstock['norm'] = post_grid_pstock['Bin_1']/post_grid_pstock['Bin_1'].sum()\n",
    "    \n",
    "    return post_grid_pstock\n",
    "\n",
    "def non_zero(alist):\n",
    "    # find the first non-zero object in an array\n",
    "    # return the index number and the value.\n",
    "    for i, anum in enumerate(alist):\n",
    "        if anum != 0:\n",
    "            return i, anum\n",
    "    return None\n",
    "\n",
    "def draw_sample_from_multinomial(normed, n=100):\n",
    "    # the norm column from the posterior data frame is\n",
    "    # used as the probabilities of a multinomial distribution\n",
    "    rv = multinomial(1, normed.values)\n",
    "    y = rv.rvs(n)   \n",
    "\n",
    "    indexes = []\n",
    "    for i in range(0, len(y)):\n",
    "        indexes.append(non_zero(y[i])[0])\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def posterior_predictions(p_g_p):\n",
    "    \n",
    "    p_norm = p_g_p['norm']\n",
    "    \n",
    "    indexes = draw_sample_from_multinomial(p_norm)\n",
    "    results_scale = p_g_p.reset_index(drop=True)\n",
    "    sample_totals = results_scale.loc[indexes, \"X\"]\n",
    "    \n",
    "    return sample_totals\n",
    "\n",
    "# the prior data from surveys\n",
    "# iqaasl_prior = report_iq_pk.w_df[report_iq_pk.w_df.project == \"IQAASL\"].copy()\n",
    "# iq_p = iqaasl_prior.groupby(['loc_date', 'project'], as_index=False).pcs_m.sum()\n",
    "# iq_p['top'] = 1\n",
    "\n",
    "# iq_prior = calculate_likelihood(aggregated_data=iq_p, bin_density_column='top', pcs_column='pcs_m', grid_range=grid_val_index, bins=[1])\n",
    "# iq_prior.rename(columns={'Likelihood_1':'Bin_1'}, inplace=True)\n",
    "\n",
    "# assuming no prior knowledge\n",
    "# that is we assume there is an equal chance (50%) of finding any\n",
    "# number on the grid 0.00 - 5.99\n",
    "beta_prior = calculate_beta_prior(bin_density_numbers=[1])\n",
    "    \n",
    "col = 'top'\n",
    "pcs_col = 'pcs/m²'\n",
    "grid_range = grid_val_index\n",
    "bins = [1]\n",
    "\n",
    "test_x = f_combi.copy().groupby(cols, as_index=False)[pcs_col].sum()\n",
    "test_x['top'] = 1\n",
    "\n",
    "grid_pstock = calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock = define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# # posterior informed\n",
    "# post_grid_iqp =define_posterior(grid_pstock, iq_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = posterior_predictions(post_grid_pstock.copy())\n",
    "# s_iqp = posterior_predictions(post_grid_iqp.copy())\n",
    "\n",
    "caption = 'Toutes les conditions'\n",
    "\n",
    "test_grid_quants = makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-tous-b-sa', test_grid_quants, display=False)\n",
    "\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions: toutes les conditions,  grid approximation, prior = IQAASL'\n",
    "\n",
    "plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='toutes-gapprox-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "328ae9c1-cb2d-4e13-aec5-352d0a93ed89",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'substrat'\n",
    "pcs_col = 'pcs/m²'\n",
    "grid_range = grid_val_index\n",
    "bins = [1]\n",
    "\n",
    "test_xi = f_combi[(f_combi['substrat'] == 1)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock = define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = posterior_predictions(post_grid_pstock.copy())\n",
    "\n",
    "caption = 'Sable'\n",
    "\n",
    "test_grid_quants = makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-sable-b-sa', test_grid_quants, display=False)\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions: Sable, grid approximation'\n",
    "\n",
    "plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='sables-gapprox-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61a2dc86-aef8-4185-9bc9-0256ad0becc7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'substrat'\n",
    "pcs_col = 'pcs/m²'\n",
    "grid_range = grid_val_index\n",
    "bins = [2]\n",
    "\n",
    "test_xi = f_combi[(f_combi['substrat'] == 2)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock = define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = posterior_predictions(post_grid_pstock.copy())\n",
    "\n",
    "caption = 'Graviers'\n",
    "\n",
    "test_grid_quants = makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-gravier-b-sa', test_grid_quants, display=False)\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions: Graviers, grid approximation'\n",
    "\n",
    "plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='graviers-gapprox-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abe143a1-1430-483e-890e-283be9816188",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'fréquentation'\n",
    "pcs_col = 'pcs/m²'\n",
    "grid_range = grid_val_index\n",
    "bins = [3]\n",
    "\n",
    "test_xi = f_combi[(f_combi['situation'] == 2) & (f_combi['fréquentation'] == 3)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock = define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = posterior_predictions(post_grid_pstock.copy())\n",
    "\n",
    "caption = 'Ville et haut fréquentation'\n",
    "\n",
    "test_grid_quants = makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-v-hf-b-sa', test_grid_quants, display=False)\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions: Ville et haut fréquentation, grid approximation'\n",
    "\n",
    "plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='v-hf-gapprox-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "345ee56a-c34d-4424-a46e-447868bf861c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'fréquentation'\n",
    "pcs_col = 'pcs/m²'\n",
    "grid_range = grid_val_index\n",
    "bins = [3]\n",
    "\n",
    "test_xi = f_combi[(f_combi['situation'] == 1) & (f_combi['fréquentation'] == 3)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock = define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = posterior_predictions(post_grid_pstock.copy())\n",
    "\n",
    "caption = 'Campagne et haut fréquentation'\n",
    "\n",
    "test_grid_quants = makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-cam-hf-b-sa', test_grid_quants, display=False)\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions: Campagne et haut fréquentation, grid approximation'\n",
    "\n",
    "plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='cam-hf-gapprox-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63dfb058-9dbb-4716-9a7d-2ccf6fe3a4d5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'situation'\n",
    "pcs_col = 'pcs/m²'\n",
    "grid_range = grid_val_index\n",
    "bins = [2]\n",
    "\n",
    "test_xi = f_combi[(f_combi['situation'] == 2) & (f_combi['distance'] == 1)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock = define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = posterior_predictions(post_grid_pstock.copy())\n",
    "\n",
    "caption = 'Ville et distance <= 500 m'\n",
    "\n",
    "test_grid_quants = makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-ville-d1-sa', test_grid_quants, display=False)\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions: Ville et distance <= 500 m, grid approximation, '\n",
    "\n",
    "plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='v-d1-sa', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "926edb0e-f41b-422d-b676-7e01874ca12f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col = 'situation'\n",
    "pcs_col = 'pcs/m²'\n",
    "grid_range = grid_val_index\n",
    "bins = [1]\n",
    "\n",
    "test_xi =  f_combi[(f_combi['situation'] == 1) & (f_combi['distance'] == 1)].copy()\n",
    "test_x = test_xi.groupby(cols, as_index=False)[pcs_col].sum()\n",
    "\n",
    "\n",
    "grid_pstock = calculate_likelihood(aggregated_data=test_x, bin_density_column=col, pcs_column=pcs_col, grid_range=grid_range, bins=bins)\n",
    "\n",
    "# posterior uninformed\n",
    "post_grid_pstock = define_posterior(grid_pstock, beta_prior, grid_val_index=grid_range)\n",
    "\n",
    "# samples\n",
    "sample_totals = posterior_predictions(post_grid_pstock.copy())\n",
    "\n",
    "caption = 'Campagne et distance <= 500 m'\n",
    "\n",
    "test_grid_quants = makeqdf(test_x[pcs_col].values, sample_totals, caption=caption)\n",
    "glue('q-cam-d1-sa', test_grid_quants, display=False)\n",
    "title = 'Plastock 2022, Le Léman\\nDistribution des Prédictions: Campagne et haut fréquentation, grid approximation,'\n",
    "\n",
    "plot_histogram(sample_totals, test_x[pcs_col].values, title=title, reference='cam-d1-sa', display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5cdb3-0401-4cec-8fc3-8740e8a2fd8f",
   "metadata": {},
   "source": [
    "(grid_approx_p)=\n",
    "### Approximation Bayésienne par Grille\n",
    "\n",
    "Source : [hammerdirt](https://hammerdirt-analyst.github.io/feb_2024/titlepage.html)\n",
    "\n",
    "application : [solid-waste-team](https://hammerdirt-analyst.github.io/solid-waste-team/grid_approximation.html)\n",
    "\n",
    "prior : beta(1,1)\n",
    "\n",
    "Cas d'utilisation : Cette méthode est une approche manuelle de l'inférence Bayésienne. Elle est particulièrement utile lorsque vous souhaitez incorporer des croyances antérieures et mettre à jour ces croyances avec des données observées.\n",
    "\n",
    "Mise en œuvre : Implique la définition d'une grille de valeurs de paramètres et le calcul de la vraisemblance des données observées à chaque point de cette grille. En multipliant par la probabilité a priori et en normalisant, on obtient la distribution a posteriori. Cela peut être fait pour chaque condition séparément ou pour toutes les conditions ensemble, bien que cela soit plus intensif en termes de calcul.\n",
    "\n",
    "\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Toutes les conditions\n",
    "{glue}`toutes-gapprox-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Graviers\n",
    "{glue}`graviers-gapprox-sa`\n",
    ":::\n",
    "\n",
    ":::{tab-item} Sables\n",
    "{glue}`sables-gapprox-sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Ville et haute Fréquentation\n",
    "{glue}`v-hf-gapprox-sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Campagne et haute fréquentation\n",
    "{glue}`cam-hf-gapprox-sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Campagne et parking <= 500 m\n",
    "{glue}`cam-d1-sa`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Ville et parking <= 500 m\n",
    "{glue}`v-d1-sa`\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    ":::{tab-item} Résultats\n",
    ":selected:\n",
    "\n",
    "````{grid} 1 2 2 2\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-tous-b-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "\n",
    "Prédictions : Fournit une distribution de valeurs possibles de pcs/m, offrant une idée de la fourchette et de l'incertitude des prédictions. Particulièrement utile lorsque la prise de décision nécessite de comprendre l'incertitude ou la variabilité des prédictions.\n",
    "\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-gravier-b-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-sable-b-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-v-hf-b-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-cam-hf-b-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-cam-d1-sa`\n",
    "```\n",
    "\n",
    "```{grid-item}\n",
    "{glue}`q-ville-d1-sa`\n",
    "```\n",
    "\n",
    "````\n",
    ":::\n",
    "\n",
    "::::\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcaac6-1e6b-44ec-a01e-87686b313a16",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "\\* Proposed citation: Vlachogianni, Th., Anastasopoulou, A., Fortibuoni, T., Ronchi, F.,\n",
    "Zeri, Ch., 2017. Marine Litter Assessment in the Adriatic and Ionian Seas. IPA-Adriatic\n",
    "DeFishGear Project, MIO-ECSDE, HCMR and ISPRA. pp. 168 (ISBN: 978-960-6793-25-7)\n",
    "\n",
    "The DeFishGear marine litter assessment report presents the results of\n",
    "the one-year long marine litter surveys aiming to assess the amounts,\n",
    "sources and impacts of marine macro-litter in the Adriatic and Ionian Seas.\n",
    "\n",
    "\\*\\* Citation: Yona D, Nooraini P, Putri SEN, Sari SHJ, Lestariadi RA and Amirudin A (2023) Spatial distribution and composition of marine litter on sandy beaches along the Indian Ocean coastline in the south Java region, Indonesia. Front. Mar. Sci. 10:1220650. doi: 10.3389/fmars.2023.1220650\n",
    "\n",
    "This study analyzed beach litter composition on five beaches (Kondangmerak, Balekambang, Ungapan, Ngudel, and Goa Cina) along the Indian Ocean coastline in the eastern part of the south Java region, Indonesia.\n",
    "\n",
    "\\*\\*\\* Vlachogianni, Th., 2019. Assessing marine litter on Mediterranean beaches. Filling in the knowledge\n",
    "gaps via a participatory-science initiative. MIO-ECSDE.\n",
    "\n",
    "The beach litter surveys were carried out on beaches located in five Mediterranean countries,\n",
    "namely in Croatia, Cyprus, France, Greece and Italy. A total of 23 sites were surveyed and two sets of\n",
    "surveys were performed; from mid-September to mid-October 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e27b1ea-47c0-4177-8db5-7685a0342845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>échantillon</th>\n",
       "      <th>Plage</th>\n",
       "      <th>substrat</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>slug</th>\n",
       "      <th>code</th>\n",
       "      <th>quantité</th>\n",
       "      <th>pcs/m²</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>groupname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>('cully', '04.05.2022')</td>\n",
       "      <td>Cully</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>67</td>\n",
       "      <td>cully-p</td>\n",
       "      <td>G113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Haut lac</td>\n",
       "      <td>Cully</td>\n",
       "      <td>micro plastics (&lt; 5mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>('cully', '04.05.2022')</td>\n",
       "      <td>Cully</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>67</td>\n",
       "      <td>cully-p</td>\n",
       "      <td>G114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Haut lac</td>\n",
       "      <td>Cully</td>\n",
       "      <td>micro plastics (&lt; 5mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>('cully', '04.05.2022')</td>\n",
       "      <td>Cully</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>67</td>\n",
       "      <td>cully-p</td>\n",
       "      <td>G148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Haut lac</td>\n",
       "      <td>Cully</td>\n",
       "      <td>packaging non food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>('cully', '04.05.2022')</td>\n",
       "      <td>Cully</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>67</td>\n",
       "      <td>cully-p</td>\n",
       "      <td>G27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Haut lac</td>\n",
       "      <td>Cully</td>\n",
       "      <td>tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>('cully', '04.05.2022')</td>\n",
       "      <td>Cully</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>67</td>\n",
       "      <td>cully-p</td>\n",
       "      <td>G30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Haut lac</td>\n",
       "      <td>Cully</td>\n",
       "      <td>food and drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>('tougues', '29.01.2022')</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>544</td>\n",
       "      <td>tougues</td>\n",
       "      <td>G27</td>\n",
       "      <td>36</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>Petit lac</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>('tougues', '29.01.2022')</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>544</td>\n",
       "      <td>tougues</td>\n",
       "      <td>G30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>Petit lac</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>food and drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>('tougues', '29.01.2022')</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>544</td>\n",
       "      <td>tougues</td>\n",
       "      <td>G31</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>Petit lac</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>food and drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>('tougues', '29.01.2022')</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>544</td>\n",
       "      <td>tougues</td>\n",
       "      <td>Gfoams</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>Petit lac</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>('tougues', '29.01.2022')</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>544</td>\n",
       "      <td>tougues</td>\n",
       "      <td>Gfrags</td>\n",
       "      <td>14</td>\n",
       "      <td>0.025735</td>\n",
       "      <td>Petit lac</td>\n",
       "      <td>Tougues</td>\n",
       "      <td>plastic pieces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7154 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    échantillon    Plage  substrat       date  area     slug   \n",
       "1531    ('cully', '04.05.2022')    Cully         3 2022-05-04    67  cully-p  \\\n",
       "1532    ('cully', '04.05.2022')    Cully         3 2022-05-04    67  cully-p   \n",
       "1533    ('cully', '04.05.2022')    Cully         3 2022-05-04    67  cully-p   \n",
       "1534    ('cully', '04.05.2022')    Cully         3 2022-05-04    67  cully-p   \n",
       "1535    ('cully', '04.05.2022')    Cully         3 2022-05-04    67  cully-p   \n",
       "...                         ...      ...       ...        ...   ...      ...   \n",
       "1207  ('tougues', '29.01.2022')  Tougues         2 2022-01-29   544  tougues   \n",
       "1208  ('tougues', '29.01.2022')  Tougues         2 2022-01-29   544  tougues   \n",
       "1209  ('tougues', '29.01.2022')  Tougues         2 2022-01-29   544  tougues   \n",
       "1210  ('tougues', '29.01.2022')  Tougues         2 2022-01-29   544  tougues   \n",
       "1211  ('tougues', '29.01.2022')  Tougues         2 2022-01-29   544  tougues   \n",
       "\n",
       "        code  quantité    pcs/m²     region     city               groupname  \n",
       "1531    G113         0  0.000000   Haut lac    Cully  micro plastics (< 5mm)  \n",
       "1532    G114         0  0.000000   Haut lac    Cully  micro plastics (< 5mm)  \n",
       "1533    G148         0  0.000000   Haut lac    Cully      packaging non food  \n",
       "1534     G27         0  0.000000   Haut lac    Cully                 tobacco  \n",
       "1535     G30         0  0.000000   Haut lac    Cully          food and drink  \n",
       "...      ...       ...       ...        ...      ...                     ...  \n",
       "1207     G27        36  0.066176  Petit lac  Tougues                 tobacco  \n",
       "1208     G30         8  0.014706  Petit lac  Tougues          food and drink  \n",
       "1209     G31         3  0.005515  Petit lac  Tougues          food and drink  \n",
       "1210  Gfoams         3  0.005515  Petit lac  Tougues          infrastructure  \n",
       "1211  Gfrags        14  0.025735  Petit lac  Tougues          plastic pieces  \n",
       "\n",
       "[7154 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8274f-9443-4114-8fad-c47595696b93",
   "metadata": {},
   "source": [
    "## Inventaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41ba0fd4-e606-433a-a901-676ebeb2557e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5b86 tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_f5b86 tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_f5b86 tr {\n",
       "  font-size: 14px;\n",
       "  padding: 6px;\n",
       "}\n",
       "#T_f5b86 th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  white-space: nowrap;\n",
       "  word-break: keep-all;\n",
       "}\n",
       "#T_f5b86 td {\n",
       "  padding: 4px;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f5b86 caption {\n",
       "  caption-side: bottom;\n",
       "  font-size: 16px;\n",
       "  text-align: left;\n",
       "  margin-top: 15px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5b86\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5b86_level0_col0\" class=\"col_heading level0 col0\" >Quantité</th>\n",
       "      <th id=\"T_f5b86_level0_col1\" class=\"col_heading level0 col1\" >% du total</th>\n",
       "      <th id=\"T_f5b86_level0_col2\" class=\"col_heading level0 col2\" >pcs/m²</th>\n",
       "      <th id=\"T_f5b86_level0_col3\" class=\"col_heading level0 col3\" >Taux d'échec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >code</th>\n",
       "      <th class=\"index_name level1\" >index</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row0\" class=\"row_heading level0 row0\" >Gfrags</th>\n",
       "      <th id=\"T_f5b86_level1_row0\" class=\"row_heading level1 row0\" >Fragments de plastique: G80, G79, G78, G75</th>\n",
       "      <td id=\"T_f5b86_row0_col0\" class=\"data row0 col0\" >11'221</td>\n",
       "      <td id=\"T_f5b86_row0_col1\" class=\"data row0 col1\" >0,41</td>\n",
       "      <td id=\"T_f5b86_row0_col2\" class=\"data row0 col2\" >0,26</td>\n",
       "      <td id=\"T_f5b86_row0_col3\" class=\"data row0 col3\" >0,97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row1\" class=\"row_heading level0 row1\" >G27</th>\n",
       "      <th id=\"T_f5b86_level1_row1\" class=\"row_heading level1 row1\" >Mégots et filtres à cigarettes</th>\n",
       "      <td id=\"T_f5b86_row1_col0\" class=\"data row1 col0\" >3'089</td>\n",
       "      <td id=\"T_f5b86_row1_col1\" class=\"data row1 col1\" >0,11</td>\n",
       "      <td id=\"T_f5b86_row1_col2\" class=\"data row1 col2\" >0,07</td>\n",
       "      <td id=\"T_f5b86_row1_col3\" class=\"data row1 col3\" >0,79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row2\" class=\"row_heading level0 row2\" >G30</th>\n",
       "      <th id=\"T_f5b86_level1_row2\" class=\"row_heading level1 row2\" >Emballages de bonbons, de snacks</th>\n",
       "      <td id=\"T_f5b86_row2_col0\" class=\"data row2 col0\" >2'080</td>\n",
       "      <td id=\"T_f5b86_row2_col1\" class=\"data row2 col1\" >0,08</td>\n",
       "      <td id=\"T_f5b86_row2_col2\" class=\"data row2 col2\" >0,05</td>\n",
       "      <td id=\"T_f5b86_row2_col3\" class=\"data row2 col3\" >0,74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row3\" class=\"row_heading level0 row3\" >G106</th>\n",
       "      <th id=\"T_f5b86_level1_row3\" class=\"row_heading level1 row3\" >Fragments de plastique angulaires <5mm</th>\n",
       "      <td id=\"T_f5b86_row3_col0\" class=\"data row3 col0\" >1'926</td>\n",
       "      <td id=\"T_f5b86_row3_col1\" class=\"data row3 col1\" >0,07</td>\n",
       "      <td id=\"T_f5b86_row3_col2\" class=\"data row3 col2\" >0,03</td>\n",
       "      <td id=\"T_f5b86_row3_col3\" class=\"data row3 col3\" >0,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row4\" class=\"row_heading level0 row4\" >G112</th>\n",
       "      <th id=\"T_f5b86_level1_row4\" class=\"row_heading level1 row4\" >Pellets industriels (GPI)</th>\n",
       "      <td id=\"T_f5b86_row4_col0\" class=\"data row4 col0\" >1'526</td>\n",
       "      <td id=\"T_f5b86_row4_col1\" class=\"data row4 col1\" >0,06</td>\n",
       "      <td id=\"T_f5b86_row4_col2\" class=\"data row4 col2\" >0,02</td>\n",
       "      <td id=\"T_f5b86_row4_col3\" class=\"data row4 col3\" >0,36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row5\" class=\"row_heading level0 row5\" >Gfoams</th>\n",
       "      <th id=\"T_f5b86_level1_row5\" class=\"row_heading level1 row5\" >Fragments de polystyrène expansé: G76, G81, G82, G83</th>\n",
       "      <td id=\"T_f5b86_row5_col0\" class=\"data row5 col0\" >1'399</td>\n",
       "      <td id=\"T_f5b86_row5_col1\" class=\"data row5 col1\" >0,05</td>\n",
       "      <td id=\"T_f5b86_row5_col2\" class=\"data row5 col2\" >0,05</td>\n",
       "      <td id=\"T_f5b86_row5_col3\" class=\"data row5 col3\" >0,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row6\" class=\"row_heading level0 row6\" >Gcaps</th>\n",
       "      <th id=\"T_f5b86_level1_row6\" class=\"row_heading level1 row6\" >Couvercles en plastique bouteille:  G21, G22, G23, G24</th>\n",
       "      <td id=\"T_f5b86_row6_col0\" class=\"data row6 col0\" >1'070</td>\n",
       "      <td id=\"T_f5b86_row6_col1\" class=\"data row6 col1\" >0,04</td>\n",
       "      <td id=\"T_f5b86_row6_col2\" class=\"data row6 col2\" >0,03</td>\n",
       "      <td id=\"T_f5b86_row6_col3\" class=\"data row6 col3\" >0,65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row7\" class=\"row_heading level0 row7\" >G95</th>\n",
       "      <th id=\"T_f5b86_level1_row7\" class=\"row_heading level1 row7\" >Coton-tige</th>\n",
       "      <td id=\"T_f5b86_row7_col0\" class=\"data row7 col0\" >1'040</td>\n",
       "      <td id=\"T_f5b86_row7_col1\" class=\"data row7 col1\" >0,04</td>\n",
       "      <td id=\"T_f5b86_row7_col2\" class=\"data row7 col2\" >0,03</td>\n",
       "      <td id=\"T_f5b86_row7_col3\" class=\"data row7 col3\" >0,54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row8\" class=\"row_heading level0 row8\" >G74</th>\n",
       "      <th id=\"T_f5b86_level1_row8\" class=\"row_heading level1 row8\" >Mousse de plastique pour l'isolation thermique</th>\n",
       "      <td id=\"T_f5b86_row8_col0\" class=\"data row8 col0\" >406</td>\n",
       "      <td id=\"T_f5b86_row8_col1\" class=\"data row8 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row8_col2\" class=\"data row8 col2\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row8_col3\" class=\"data row8 col3\" >0,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row9\" class=\"row_heading level0 row9\" >G89</th>\n",
       "      <th id=\"T_f5b86_level1_row9\" class=\"row_heading level1 row9\" >Déchets de construction en plastique</th>\n",
       "      <td id=\"T_f5b86_row9_col0\" class=\"data row9 col0\" >380</td>\n",
       "      <td id=\"T_f5b86_row9_col1\" class=\"data row9 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row9_col2\" class=\"data row9 col2\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row9_col3\" class=\"data row9 col3\" >0,24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row10\" class=\"row_heading level0 row10\" >G31</th>\n",
       "      <th id=\"T_f5b86_level1_row10\" class=\"row_heading level1 row10\" >Bâtonnets de sucette</th>\n",
       "      <td id=\"T_f5b86_row10_col0\" class=\"data row10 col0\" >379</td>\n",
       "      <td id=\"T_f5b86_row10_col1\" class=\"data row10 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row10_col2\" class=\"data row10 col2\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row10_col3\" class=\"data row10 col3\" >0,54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row11\" class=\"row_heading level0 row11\" >G103</th>\n",
       "      <th id=\"T_f5b86_level1_row11\" class=\"row_heading level1 row11\" >Fragments de plastique arrondis <5mm</th>\n",
       "      <td id=\"T_f5b86_row11_col0\" class=\"data row11 col0\" >375</td>\n",
       "      <td id=\"T_f5b86_row11_col1\" class=\"data row11 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row11_col2\" class=\"data row11 col2\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row11_col3\" class=\"data row11 col3\" >0,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row12\" class=\"row_heading level0 row12\" >G117</th>\n",
       "      <th id=\"T_f5b86_level1_row12\" class=\"row_heading level1 row12\" >Polystyrène < 5mm</th>\n",
       "      <td id=\"T_f5b86_row12_col0\" class=\"data row12 col0\" >311</td>\n",
       "      <td id=\"T_f5b86_row12_col1\" class=\"data row12 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row12_col2\" class=\"data row12 col2\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row12_col3\" class=\"data row12 col3\" >0,34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row13\" class=\"row_heading level0 row13\" >G70</th>\n",
       "      <th id=\"T_f5b86_level1_row13\" class=\"row_heading level1 row13\" >Cartouches de fusil de chasse</th>\n",
       "      <td id=\"T_f5b86_row13_col0\" class=\"data row13 col0\" >199</td>\n",
       "      <td id=\"T_f5b86_row13_col1\" class=\"data row13 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row13_col2\" class=\"data row13 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row13_col3\" class=\"data row13 col3\" >0,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row14\" class=\"row_heading level0 row14\" >G114</th>\n",
       "      <th id=\"T_f5b86_level1_row14\" class=\"row_heading level1 row14\" >Films <5mm</th>\n",
       "      <td id=\"T_f5b86_row14_col0\" class=\"data row14 col0\" >197</td>\n",
       "      <td id=\"T_f5b86_row14_col1\" class=\"data row14 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row14_col2\" class=\"data row14 col2\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row14_col3\" class=\"data row14 col3\" >0,12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row15\" class=\"row_heading level0 row15\" >G50</th>\n",
       "      <th id=\"T_f5b86_level1_row15\" class=\"row_heading level1 row15\" >Cordon < 1cm</th>\n",
       "      <td id=\"T_f5b86_row15_col0\" class=\"data row15 col0\" >172</td>\n",
       "      <td id=\"T_f5b86_row15_col1\" class=\"data row15 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row15_col2\" class=\"data row15 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row15_col3\" class=\"data row15 col3\" >0,44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row16\" class=\"row_heading level0 row16\" >G113</th>\n",
       "      <th id=\"T_f5b86_level1_row16\" class=\"row_heading level1 row16\" >Filaments <5mm</th>\n",
       "      <td id=\"T_f5b86_row16_col0\" class=\"data row16 col0\" >169</td>\n",
       "      <td id=\"T_f5b86_row16_col1\" class=\"data row16 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row16_col2\" class=\"data row16 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row16_col3\" class=\"data row16 col3\" >0,31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row17\" class=\"row_heading level0 row17\" >G932</th>\n",
       "      <th id=\"T_f5b86_level1_row17\" class=\"row_heading level1 row17\" >Bio-perles, micro plastique pour les eaux usées</th>\n",
       "      <td id=\"T_f5b86_row17_col0\" class=\"data row17 col0\" >161</td>\n",
       "      <td id=\"T_f5b86_row17_col1\" class=\"data row17 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row17_col2\" class=\"data row17 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row17_col3\" class=\"data row17 col3\" >0,36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row18\" class=\"row_heading level0 row18\" >G35</th>\n",
       "      <th id=\"T_f5b86_level1_row18\" class=\"row_heading level1 row18\" >Pailles et agitateurs</th>\n",
       "      <td id=\"T_f5b86_row18_col0\" class=\"data row18 col0\" >159</td>\n",
       "      <td id=\"T_f5b86_row18_col1\" class=\"data row18 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row18_col2\" class=\"data row18 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row18_col3\" class=\"data row18 col3\" >0,40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row19\" class=\"row_heading level0 row19\" >G67</th>\n",
       "      <th id=\"T_f5b86_level1_row19\" class=\"row_heading level1 row19\" >Bâche, feuille plastique industrielle</th>\n",
       "      <td id=\"T_f5b86_row19_col0\" class=\"data row19 col0\" >146</td>\n",
       "      <td id=\"T_f5b86_row19_col1\" class=\"data row19 col1\" >0,01</td>\n",
       "      <td id=\"T_f5b86_row19_col2\" class=\"data row19 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row19_col3\" class=\"data row19 col3\" >0,07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row20\" class=\"row_heading level0 row20\" >G66</th>\n",
       "      <th id=\"T_f5b86_level1_row20\" class=\"row_heading level1 row20\" >Sangles/bandes ; fermeture de paquet en plastique dur</th>\n",
       "      <td id=\"T_f5b86_row20_col0\" class=\"data row20 col0\" >114</td>\n",
       "      <td id=\"T_f5b86_row20_col1\" class=\"data row20 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row20_col2\" class=\"data row20 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row20_col3\" class=\"data row20 col3\" >0,30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row21\" class=\"row_heading level0 row21\" >G905</th>\n",
       "      <th id=\"T_f5b86_level1_row21\" class=\"row_heading level1 row21\" >Pince à cheveux, accessoires personnels</th>\n",
       "      <td id=\"T_f5b86_row21_col0\" class=\"data row21 col0\" >108</td>\n",
       "      <td id=\"T_f5b86_row21_col1\" class=\"data row21 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row21_col2\" class=\"data row21 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row21_col3\" class=\"data row21 col3\" >0,44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row22\" class=\"row_heading level0 row22\" >G211</th>\n",
       "      <th id=\"T_f5b86_level1_row22\" class=\"row_heading level1 row22\" >Autres articles médicaux: compresses, pansements</th>\n",
       "      <td id=\"T_f5b86_row22_col0\" class=\"data row22 col0\" >105</td>\n",
       "      <td id=\"T_f5b86_row22_col1\" class=\"data row22 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row22_col2\" class=\"data row22 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row22_col3\" class=\"data row22 col3\" >0,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row23\" class=\"row_heading level0 row23\" >G165</th>\n",
       "      <th id=\"T_f5b86_level1_row23\" class=\"row_heading level1 row23\" >Bâtons de glace, cure-dents, baguettes chinoises</th>\n",
       "      <td id=\"T_f5b86_row23_col0\" class=\"data row23 col0\" >93</td>\n",
       "      <td id=\"T_f5b86_row23_col1\" class=\"data row23 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row23_col2\" class=\"data row23 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row23_col3\" class=\"data row23 col3\" >0,11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row24\" class=\"row_heading level0 row24\" >G32</th>\n",
       "      <th id=\"T_f5b86_level1_row24\" class=\"row_heading level1 row24\" >Jouets et faveurs de fête</th>\n",
       "      <td id=\"T_f5b86_row24_col0\" class=\"data row24 col0\" >63</td>\n",
       "      <td id=\"T_f5b86_row24_col1\" class=\"data row24 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row24_col2\" class=\"data row24 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row24_col3\" class=\"data row24 col3\" >0,22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row25\" class=\"row_heading level0 row25\" >G194</th>\n",
       "      <th id=\"T_f5b86_level1_row25\" class=\"row_heading level1 row25\" >Câbles, fil métallique</th>\n",
       "      <td id=\"T_f5b86_row25_col0\" class=\"data row25 col0\" >58</td>\n",
       "      <td id=\"T_f5b86_row25_col1\" class=\"data row25 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row25_col2\" class=\"data row25 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row25_col3\" class=\"data row25 col3\" >0,24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row26\" class=\"row_heading level0 row26\" >G131</th>\n",
       "      <th id=\"T_f5b86_level1_row26\" class=\"row_heading level1 row26\" >Bandes élastiques</th>\n",
       "      <td id=\"T_f5b86_row26_col0\" class=\"data row26 col0\" >57</td>\n",
       "      <td id=\"T_f5b86_row26_col1\" class=\"data row26 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row26_col2\" class=\"data row26 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row26_col3\" class=\"data row26 col3\" >0,24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row27\" class=\"row_heading level0 row27\" >G125</th>\n",
       "      <th id=\"T_f5b86_level1_row27\" class=\"row_heading level1 row27\" >Ballons et bâtonnets de ballons</th>\n",
       "      <td id=\"T_f5b86_row27_col0\" class=\"data row27 col0\" >51</td>\n",
       "      <td id=\"T_f5b86_row27_col1\" class=\"data row27 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row27_col2\" class=\"data row27 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row27_col3\" class=\"data row27 col3\" >0,24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row28\" class=\"row_heading level0 row28\" >G922</th>\n",
       "      <th id=\"T_f5b86_level1_row28\" class=\"row_heading level1 row28\" >Étiquettes, codes à barres</th>\n",
       "      <td id=\"T_f5b86_row28_col0\" class=\"data row28 col0\" >43</td>\n",
       "      <td id=\"T_f5b86_row28_col1\" class=\"data row28 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row28_col2\" class=\"data row28 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row28_col3\" class=\"data row28 col3\" >0,15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row29\" class=\"row_heading level0 row29\" >G33</th>\n",
       "      <th id=\"T_f5b86_level1_row29\" class=\"row_heading level1 row29\" >Gobelets, couvercles, mousse à usage unique et plastique dur</th>\n",
       "      <td id=\"T_f5b86_row29_col0\" class=\"data row29 col0\" >42</td>\n",
       "      <td id=\"T_f5b86_row29_col1\" class=\"data row29 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row29_col2\" class=\"data row29 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row29_col3\" class=\"data row29 col3\" >0,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row30\" class=\"row_heading level0 row30\" >G159</th>\n",
       "      <th id=\"T_f5b86_level1_row30\" class=\"row_heading level1 row30\" >Bouchon de liège</th>\n",
       "      <td id=\"T_f5b86_row30_col0\" class=\"data row30 col0\" >29</td>\n",
       "      <td id=\"T_f5b86_row30_col1\" class=\"data row30 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row30_col2\" class=\"data row30 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row30_col3\" class=\"data row30 col3\" >0,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row31\" class=\"row_heading level0 row31\" >G73</th>\n",
       "      <th id=\"T_f5b86_level1_row31\" class=\"row_heading level1 row31\" >Articles et pièces en mousse (pas d'emballage)</th>\n",
       "      <td id=\"T_f5b86_row31_col0\" class=\"data row31 col0\" >24</td>\n",
       "      <td id=\"T_f5b86_row31_col1\" class=\"data row31 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row31_col2\" class=\"data row31 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row31_col3\" class=\"data row31 col3\" >0,06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row32\" class=\"row_heading level0 row32\" >G53</th>\n",
       "      <th id=\"T_f5b86_level1_row32\" class=\"row_heading level1 row32\" >Filets et pièces < 50cm</th>\n",
       "      <td id=\"T_f5b86_row32_col0\" class=\"data row32 col0\" >23</td>\n",
       "      <td id=\"T_f5b86_row32_col1\" class=\"data row32 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row32_col2\" class=\"data row32 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row32_col3\" class=\"data row32 col3\" >0,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row33\" class=\"row_heading level0 row33\" >G132</th>\n",
       "      <th id=\"T_f5b86_level1_row33\" class=\"row_heading level1 row33\" >Bobine de pêche</th>\n",
       "      <td id=\"T_f5b86_row33_col0\" class=\"data row33 col0\" >19</td>\n",
       "      <td id=\"T_f5b86_row33_col1\" class=\"data row33 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row33_col2\" class=\"data row33 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row33_col3\" class=\"data row33 col3\" >0,12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row34\" class=\"row_heading level0 row34\" >G2</th>\n",
       "      <th id=\"T_f5b86_level1_row34\" class=\"row_heading level1 row34\" >Sacs</th>\n",
       "      <td id=\"T_f5b86_row34_col0\" class=\"data row34 col0\" >19</td>\n",
       "      <td id=\"T_f5b86_row34_col1\" class=\"data row34 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row34_col2\" class=\"data row34 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row34_col3\" class=\"data row34 col3\" >0,15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row35\" class=\"row_heading level0 row35\" >G34</th>\n",
       "      <th id=\"T_f5b86_level1_row35\" class=\"row_heading level1 row35\" >Couverts, assiettes et plateaux palstique</th>\n",
       "      <td id=\"T_f5b86_row35_col0\" class=\"data row35 col0\" >18</td>\n",
       "      <td id=\"T_f5b86_row35_col1\" class=\"data row35 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row35_col2\" class=\"data row35 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row35_col3\" class=\"data row35 col3\" >0,14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row36\" class=\"row_heading level0 row36\" >G10</th>\n",
       "      <th id=\"T_f5b86_level1_row36\" class=\"row_heading level1 row36\" >Emballage fast food</th>\n",
       "      <td id=\"T_f5b86_row36_col0\" class=\"data row36 col0\" >18</td>\n",
       "      <td id=\"T_f5b86_row36_col1\" class=\"data row36 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row36_col2\" class=\"data row36 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row36_col3\" class=\"data row36 col3\" >0,09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row37\" class=\"row_heading level0 row37\" >G926</th>\n",
       "      <th id=\"T_f5b86_level1_row37\" class=\"row_heading level1 row37\" >Du chewing-gum</th>\n",
       "      <td id=\"T_f5b86_row37_col0\" class=\"data row37 col0\" >15</td>\n",
       "      <td id=\"T_f5b86_row37_col1\" class=\"data row37 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row37_col2\" class=\"data row37 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row37_col3\" class=\"data row37 col3\" >0,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row38\" class=\"row_heading level0 row38\" >G97</th>\n",
       "      <th id=\"T_f5b86_level1_row38\" class=\"row_heading level1 row38\" >Rafraîchisseurs de toilettes</th>\n",
       "      <td id=\"T_f5b86_row38_col0\" class=\"data row38 col0\" >15</td>\n",
       "      <td id=\"T_f5b86_row38_col1\" class=\"data row38 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row38_col2\" class=\"data row38 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row38_col3\" class=\"data row38 col3\" >0,08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row39\" class=\"row_heading level0 row39\" >G139</th>\n",
       "      <th id=\"T_f5b86_level1_row39\" class=\"row_heading level1 row39\" >Sacs à dos</th>\n",
       "      <td id=\"T_f5b86_row39_col0\" class=\"data row39 col0\" >15</td>\n",
       "      <td id=\"T_f5b86_row39_col1\" class=\"data row39 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row39_col2\" class=\"data row39 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row39_col3\" class=\"data row39 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row40\" class=\"row_heading level0 row40\" >G100</th>\n",
       "      <th id=\"T_f5b86_level1_row40\" class=\"row_heading level1 row40\" >Médical conteneurs/tubes/ emballages</th>\n",
       "      <td id=\"T_f5b86_row40_col0\" class=\"data row40 col0\" >13</td>\n",
       "      <td id=\"T_f5b86_row40_col1\" class=\"data row40 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row40_col2\" class=\"data row40 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row40_col3\" class=\"data row40 col3\" >0,09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row41\" class=\"row_heading level0 row41\" >G12</th>\n",
       "      <th id=\"T_f5b86_level1_row41\" class=\"row_heading level1 row41\" >Récipients de soins personnels non destinés à la plage</th>\n",
       "      <td id=\"T_f5b86_row41_col0\" class=\"data row41 col0\" >13</td>\n",
       "      <td id=\"T_f5b86_row41_col1\" class=\"data row41 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row41_col2\" class=\"data row41 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row41_col3\" class=\"data row41 col3\" >0,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row42\" class=\"row_heading level0 row42\" >G901</th>\n",
       "      <th id=\"T_f5b86_level1_row42\" class=\"row_heading level1 row42\" >Masque médical, synthétique</th>\n",
       "      <td id=\"T_f5b86_row42_col0\" class=\"data row42 col0\" >12</td>\n",
       "      <td id=\"T_f5b86_row42_col1\" class=\"data row42 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row42_col2\" class=\"data row42 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row42_col3\" class=\"data row42 col3\" >0,08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row43\" class=\"row_heading level0 row43\" >G26</th>\n",
       "      <th id=\"T_f5b86_level1_row43\" class=\"row_heading level1 row43\" >Allume-cigarettes</th>\n",
       "      <td id=\"T_f5b86_row43_col0\" class=\"data row43 col0\" >9</td>\n",
       "      <td id=\"T_f5b86_row43_col1\" class=\"data row43 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row43_col2\" class=\"data row43 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row43_col3\" class=\"data row43 col3\" >0,08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row44\" class=\"row_heading level0 row44\" >G135</th>\n",
       "      <th id=\"T_f5b86_level1_row44\" class=\"row_heading level1 row44\" >Vêtements, chaussures, chapeaux et gants</th>\n",
       "      <td id=\"T_f5b86_row44_col0\" class=\"data row44 col0\" >9</td>\n",
       "      <td id=\"T_f5b86_row44_col1\" class=\"data row44 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row44_col2\" class=\"data row44 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row44_col3\" class=\"data row44 col3\" >0,07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row45\" class=\"row_heading level0 row45\" >G137</th>\n",
       "      <th id=\"T_f5b86_level1_row45\" class=\"row_heading level1 row45\" >Serviettes et chiffons</th>\n",
       "      <td id=\"T_f5b86_row45_col0\" class=\"data row45 col0\" >8</td>\n",
       "      <td id=\"T_f5b86_row45_col1\" class=\"data row45 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row45_col2\" class=\"data row45 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row45_col3\" class=\"data row45 col3\" >0,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row46\" class=\"row_heading level0 row46\" >G7</th>\n",
       "      <th id=\"T_f5b86_level1_row46\" class=\"row_heading level1 row46\" >Bouteilles à boisson < = 0,5L</th>\n",
       "      <td id=\"T_f5b86_row46_col0\" class=\"data row46 col0\" >7</td>\n",
       "      <td id=\"T_f5b86_row46_col1\" class=\"data row46 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row46_col2\" class=\"data row46 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row46_col3\" class=\"data row46 col3\" >0,07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row47\" class=\"row_heading level0 row47\" >G28</th>\n",
       "      <th id=\"T_f5b86_level1_row47\" class=\"row_heading level1 row47\" >Stylos, couvercles, porte-mines</th>\n",
       "      <td id=\"T_f5b86_row47_col0\" class=\"data row47 col0\" >7</td>\n",
       "      <td id=\"T_f5b86_row47_col1\" class=\"data row47 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row47_col2\" class=\"data row47 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row47_col3\" class=\"data row47 col3\" >0,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row48\" class=\"row_heading level0 row48\" >G931</th>\n",
       "      <th id=\"T_f5b86_level1_row48\" class=\"row_heading level1 row48\" >Ruban pour barrière, police, construction</th>\n",
       "      <td id=\"T_f5b86_row48_col0\" class=\"data row48 col0\" >7</td>\n",
       "      <td id=\"T_f5b86_row48_col1\" class=\"data row48 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row48_col2\" class=\"data row48 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row48_col3\" class=\"data row48 col3\" >0,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row49\" class=\"row_heading level0 row49\" >G144</th>\n",
       "      <th id=\"T_f5b86_level1_row49\" class=\"row_heading level1 row49\" >Tampons</th>\n",
       "      <td id=\"T_f5b86_row49_col0\" class=\"data row49 col0\" >6</td>\n",
       "      <td id=\"T_f5b86_row49_col1\" class=\"data row49 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row49_col2\" class=\"data row49 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row49_col3\" class=\"data row49 col3\" >0,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row50\" class=\"row_heading level0 row50\" >G145</th>\n",
       "      <th id=\"T_f5b86_level1_row50\" class=\"row_heading level1 row50\" >Autres textiles</th>\n",
       "      <td id=\"T_f5b86_row50_col0\" class=\"data row50 col0\" >6</td>\n",
       "      <td id=\"T_f5b86_row50_col1\" class=\"data row50 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row50_col2\" class=\"data row50 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row50_col3\" class=\"data row50 col3\" >0,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row51\" class=\"row_heading level0 row51\" >G90</th>\n",
       "      <th id=\"T_f5b86_level1_row51\" class=\"row_heading level1 row51\" >Pots de fleurs en plastique</th>\n",
       "      <td id=\"T_f5b86_row51_col0\" class=\"data row51 col0\" >6</td>\n",
       "      <td id=\"T_f5b86_row51_col1\" class=\"data row51 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row51_col2\" class=\"data row51 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row51_col3\" class=\"data row51 col3\" >0,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row52\" class=\"row_heading level0 row52\" >G126</th>\n",
       "      <th id=\"T_f5b86_level1_row52\" class=\"row_heading level1 row52\" >Boules en caoutchouc</th>\n",
       "      <td id=\"T_f5b86_row52_col0\" class=\"data row52 col0\" >6</td>\n",
       "      <td id=\"T_f5b86_row52_col1\" class=\"data row52 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row52_col2\" class=\"data row52 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row52_col3\" class=\"data row52 col3\" >0,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row53\" class=\"row_heading level0 row53\" >G99</th>\n",
       "      <th id=\"T_f5b86_level1_row53\" class=\"row_heading level1 row53\" >Seringues - aiguilles</th>\n",
       "      <td id=\"T_f5b86_row53_col0\" class=\"data row53 col0\" >5</td>\n",
       "      <td id=\"T_f5b86_row53_col1\" class=\"data row53 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row53_col2\" class=\"data row53 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row53_col3\" class=\"data row53 col3\" >0,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row54\" class=\"row_heading level0 row54\" >G48</th>\n",
       "      <th id=\"T_f5b86_level1_row54\" class=\"row_heading level1 row54\" >Corde, synthétique</th>\n",
       "      <td id=\"T_f5b86_row54_col0\" class=\"data row54 col0\" >5</td>\n",
       "      <td id=\"T_f5b86_row54_col1\" class=\"data row54 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row54_col2\" class=\"data row54 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row54_col3\" class=\"data row54 col3\" >0,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row55\" class=\"row_heading level0 row55\" >G937</th>\n",
       "      <th id=\"T_f5b86_level1_row55\" class=\"row_heading level1 row55\" >Appâts à phéromones pour les vignobles</th>\n",
       "      <td id=\"T_f5b86_row55_col0\" class=\"data row55 col0\" >4</td>\n",
       "      <td id=\"T_f5b86_row55_col1\" class=\"data row55 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row55_col2\" class=\"data row55 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row55_col3\" class=\"data row55 col3\" >0,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row56\" class=\"row_heading level0 row56\" >G29</th>\n",
       "      <th id=\"T_f5b86_level1_row56\" class=\"row_heading level1 row56\" >Peignes, brosses et lunettes de soleil</th>\n",
       "      <td id=\"T_f5b86_row56_col0\" class=\"data row56 col0\" >4</td>\n",
       "      <td id=\"T_f5b86_row56_col1\" class=\"data row56 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row56_col2\" class=\"data row56 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row56_col3\" class=\"data row56 col3\" >0,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row57\" class=\"row_heading level0 row57\" >G25</th>\n",
       "      <th id=\"T_f5b86_level1_row57\" class=\"row_heading level1 row57\" >Tabac emballages en plastique</th>\n",
       "      <td id=\"T_f5b86_row57_col0\" class=\"data row57 col0\" >4</td>\n",
       "      <td id=\"T_f5b86_row57_col1\" class=\"data row57 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row57_col2\" class=\"data row57 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row57_col3\" class=\"data row57 col3\" >0,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row58\" class=\"row_heading level0 row58\" >G128</th>\n",
       "      <th id=\"T_f5b86_level1_row58\" class=\"row_heading level1 row58\" >Pneus et courroies</th>\n",
       "      <td id=\"T_f5b86_row58_col0\" class=\"data row58 col0\" >3</td>\n",
       "      <td id=\"T_f5b86_row58_col1\" class=\"data row58 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row58_col2\" class=\"data row58 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row58_col3\" class=\"data row58 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row59\" class=\"row_heading level0 row59\" >G54</th>\n",
       "      <th id=\"T_f5b86_level1_row59\" class=\"row_heading level1 row59\" >Filets et pièces > 50cm</th>\n",
       "      <td id=\"T_f5b86_row59_col0\" class=\"data row59 col0\" >3</td>\n",
       "      <td id=\"T_f5b86_row59_col1\" class=\"data row59 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row59_col2\" class=\"data row59 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row59_col3\" class=\"data row59 col3\" >0,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row60\" class=\"row_heading level0 row60\" >G929</th>\n",
       "      <th id=\"T_f5b86_level1_row60\" class=\"row_heading level1 row60\" >Électronique et pièces ; capteurs, écouteurs</th>\n",
       "      <td id=\"T_f5b86_row60_col0\" class=\"data row60 col0\" >3</td>\n",
       "      <td id=\"T_f5b86_row60_col1\" class=\"data row60 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row60_col2\" class=\"data row60 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row60_col3\" class=\"data row60 col3\" >0,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row61\" class=\"row_heading level0 row61\" >G39</th>\n",
       "      <th id=\"T_f5b86_level1_row61\" class=\"row_heading level1 row61\" >Gants</th>\n",
       "      <td id=\"T_f5b86_row61_col0\" class=\"data row61 col0\" >3</td>\n",
       "      <td id=\"T_f5b86_row61_col1\" class=\"data row61 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row61_col2\" class=\"data row61 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row61_col3\" class=\"data row61 col3\" >0,02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row62\" class=\"row_heading level0 row62\" >G136</th>\n",
       "      <th id=\"T_f5b86_level1_row62\" class=\"row_heading level1 row62\" >Chaussures</th>\n",
       "      <td id=\"T_f5b86_row62_col0\" class=\"data row62 col0\" >2</td>\n",
       "      <td id=\"T_f5b86_row62_col1\" class=\"data row62 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row62_col2\" class=\"data row62 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row62_col3\" class=\"data row62 col3\" >0,02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row63\" class=\"row_heading level0 row63\" >G914</th>\n",
       "      <th id=\"T_f5b86_level1_row63\" class=\"row_heading level1 row63\" >Trombones, épingles à linge, articles utilitaires en plastique</th>\n",
       "      <td id=\"T_f5b86_row63_col0\" class=\"data row63 col0\" >2</td>\n",
       "      <td id=\"T_f5b86_row63_col1\" class=\"data row63 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row63_col2\" class=\"data row63 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row63_col3\" class=\"data row63 col3\" >0,02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row64\" class=\"row_heading level0 row64\" >G127</th>\n",
       "      <th id=\"T_f5b86_level1_row64\" class=\"row_heading level1 row64\" >Bottes en caoutchouc</th>\n",
       "      <td id=\"T_f5b86_row64_col0\" class=\"data row64 col0\" >2</td>\n",
       "      <td id=\"T_f5b86_row64_col1\" class=\"data row64 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row64_col2\" class=\"data row64 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row64_col3\" class=\"data row64 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row65\" class=\"row_heading level0 row65\" >G4</th>\n",
       "      <th id=\"T_f5b86_level1_row65\" class=\"row_heading level1 row65\" >Petits sacs en plastique ; congélateur, zip-lock</th>\n",
       "      <td id=\"T_f5b86_row65_col0\" class=\"data row65 col0\" >2</td>\n",
       "      <td id=\"T_f5b86_row65_col1\" class=\"data row65 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row65_col2\" class=\"data row65 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row65_col3\" class=\"data row65 col3\" >0,02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row66\" class=\"row_heading level0 row66\" >G101</th>\n",
       "      <th id=\"T_f5b86_level1_row66\" class=\"row_heading level1 row66\" >Sac pour déjections canines</th>\n",
       "      <td id=\"T_f5b86_row66_col0\" class=\"data row66 col0\" >2</td>\n",
       "      <td id=\"T_f5b86_row66_col1\" class=\"data row66 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row66_col2\" class=\"data row66 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row66_col3\" class=\"data row66 col3\" >0,02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row67\" class=\"row_heading level0 row67\" >G129</th>\n",
       "      <th id=\"T_f5b86_level1_row67\" class=\"row_heading level1 row67\" >Chambres à air et feuilles de caoutchouc</th>\n",
       "      <td id=\"T_f5b86_row67_col0\" class=\"data row67 col0\" >1</td>\n",
       "      <td id=\"T_f5b86_row67_col1\" class=\"data row67 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row67_col2\" class=\"data row67 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row67_col3\" class=\"data row67 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row68\" class=\"row_heading level0 row68\" >G148</th>\n",
       "      <th id=\"T_f5b86_level1_row68\" class=\"row_heading level1 row68\" >Boîtes en carton</th>\n",
       "      <td id=\"T_f5b86_row68_col0\" class=\"data row68 col0\" >1</td>\n",
       "      <td id=\"T_f5b86_row68_col1\" class=\"data row68 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row68_col2\" class=\"data row68 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row68_col3\" class=\"data row68 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row69\" class=\"row_heading level0 row69\" >G155</th>\n",
       "      <th id=\"T_f5b86_level1_row69\" class=\"row_heading level1 row69\" >Tubes et fragments de papier: feux d'artifice</th>\n",
       "      <td id=\"T_f5b86_row69_col0\" class=\"data row69 col0\" >1</td>\n",
       "      <td id=\"T_f5b86_row69_col1\" class=\"data row69 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row69_col2\" class=\"data row69 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row69_col3\" class=\"data row69 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row70\" class=\"row_heading level0 row70\" >G18</th>\n",
       "      <th id=\"T_f5b86_level1_row70\" class=\"row_heading level1 row70\" >Caisses/paniers</th>\n",
       "      <td id=\"T_f5b86_row70_col0\" class=\"data row70 col0\" >1</td>\n",
       "      <td id=\"T_f5b86_row70_col1\" class=\"data row70 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row70_col2\" class=\"data row70 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row70_col3\" class=\"data row70 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row71\" class=\"row_heading level0 row71\" >G102</th>\n",
       "      <th id=\"T_f5b86_level1_row71\" class=\"row_heading level1 row71\" >Tongs</th>\n",
       "      <td id=\"T_f5b86_row71_col0\" class=\"data row71 col0\" >1</td>\n",
       "      <td id=\"T_f5b86_row71_col1\" class=\"data row71 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row71_col2\" class=\"data row71 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row71_col3\" class=\"data row71 col3\" >0,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b86_level0_row72\" class=\"row_heading level0 row72\" >G133</th>\n",
       "      <th id=\"T_f5b86_level1_row72\" class=\"row_heading level1 row72\" >Préservatifs, y compris emballage</th>\n",
       "      <td id=\"T_f5b86_row72_col0\" class=\"data row72 col0\" >1</td>\n",
       "      <td id=\"T_f5b86_row72_col1\" class=\"data row72 col1\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row72_col2\" class=\"data row72 col2\" >0,00</td>\n",
       "      <td id=\"T_f5b86_row72_col3\" class=\"data row72 col3\" >0,01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc453b5d4c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory['index'] = inventory.index.map(lambda x: codes.fr.loc[x])\n",
    "inventory.reset_index(inplace=True)\n",
    "inventory.set_index(['code','index'], drop=True, inplace=True)\n",
    "inventory.index.name = None\n",
    "inventory.sort_values(by='Quantité', inplace=True, ascending=False)\n",
    "inventory.style.set_table_styles(table_css_styles).format(**format_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c6060f9-9319-40b1-842f-1995cf4820bc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git repo: https://github.com/hammerdirt-analyst/plastock.git\n",
      "\n",
      "Git branch: dec20\n",
      "\n",
      "seaborn   : 0.12.2\n",
      "numpy     : 1.24.2\n",
      "pandas    : 2.0.0\n",
      "matplotlib: 3.7.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions -b -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e0bd5-5be4-4326-8345-458f206b52c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a83fc6-21a5-4f72-95e3-fd01107f8757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d610a-b3a4-46c8-a2b1-8d169537dc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5746a19-9e02-4fdb-a52f-30d003dede25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}